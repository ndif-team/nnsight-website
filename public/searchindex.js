Search.setIndex({"alltitles": {"*\ufe0f\u20e3 Exercise: delving a little deeper": [[32, "*\ufe0f\u20e3-Exercise:-delving-a-little-deeper"]], "*\ufe0f\u20e3 Extension: gender bias in GPT-2": [[33, "*\ufe0f\u20e3-Extension:-gender-bias-in-GPT-2"]], ".all() streamlines interventions on many generated tokens": [[16, ".all()-streamlines-interventions-on-many-generated-tokens"]], ".generate()": [[16, ".generate()"]], ".iter() for interventions only on specific generation iterations": [[16, ".iter()-for-interventions-only-on-specific-generation-iterations"]], ".next()": [[16, ".next()"], [37, ".next()"]], "0\ufe0f\u20e3 Setup": [[25, "0\ufe0f\u20e3-Setup"], [26, "0\ufe0f\u20e3-Setup"], [27, "0\ufe0f\u20e3-Setup"], [32, "0\ufe0f\u20e3-Setup"], [33, "0\ufe0f\u20e3-Setup"]], "1 First, let\u2019s start small": [[37, "1-First,-let's-start-small"]], "1. Configure NDIF API Key": [[17, "1.-Configure-NDIF-API-Key"]], "1\ufe0f\u20e3 Causal mediation": [[32, "1\ufe0f\u20e3-Causal-mediation"]], "1\ufe0f\u20e3 Causal mediation & information flow": [[33, "1\ufe0f\u20e3-Causal-mediation-&-information-flow"]], "1\ufe0f\u20e3 How do we actually find these heads?": [[25, "1\ufe0f\u20e3-How-do-we-actually-find-these-heads?"]], "1\ufe0f\u20e3 Indirect Object Identification (IOI) Patching": [[31, "1\ufe0f\u20e3-Indirect-Object-Identification-(IOI)-Patching"]], "1\ufe0f\u20e3 Information flow": [[27, "1\ufe0f\u20e3-Information-flow"]], "1\ufe0f\u20e3 Introduction to nnsight": [[28, "1\ufe0f\u20e3-Introduction-to-nnsight"], [28, "id2"]], "1\ufe0f\u20e3 What triggers memorization?": [[26, "1\ufe0f\u20e3-What-triggers-memorization?"]], "2. Access NDIF-hosted Models Remotely": [[17, "2.-Access-NDIF-hosted-Models-Remotely"]], "2\ufe0f Bigger": [[37, "2\ufe0f-Bigger"]], "2\ufe0f\u20e3 Attention Scores: Where are these heads attending?": [[25, "2\ufe0f\u20e3-Attention-Scores:-Where-are-these-heads-attending?"]], "2\ufe0f\u20e3 Attribution Patching Over Components": [[31, "2\ufe0f\u20e3-Attribution-Patching-Over-Components"]], "2\ufe0f\u20e3 How does causal mediation analysis inform behavior?": [[26, "2\ufe0f\u20e3-How-does-causal-mediation-analysis-inform-behavior?"]], "2\ufe0f\u20e3 Intervening on specific model components": [[33, "2\ufe0f\u20e3-Intervening-on-specific-model-components"]], "2\ufe0f\u20e3 Task-encoding hidden states": [[28, "2\ufe0f\u20e3-Task-encoding-hidden-states"], [28, "id4"]], "2\ufe0f\u20e3 Total, Direct, and Indirect Effect": [[32, "2\ufe0f\u20e3-Total,-Direct,-and-Indirect-Effect"]], "2\ufe0f\u20e3 Visualizing activations": [[27, "2\ufe0f\u20e3-Visualizing-activations"]], "3 I thought you said huge models?": [[37, "3-I-thought-you-said-huge-models?"]], "3. Streamlining Remote Experiments with Sessions": [[17, "3.-Streamlining-Remote-Experiments-with-Sessions"]], "3\ufe0f\u20e3 Attribution Patching Over Position": [[31, "3\ufe0f\u20e3-Attribution-Patching-Over-Position"]], "3\ufe0f\u20e3 Causal mediation analysis on a toy network": [[32, "3\ufe0f\u20e3-Causal-mediation-analysis-on-a-toy-network"]], "3\ufe0f\u20e3 Choosing the right probe - linear classifiers vs. difference in means": [[27, "3\ufe0f\u20e3-Choosing-the-right-probe---linear-classifiers-vs.-difference-in-means"]], "3\ufe0f\u20e3 Concept/Token Lens: What information are these heads actually transferring?": [[25, "3\ufe0f\u20e3-Concept/Token-Lens:-What-information-are-these-heads-actually-transferring?"]], "3\ufe0f\u20e3 Function Vectors": [[28, "3\ufe0f\u20e3-Function-Vectors"], [28, "id6"]], "4. Remote Model Considerations & System Limits": [[17, "4.-Remote-Model-Considerations-&-System-Limits"]], "4\ufe0f\u20e3 Difference in means steering": [[27, "4\ufe0f\u20e3-Difference-in-means-steering"]], "4\ufe0f\u20e3 Steering Vectors in GPT2-XL": [[28, "4\ufe0f\u20e3-Steering-Vectors-in-GPT2-XL"], [28, "id8"]], "4\ufe0f\u20e3 What happens when you ablate token heads?": [[25, "4\ufe0f\u20e3-What-happens-when-you-ablate-token-heads?"]], "5\ufe0f\u20e3 Language-Invariant Conceptual Representations": [[25, "5\ufe0f\u20e3-Language-Invariant-Conceptual-Representations"]], "@nnsight.trace function decorator": [[22, "@nnsight.trace-function-decorator"], [37, "@nnsight.trace-function-decorator"]], "A note on out_proj": [[28, "A-note-on-out_proj"]], "About NNsight": [[0, "about-nnsight"]], "Access LLM Internals": [[50, "access-llm-internals"]], "Access LLMs with NDIF and NNsight": [[36, "Access-LLMs-with-NDIF-and-NNsight"]], "Access model internals": [[36, "Access-model-internals"]], "Accessing Gradients": [[13, "Accessing-Gradients"]], "Activation Patching": [[27, "Activation-Patching"], [30, "Activation-Patching"]], "Alter model internals": [[36, "Alter-model-internals"]], "An API for transparent science on black-box AI.": [[0, "an-api-for-transparent-science-on-black-box-ai"]], "Apply Logit Lens": [[39, "Apply-Logit-Lens"]], "Apply SAE": [[41, "Apply-SAE"]], "Applying a Chat Template": [[35, "Applying-a-Chat-Template"]], "At last: interpreting our model": [[32, "At-last:-interpreting-our-model"]], "Attribution Patching": [[31, "Attribution-Patching"]], "BONUS: FLUX Schnell (CLIP and T5 XXL encoders)": [[38, "BONUS:-FLUX-Schnell-(CLIP-and-T5-XXL-encoders)"]], "BONUS: Stable Diffusion XL (Two CLIP encoders)": [[38, "BONUS:-Stable-Diffusion-XL-(Two-CLIP-encoders)"]], "Batching": [[10, "Batching"], [37, "Batching"]], "Caching": [[28, "Caching"]], "Causal Mediation Analysis I: Introduction": [[32, "Causal-Mediation-Analysis-I:-Introduction"]], "Causal Mediation Analysis II: Explaining LLMs": [[33, "Causal-Mediation-Analysis-II:-Explaining-LLMs"]], "Causal effect depends on what we\u2019re trying to mediate": [[32, "Causal-effect-depends-on-what-we're-trying-to-mediate"]], "Causal mediation analysis": [[26, "Causal-mediation-analysis"]], "Causal mediators": [[32, "Causal-mediators"]], "Chat Template Parameters": [[35, "Chat-Template-Parameters"]], "Chat Templates": [[35, "Chat-Templates"]], "Choose a Model": [[36, "Choose-a-Model"]], "Choosing the right unit of computation - how do models represent concepts?": [[29, "Choosing-the-right-unit-of-computation---how-do-models-represent-concepts?"]], "Code Implementation": [[25, "Code-Implementation"], [25, "id1"], [25, "id2"], [25, "id3"]], "Concept Lens: Interactive Visualization": [[25, "Concept-Lens:-Interactive-Visualization"]], "Conditional Interventions": [[37, "Conditional-Interventions"]], "Content & Learning Objectives": [[28, "Content-&-Learning-Objectives"]], "Continuing the Final Messages": [[35, "Continuing-the-Final-Messages"]], "Control": [[53, null]], "Cross-Prompt Intervention and Batching": [[10, "Cross-Prompt-Intervention-and-Batching"]], "Cross-Prompt Interventions": [[10, "Cross-Prompt-Interventions"]], "Custom Functions": [[37, "Custom-Functions"]], "Deep Floyd (T5 encoder)": [[38, "Deep-Floyd-(T5-encoder)"]], "Demystifying Verbatim Memorization in Large Language Models": [[26, "Demystifying-Verbatim-Memorization-in-Large-Language-Models"]], "Dictionary Learning": [[41, "Dictionary-Learning"]], "Difference in means probe (aka. mean mass / MM)": [[27, "Difference-in-means-probe-(aka.-mean-mass-/-MM)"]], "Diffusion Lens": [[38, "Diffusion-Lens"]], "Direct effect": [[32, "Direct-effect"]], "Distributed Alignment Search (DAS): Searching for Linearly Encoded Concepts in Model Representations": [[29, "Distributed-Alignment-Search-(DAS):-Searching-for-Linearly-Encoded-Concepts-in-Model-Representations"]], "Do Language Models Use Their Depth Efficiently?": [[24, "Do-Language-Models-Use-Their-Depth-Efficiently?"]], "Documentation": [[2, "documentation"], [49, "documentation"]], "Early Stopping": [[11, "Early-Stopping"], [37, "Early-Stopping"]], "Enter DAS - automatically finding relevant linear subspaces": [[29, "Enter-DAS---automatically-finding-relevant-linear-subspaces"]], "Example: Live-streaming remote chat": [[22, "Example:-Live-streaming-remote-chat"], [37, "Example:-Live-streaming-remote-chat"]], "Exercise (optional) - generate your own antonym pairs": [[28, "Exercise-(optional)---generate-your-own-antonym-pairs"]], "Exercise - calculate the function vector": [[28, "Exercise---calculate-the-function-vector"]], "Exercise - combine the last two functions": [[28, "Exercise---combine-the-last-two-functions"]], "Exercise - compute change in accuracy": [[28, "Exercise---compute-change-in-accuracy"]], "Exercise - forward pass on antonym dataset": [[28, "Exercise---forward-pass-on-antonym-dataset"]], "Exercise - generalize results to another task (optional)": [[28, "Exercise---generalize-results-to-another-task-(optional)"]], "Exercise - implement calculate_fn_vectors_and_intervene": [[28, "Exercise---implement-calculate_fn_vectors_and_intervene"]], "Exercise - intervene with function vector, in multi-token generation": [[28, "Exercise---intervene-with-function-vector,-in-multi-token-generation"]], "Exercise - intervene with h": [[28, "Exercise---intervene-with-h"]], "Exercise - replicate the steering vector results": [[28, "Exercise---replicate-the-steering-vector-results"]], "Exercise - visualize attention heads": [[28, "Exercise---visualize-attention-heads"]], "Exposing memorization of MMLU": [[26, "Exposing-memorization-of-MMLU"]], "Extensions of the Function Vectors Paper": [[28, "Extensions-of-the-Function-Vectors-Paper"]], "Extensions of the Steering Vectors Post": [[28, "Extensions-of-the-Steering-Vectors-Post"]], "Extracting & using FVs": [[28, "Extracting-&-using-FVs"]], "Features": [[8, "features"]], "Function Vectors": [[28, "Function-Vectors"]], "Functions, Methods, and Operations": [[37, "Functions,-Methods,-and-Operations"]], "GPT-2 Model Architecture": [[39, "GPT-2-Model-Architecture"]], "Generator Output": [[28, "Generator-Output"]], "Get Started": [[53, null]], "Getting": [[12, "Getting"], [37, "Getting"]], "Getting Involved!": [[37, "Getting-Involved!"]], "Getting Started": [[50, "getting-started"]], "Gradients": [[13, "Gradients"], [37, "Gradients"]], "How do I use NNsight?": [[0, "how-do-i-use-nnsight"]], "How to Use": [[10, "How-to-Use"], [11, "How-to-Use"], [12, "How-to-Use"], [13, "How-to-Use"], [14, "How-to-Use"], [15, "How-to-Use"], [16, "How-to-Use"], [17, "How-to-Use"], [18, "How-to-Use"], [19, "How-to-Use"], [20, "How-to-Use"], [21, "How-to-Use"]], "ICL Dataset": [[28, "ICL-Dataset"]], "ICL Task": [[28, "ICL-Task"]], "IOI Task Setup": [[31, "IOI-Task-Setup"]], "Important syntax": [[28, "Important-syntax"]], "In-place setting": [[19, "In-place-setting"]], "Indicating the Start of a Response": [[35, "Indicating-the-Start-of-a-Response"]], "Indirect effect": [[32, "Indirect-effect"]], "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model": [[28, "Inference-Time-Intervention:-Eliciting-Truthful-Answers-from-a-Language-Model"]], "Install NNsight": [[36, "Install-NNsight"]], "Installation": [[50, "installation"]], "Integrated Gradients": [[24, "Integrated-Gradients"]], "Interactive Visualization": [[25, "Interactive-Visualization"]], "Interchange interventions": [[34, "Interchange-interventions"]], "Interpreting our patching results": [[26, "Interpreting-our-patching-results"]], "Intervening on Gradients": [[13, "Intervening-on-Gradients"]], "Intervening on a causal graph": [[34, "Intervening-on-a-causal-graph"]], "Interventions on vLLM models": [[23, "Interventions-on-vLLM-models"]], "Introduction": [[28, "Introduction"], [38, "Introduction"], [39, "Introduction"]], "Iterative Interventions": [[37, "Iterative-Interventions"]], "Key-Value Caching": [[28, "Key-Value-Caching"]], "Known Issues": [[23, "Known-Issues"]], "LLM Fine Tuning": [[40, "LLM-Fine-Tuning"]], "LanguageModel": [[37, "LanguageModel"]], "Let\u2019s set up a causal model": [[34, "Let's-set-up-a-causal-model"]], "Limitations": [[30, "Limitations"]], "LoRA for Sentiment Analysis": [[40, "LoRA-for-Sentiment-Analysis"]], "Load Model": [[38, "Load-Model"], [38, "id1"], [38, "id4"], [38, "id7"]], "Logistic regression probe (LR)": [[27, "Logistic-regression-probe-(LR)"]], "Logit Lens": [[24, "Logit-Lens"], [39, "Logit-Lens"]], "Looping across sessions": [[37, "Looping-across-sessions"]], "Main Tutorials": [[53, "main-tutorials"]], "Making surgical edits - residual streams capture too much information": [[29, "Making-surgical-edits---residual-streams-capture-too-much-information"]], "Measuring the effect of the layer on future computations": [[24, "Measuring-the-effect-of-the-layer-on-future-computations"]], "Mini Paper Tutorials": [[1, "mini-paper-tutorials"]], "Model Editing": [[14, "Model-Editing"], [37, "Model-Editing"]], "Model Training": [[35, "Model-Training"]], "Model config": [[28, "Model-config"]], "Model outputs": [[28, "Model-outputs"]], "Modules": [[15, "Modules"]], "Multi-Task DAS": [[29, "Multi-Task-DAS"]], "Multi-token generation": [[28, "Multi-token-generation"]], "Multiple Templates": [[35, "Multiple-Templates"]], "Multiple Token Generation": [[16, "Multiple-Token-Generation"], [37, "Multiple-Token-Generation"]], "Neural networks are causal models too!": [[32, "Neural-networks-are-causal-models-too!"]], "Next Steps": [[0, "next-steps"], [37, "Next-Steps"], [50, "next-steps"]], "Next steps: Run your own experiment with NDIF and NNsight": [[36, "Next-steps:-Run-your-own-experiment-with-NDIF-and-NNsight"]], "Not in-place setting": [[19, "Not-in-place-setting"]], "Note: IOI Task": [[30, "Note:-IOI-Task"]], "Note: Optimize workflow with NNsight batching": [[30, "Note:-Optimize-workflow-with-NNsight-batching"]], "Notes": [[13, "Notes"]], "Operations on causal graphs": [[34, "Operations-on-causal-graphs"]], "Order Matters": [[19, "Order-Matters"]], "Other tips / notes": [[28, "Other-tips-/-notes"]], "Output vs input": [[28, "Output-vs-input"]], "Padding": [[28, "Padding"]], "Paraphrasing a piece of code": [[25, "Paraphrasing-a-piece-of-code"]], "Paraphrasing a sentence": [[25, "Paraphrasing-a-sentence"]], "Patching Experiment": [[30, "Patching-Experiment"]], "Patching Results": [[25, "Patching-Results"]], "Polysemanticity": [[41, "Polysemanticity"]], "Predict": [[53, null]], "Prepare Data": [[40, "Prepare-Data"]], "Prepare our Model": [[40, "Prepare-our-Model"]], "Putting this into practice": [[28, "Putting-this-into-practice"]], "Red-teaming language models via activation engineering": [[28, "Red-teaming-language-models-via-activation-engineering"]], "Register here for a free API key!": [[36, "Register-here-for-a-free-API-key!"]], "Related": [[10, "Related"], [12, "Related"], [13, "Related"], [14, "Related"], [18, "Related"], [19, "Related"], [20, "Related"], [21, "Related"]], "Relative contributions and cosine similarities": [[24, "Relative-contributions-and-cosine-similarities"]], "Remote Attribution Patching": [[31, "Remote-Attribution-Patching"], [31, "id1"]], "Remote Execution": [[17, "Remote-Execution"]], "Remote Model Access": [[50, "remote-model-access"]], "Remote Setup": [[31, "Remote-Setup"]], "Remote execution": [[28, "Remote-execution"], [37, "Remote-execution"]], "Report Issues": [[2, "report-issues"], [8, "report-issues"], [52, "report-issues"]], "Residual erasure experiment": [[24, "Residual-erasure-experiment"]], "Run Diffusion Lens": [[38, "Run-Diffusion-Lens"], [38, "id2"], [38, "id5"], [38, "id8"]], "Sampled Token Traceability": [[23, "Sampled-Token-Traceability"]], "Sampling": [[28, "Sampling"]], "Scan & Validate": [[28, "Scan-&-Validate"]], "Scan and Validate": [[18, "Scan-and-Validate"], [37, "Scan-and-Validate"]], "Sessions": [[37, "Sessions"]], "Setting": [[19, "Setting"], [37, "Setting"]], "Setup": [[22, "Setup"], [23, "Setup"], [24, "Setup"], [30, "Setup"], [31, "Setup"], [34, "Setup"], [35, "Setup"], [37, "Setup"], [38, "Setup"], [39, "Setup"], [40, "Setup"], [41, "Setup"]], "Setup code": [[28, "Setup-code"]], "Sign up for NDIF remote model access": [[36, "Sign-up-for-NDIF-remote-model-access"]], "Skipping Modules": [[20, "Skipping-Modules"]], "Source Code Interventions": [[21, "Source-Code-Interventions"]], "Sparse Autoencoders": [[41, "Sparse-Autoencoders"]], "Stable Diffusion 1.5 (CLIP encoder)": [[38, "Stable-Diffusion-1.5-(CLIP-encoder)"]], "Status": [[51, "status"]], "Steering Llama 2 via Contrastive Activation Addition": [[28, "Steering-Llama-2-via-Contrastive-Activation-Addition"]], "Steering model behaviour": [[28, "Steering-model-behaviour"]], "Step 1: Clean Run": [[30, "Step-1:-Clean-Run"]], "Step 2: Corrupted Run": [[30, "Step-2:-Corrupted-Run"]], "Step 3: Activation Patching Intervention": [[30, "Step-3:-Activation-Patching-Intervention"]], "Streaming": [[22, "Streaming"], [37, "Streaming"]], "Submit Your Own Ideas!": [[1, "submit-your-own-ideas"]], "Suggested paper replications": [[28, "Suggested-paper-replications"]], "Summary": [[10, "Summary"], [11, "Summary"], [12, "Summary"], [13, "Summary"], [14, "Summary"], [15, "Summary"], [16, "Summary"], [17, "Summary"], [18, "Summary"], [19, "Summary"], [20, "Summary"], [21, "Summary"]], "Task-encoding vector": [[28, "Task-encoding-vector"]], "Testing our model on MMLU": [[26, "Testing-our-model-on-MMLU"]], "The API for a transparent science on black-box AI": [[37, "The-API-for-a-transparent-science-on-black-box-AI"]], "The Decoded Vocabulary of Function Vectors (3.2)": [[28, "The-Decoded-Vocabulary-of-Function-Vectors-(3.2)"]], "The Dual-Route Model of Induction": [[25, "The-Dual-Route-Model-of-Induction"]], "The Geometry of Truth": [[27, "The-Geometry-of-Truth"]], "Time Saving": [[11, "Time-Saving"]], "Token Lens: Interactive Visualization": [[25, "Token-Lens:-Interactive-Visualization"]], "Tokenizers": [[28, "Tokenizers"]], "Total effect": [[32, "Total-effect"]], "Tracing Context": [[37, "Tracing-Context"]], "Training a LoRA": [[37, "Training-a-LoRA"]], "Trying on a bigger model": [[30, "Trying-on-a-bigger-model"]], "Tutorials": [[52, "tutorials"]], "Understand": [[53, null]], "Using multiple invokes": [[28, "Using-multiple-invokes"]], "Using nnsight for multi-token generation": [[28, "Using-nnsight-for-multi-token-generation"]], "Vector Algebra on Function Vectors (3.3)": [[28, "Vector-Algebra-on-Function-Vectors-(3.3)"]], "Visualization": [[41, "Visualization"]], "Visualize Results": [[30, "Visualize-Results"], [38, "Visualize-Results"], [38, "id3"], [38, "id6"], [38, "id9"]], "Visualizing GPT-2 Layer Interpretations": [[39, "Visualizing-GPT-2-Layer-Interpretations"]], "Walkthrough": [[37, "Walkthrough"]], "What happens behind the scenes?": [[0, "what-happens-behind-the-scenes"]], "What\u2019s a causal model?": [[34, "What's-a-causal-model?"]], "When to Use": [[11, "When-to-Use"], [12, "When-to-Use"], [13, "When-to-Use"], [14, "When-to-Use"], [15, "When-to-Use"], [16, "When-to-Use"], [17, "When-to-Use"], [18, "When-to-Use"], [19, "When-to-Use"], [20, "When-to-Use"], [21, "When-to-Use"]], "Where to Use": [[10, "Where-to-Use"]], "Which objects to save": [[28, "Which-objects-to-save"]], "With Autoencoder": [[41, "With-Autoencoder"]], "Without Autoencoder (optional comparison)": [[41, "Without-Autoencoder-(optional-comparison)"]], "nnsight": [[9, "nnsight"]], "nnsight.contexts": [[42, "nnsight-contexts"]], "nnsight.intervention": [[3, "module-nnsight.intervention.protocols"], [43, "module-nnsight.intervention"]], "nnsight.local()": [[22, "nnsight.local()"], [37, "nnsight.local()"]], "nnsight.modeling": [[4, "nnsight-modeling"]], "nnsight.models": [[44, "nnsight-models"]], "nnsight.module": [[45, "nnsight-module"]], "nnsight.patching": [[46, "nnsight-patching"]], "nnsight.schema": [[5, "module-nnsight.schema"]], "nnsight.tracing": [[6, "nnsight-tracing"], [47, "nnsight-tracing"]], "nnsight.util": [[7, "module-nnsight.util"], [48, "module-nnsight.util"]], "using .all()": [[37, "using-.all()"]], "vLLM Support": [[23, "vLLM-Support"]], "\u2606 Bonus": [[28, "\u2606-Bonus"], [28, "id10"]], "\u27a1\ufe0f Let\u2019s scale things up! Memorized MMLU examples": [[26, "\u27a1\ufe0f-Let's-scale-things-up!-Memorized-MMLU-examples"]], "\u27a1\ufe0f Let\u2019s scale things up! Steering Llama-70B on NDIF": [[27, "\u27a1\ufe0f-Let's-scale-things-up!-Steering-Llama-70B-on-NDIF"]]}, "docnames": ["about", "applied_tutorials", "documentation", "documentation/intervention", "documentation/modeling", "documentation/schema", "documentation/tracing", "documentation/util", "features", "index", "notebooks/features/cross_prompt", "notebooks/features/early_stopping", "notebooks/features/getting", "notebooks/features/gradients", "notebooks/features/model_editing", "notebooks/features/modules", "notebooks/features/multiple_token", "notebooks/features/remote_execution", "notebooks/features/scan_validate", "notebooks/features/setting", "notebooks/features/skip", "notebooks/features/source", "notebooks/features/streaming", "notebooks/features/vllm_support", "notebooks/mini-papers/csordas_llm_depth", "notebooks/mini-papers/feucht_dual_route_induction", "notebooks/mini-papers/huang_demystifying_memorization", "notebooks/mini-papers/marks_geometry_of_truth", "notebooks/mini-papers/todd_function_vectors", "notebooks/tutorials/causal_mediation_analysis/DAS", "notebooks/tutorials/causal_mediation_analysis/activation_patching", "notebooks/tutorials/causal_mediation_analysis/attribution_patching", "notebooks/tutorials/causal_mediation_analysis/causal_mediation_analysis_i", "notebooks/tutorials/causal_mediation_analysis/causal_mediation_analysis_ii", "notebooks/tutorials/causal_mediation_analysis/causal_models_intro", "notebooks/tutorials/get_started/chat_templates", "notebooks/tutorials/get_started/start_remote_access", "notebooks/tutorials/get_started/walkthrough", "notebooks/tutorials/probing/diffusion_lens", "notebooks/tutorials/probing/logit_lens", "notebooks/tutorials/steering/LoRA_tutorial", "notebooks/tutorials/steering/dict_learning", "sourcelatex/documentation/contexts", "sourcelatex/documentation/intervention", "sourcelatex/documentation/models", "sourcelatex/documentation/module", "sourcelatex/documentation/patching", "sourcelatex/documentation/tracing", "sourcelatex/documentation/util", "sourcelatex/index", "start", "status", "tutorials", "walkthroughs"], "envversion": {"nbsphinx": 4, "sphinx": 61, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1}, "filenames": ["about.rst", "applied_tutorials.rst", "documentation.rst", "documentation/intervention.rst", "documentation/modeling.rst", "documentation/schema.rst", "documentation/tracing.rst", "documentation/util.rst", "features.rst", "index.rst", "notebooks/features/cross_prompt.ipynb", "notebooks/features/early_stopping.ipynb", "notebooks/features/getting.ipynb", "notebooks/features/gradients.ipynb", "notebooks/features/model_editing.ipynb", "notebooks/features/modules.ipynb", "notebooks/features/multiple_token.ipynb", "notebooks/features/remote_execution.ipynb", "notebooks/features/scan_validate.ipynb", "notebooks/features/setting.ipynb", "notebooks/features/skip.ipynb", "notebooks/features/source.ipynb", "notebooks/features/streaming.ipynb", "notebooks/features/vllm_support.ipynb", "notebooks/mini-papers/csordas_llm_depth.ipynb", "notebooks/mini-papers/feucht_dual_route_induction.ipynb", "notebooks/mini-papers/huang_demystifying_memorization.ipynb", "notebooks/mini-papers/marks_geometry_of_truth.ipynb", "notebooks/mini-papers/todd_function_vectors.ipynb", "notebooks/tutorials/causal_mediation_analysis/DAS.ipynb", "notebooks/tutorials/causal_mediation_analysis/activation_patching.ipynb", "notebooks/tutorials/causal_mediation_analysis/attribution_patching.ipynb", "notebooks/tutorials/causal_mediation_analysis/causal_mediation_analysis_i.ipynb", "notebooks/tutorials/causal_mediation_analysis/causal_mediation_analysis_ii.ipynb", "notebooks/tutorials/causal_mediation_analysis/causal_models_intro.ipynb", "notebooks/tutorials/get_started/chat_templates.ipynb", "notebooks/tutorials/get_started/start_remote_access.ipynb", "notebooks/tutorials/get_started/walkthrough.ipynb", "notebooks/tutorials/probing/diffusion_lens.ipynb", "notebooks/tutorials/probing/logit_lens.ipynb", "notebooks/tutorials/steering/LoRA_tutorial.ipynb", "notebooks/tutorials/steering/dict_learning.ipynb", "sourcelatex/documentation/contexts.rst", "sourcelatex/documentation/intervention.rst", "sourcelatex/documentation/models.rst", "sourcelatex/documentation/module.rst", "sourcelatex/documentation/patching.rst", "sourcelatex/documentation/tracing.rst", "sourcelatex/documentation/util.rst", "sourcelatex/index.rst", "start.rst", "status.rst", "tutorials.rst", "walkthroughs.rst"], "indexentries": {"add() (nnsight.util.patcher method)": [[7, "nnsight.util.Patcher.add", false], [48, "nnsight.util.Patcher.add", false]], "apply() (in module nnsight.util)": [[7, "nnsight.util.apply", false], [48, "nnsight.util.apply", false]], "applyn() (in module nnsight.util)": [[7, "nnsight.util.applyn", false], [48, "nnsight.util.applyn", false]], "fetch_attr() (in module nnsight.util)": [[7, "nnsight.util.fetch_attr", false], [48, "nnsight.util.fetch_attr", false]], "forward() (nnsight.util.wrappermodule method)": [[7, "nnsight.util.WrapperModule.forward", false], [48, "nnsight.util.WrapperModule.forward", false]], "module": [[3, "module-nnsight.intervention.contexts", false], [3, "module-nnsight.intervention.graph", false], [3, "module-nnsight.intervention.protocols", false], [5, "module-nnsight.schema", false], [7, "module-nnsight.util", false], [43, "module-nnsight.intervention", false], [48, "module-nnsight.util", false]], "nnsight.intervention": [[43, "module-nnsight.intervention", false]], "nnsight.intervention.contexts": [[3, "module-nnsight.intervention.contexts", false]], "nnsight.intervention.graph": [[3, "module-nnsight.intervention.graph", false]], "nnsight.intervention.protocols": [[3, "module-nnsight.intervention.protocols", false]], "nnsight.schema": [[5, "module-nnsight.schema", false]], "nnsight.util": [[7, "module-nnsight.util", false], [48, "module-nnsight.util", false]], "obj (nnsight.util.patch attribute)": [[7, "nnsight.util.Patch.obj", false], [48, "nnsight.util.Patch.obj", false]], "parent (nnsight.util.patch attribute)": [[7, "nnsight.util.Patch.parent", false], [48, "nnsight.util.Patch.parent", false]], "patch (class in nnsight.util)": [[7, "nnsight.util.Patch", false], [48, "nnsight.util.Patch", false]], "patch() (nnsight.util.patch method)": [[7, "nnsight.util.Patch.patch", false], [48, "nnsight.util.Patch.patch", false]], "patcher (class in nnsight.util)": [[7, "nnsight.util.Patcher", false], [48, "nnsight.util.Patcher", false]], "patches (nnsight.util.patcher attribute)": [[7, "nnsight.util.Patcher.patches", false], [48, "nnsight.util.Patcher.patches", false]], "replacement (nnsight.util.patch attribute)": [[7, "nnsight.util.Patch.replacement", false], [48, "nnsight.util.Patch.replacement", false]], "restore() (nnsight.util.patch method)": [[7, "nnsight.util.Patch.restore", false], [48, "nnsight.util.Patch.restore", false]], "wrappermodule (class in nnsight.util)": [[7, "nnsight.util.WrapperModule", false], [48, "nnsight.util.WrapperModule", false]]}, "objects": {"nnsight": [[43, 0, 0, "-", "intervention"], [5, 0, 0, "-", "schema"], [48, 0, 0, "-", "util"]], "nnsight.intervention": [[3, 0, 0, "-", "contexts"], [3, 0, 0, "-", "graph"], [3, 0, 0, "-", "protocols"]], "nnsight.util": [[48, 1, 1, "", "Patch"], [48, 1, 1, "", "Patcher"], [48, 1, 1, "", "WrapperModule"], [48, 4, 1, "", "apply"], [48, 4, 1, "", "applyn"], [48, 4, 1, "", "fetch_attr"]], "nnsight.util.Patch": [[48, 2, 1, "", "obj"], [48, 2, 1, "", "parent"], [48, 3, 1, "", "patch"], [48, 2, 1, "", "replacement"], [48, 3, 1, "", "restore"]], "nnsight.util.Patcher": [[48, 3, 1, "", "add"], [48, 2, 1, "", "patches"]], "nnsight.util.WrapperModule": [[48, 3, 1, "", "forward"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:function"}, "terms": {"": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 53], "0": [0, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 34, 36, 37, 38, 39, 40, 41], "00": [17, 18, 22, 23, 26, 27, 28, 30, 31, 37, 38, 40], "000": 25, "0000": [17, 19, 22, 23, 31, 36, 37, 40], "000000953674316": 32, "0000e": 40, "00018062107847072184": 33, "00032852389267645776": 33, "000678597076330334": 33, "0012355081271380186": 33, "0015e": 18, "001a85ce554d": 37, "0020e": 40, "0025e": 18, "003": 40, "0031e": 18, "0035e": 18, "0039e": 40, "0041e": 18, "0049e": [18, 40], "0051e": 21, "0058e": 18, "0059e": 18, "006": 40, "0061": 40, "0063": 40, "0064e": 18, "006500244140625": 30, "0068": 11, "0074e": 18, "0075e": 18, "0076": 40, "0078": [37, 40], "0078e": 40, "0081": 40, "0084": 40, "0085": 40, "0086e": 18, "0088": [37, 40], "0089": 40, "009": 40, "0090": 40, "0092": 40, "0093": 40, "0094e": 18, "0096": [12, 40], "00df": 24, "01": [18, 21, 29, 37, 40], "0100": 40, "0109": 40, "011": [36, 40], "0111": 29, "0112": 40, "0113": 11, "0114": 15, "0114e": [18, 21], "0115": 40, "0118": 40, "0119": 40, "0121": 40, "0122e": 21, "0125e": 40, "0126": 40, "0129": 40, "013": 37, "01300048828125": 30, "0131": 40, "0131e": 21, "0132": 40, "0132e": 18, "0133": 19, "0134": 40, "0135": 40, "0138": 19, "013899803161621": 32, "014": 40, "0141": 40, "0144": 40, "0145": 40, "0146e": 21, "0148": 40, "0148e": 21, "015": 24, "0150": 11, "0156": [37, 40], "0156e": [37, 40], "0159": 40, "0160": 40, "0161": 40, "0162e": 18, "0164": 40, "0165e": 18, "0166": 40, "0167": 40, "0171": 40, "0176": 40, "0177e": 21, "0182": 40, "0186": 40, "019": 26, "0190": 40, "01953125": 30, "0196": 37, "01mb": 22, "02": [17, 18, 21, 28, 29, 30, 31, 36, 37, 40], "020": 40, "0200": 40, "0204": 40, "0206": 29, "0210": 40, "0210e": 18, "0211": 40, "0213e": 21, "0214": 40, "0215e": 40, "0216": 40, "0219": 40, "0220": 40, "0222e": 18, "0223": 40, "0225": 40, "0227": 40, "023": [37, 40], "0232": 40, "0232e": 21, "0233": 15, "0234": 40, "0234e": 40, "0235e": 18, "0236e": 18, "0237": 40, "0238": 40, "0239": 40, "0240e": 21, "0242": 40, "0243": 40, "0244": 40, "0247": 40, "0249": 40, "0250": 40, "0250e": 40, "0251": 40, "0253": 40, "0254e": 40, "0255": 40, "0260": 40, "0260009765625": 30, "0262": 40, "0265": 40, "0266": 40, "0269": 40, "0269e": 18, "027": 40, "0270": 40, "0271e": 18, "0272": 40, "0273": 40, "0273e": 40, "0278": 40, "028": 37, "0281": 29, "0282": 40, "0284": 40, "0287": 40, "0287e": 21, "0288": 40, "0289": 40, "0293": 40, "0294": 40, "0295": [11, 40], "0298": 40, "0299": 40, "03": [18, 21, 22, 24, 28, 37, 40], "030": 40, "0303": 40, "0304": 40, "0306": 40, "0306e": 18, "0309": 40, "0309e": 18, "0310": 40, "0311e": 18, "0312": [37, 40], "0312e": 40, "0315": 40, "0315e": [21, 40], "032470703125": 30, "0325": 40, "0326e": 18, "0327": 40, "033": [31, 40], "0330": 40, "0332": 40, "0332e": 40, "0334": 40, "0336e": 18, "0337": 40, "0342": 40, "0344": 40, "0345e": 18, "0346": 29, "0347": 40, "035": 37, "0352": [37, 40], "0354": 40, "0359": 40, "036": 40, "0361": 40, "0362e": 18, "0364": 40, "0366": 40, "0368e": 18, "0371": 40, "0376": 40, "0378": 40, "0381": 40, "0383": 40, "0386": 40, "0390625": 30, "0391": [37, 40], "0391e": 40, "0396": 40, "0398": 40, "03mb": 37, "04": [21, 26, 30, 31, 37, 40], "0400": 40, "0403": 40, "0404e": [18, 21], "0405": 40, "0410e": 18, "0413": 40, "0414b4df": 37, "0417": 40, "0418": 12, "0420": 40, "0422": 40, "0425": 40, "0425e": 40, "0427": 40, "0430": 40, "0430e": 40, "0432": 40, "0435": 40, "0437": 40, "0437e": 40, "0439": 40, "044": 40, "0442": 40, "0443e": 18, "0444": 40, "0447": 40, "0449": 40, "0452": 37, "0454": 40, "0457": 40, "0459e": 21, "0461": 40, "0464e": 21, "0469": [37, 40], "0469e": 40, "0470": 11, "0471": 40, "0475": 37, "0479": 40, "0479e": 18, "048": 40, "0481": [12, 40], "0481e": 18, "0483": 40, "0484e": 18, "0486": 40, "049": 40, "0491": 40, "0493": 40, "0498": 40, "0498e": 40, "05": [23, 24, 26, 27, 28, 29, 30, 31, 36, 37, 39, 40], "0500": 40, "0502e": 18, "0505": [12, 40], "0505e": 21, "0508": 40, "0508e": 40, "051": 40, "0510": 40, "0510e": 18, "0513": 40, "0517e": 21, "0518": 40, "0518e": [18, 40], "052001953125": 30, "0522": 40, "0525": 40, "0525e": [18, 21], "0527": 40, "0528": 12, "053": [26, 40], "0535": 40, "0536e": 18, "0537": 40, "0538e": 18, "0542": 40, "0544": 40, "0544e": 18, "0547": [36, 37, 40], "0547e": 40, "0549": 40, "0552": 40, "0554": 40, "0557": 40, "0559": 40, "0559e": 40, "0566": 37, "0566e": 40, "0569": 40, "0571": 40, "0572e": 18, "0574": 40, "0579e": 18, "0581": 40, "0583": 40, "058349609375": 30, "0586": [37, 40], "0588": [12, 40], "0593": 40, "0595e": [18, 21], "0596": 40, "0596e": 40, "0598": 37, "0599": 15, "05mb": 31, "06": [28, 29, 31, 40], "060": 22, "0605": 40, "0605e": 18, "0608": 40, "0609e": 18, "061": 40, "0615": [37, 40], "0618": 40, "0620": 40, "0623": 40, "0625": [23, 37, 40], "0625e": 40, "063": [24, 40], "0630": 40, "0630e": 40, "0635": 40, "0635e": 18, "0640": 40, "0642e": 18, "0645": [37, 40], "0645e": [18, 37, 40], "06494140625": 30, "065": 40, "0654": 40, "0655942884453795": 33, "0656e": 21, "0659": 40, "0664": 40, "0664e": [18, 40], "0669": 40, "0669e": 18, "067": 40, "0672e": 21, "0673e": 18, "0674": 40, "0674e": 18, "0677e": 18, "0679": 40, "0679e": 18, "0682": 12, "0682e": 18, "0684": 40, "0687": 12, "0688": 37, "0689e": 18, "0693e": 40, "0698": 40, "0698e": 18, "0699e": 18, "07": [17, 24, 25, 26, 27, 29, 31, 37, 40], "0703": [36, 37, 40], "0703e": 40, "0708": 40, "071": 40, "0710e": 18, "0712890625": 30, "0713": [37, 40], "0713e": 21, "0716e": 21, "0718": [37, 40], "0723": [37, 40], "0723e": 18, "0726": 11, "0728": 40, "0730e": 40, "0732": [37, 40], "0737": [37, 40], "0738e": 18, "0742": 40, "0746e": 18, "0747": 40, "0748": 37, "0750e": 40, "0752": 40, "0752e": 40, "0757": 40, "0761e": 18, "0762": [37, 40], "0767": 40, "0768e": 18, "0769e": 18, "0771": 40, "0771e": 21, "0776": 40, "0776e": 18, "078": [36, 40], "0780e": 18, "0781": [37, 40], "078125": 30, "0781e": 40, "0786": 40, "079": 40, "0791": 40, "0791e": 40, "07920493": 27, "0794": 15, "0796": [17, 40], "07c4d2b952bb": 37, "08": [17, 29, 36, 40], "0801": 40, "0803e": 18, "0806": 40, "0807e": 18, "081": 40, "0811": 40, "0812e": 21, "0814e": 18, "0815": 40, "0816e": 18, "0819e": 18, "0820": 40, "0820e": 40, "0821e": 18, "0822e": 18, "0825": 40, "0826e": 18, "0830": 40, "0834e": 18, "084": 40, "0840": 40, "0845": 40, "0845e": 21, "0850": 40, "0854": 40, "0859": [36, 40], "0859e": 40, "086": 37, "0864": 40, "0869": 40, "087": 40, "0872e": 40, "0874": 40, "0874e": 40, "0879": 40, "0879e": 18, "0883e": 18, "0884": 40, "0889": 40, "0889e": [18, 40], "0894": 40, "0898": 40, "0898e": 40, "09": [29, 40], "0902e": 18, "0903": 40, "0904": 37, "0906e": 18, "0907e": 18, "0908": 40, "0908203125": 30, "0912e": 18, "0913": 40, "0918": 40, "092": 37, "0923": 40, "0927e": 21, "0930e": 21, "0931e": 18, "0933": 40, "0938": [17, 36, 37, 40], "0938e": [37, 40], "094": [24, 26], "0942": 40, "0947": 40, "0950e": 18, "0952": 40, "0952e": 18, "0954e": 21, "0957": 40, "0958e": 18, "0962": 40, "0963e": 18, "0965e": 18, "09716796875": 30, "0972": 40, "0973e": 18, "0977": 40, "0981": 40, "0985e": 18, "0986": 40, "0991": 40, "0992e": 18, "0996": 40, "0996e": 40, "0bb0": 37, "0e72f03d08da": 37, "0f246c75a359": 37, "0nl_h2cd54q90chs9hf0n5qr0000gn": 37, "0th": [19, 37], "0x790b98b1b910": 35, "0x7edbe8693e50": 28, "1": [0, 1, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 29, 34, 36, 39, 40, 41, 48, 50, 51, 53], "10": [0, 14, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40], "100": [17, 18, 22, 23, 25, 26, 27, 28, 30, 31, 32, 37, 38, 40], "1000": 28, "100000381469727": 32, "1001": 40, "1002e": 21, "1003e": 18, "1006": 40, "101": [22, 23, 37], "1011": 40, "1011e": 18, "10134": 25, "1016": [37, 40], "1016e": 40, "1019": 13, "102": 37, "1021": 40, "1024": [23, 24, 27, 30, 31, 36, 37, 39, 40], "1025": 40, "1029e": 21, "103": [37, 40], "1030": 40, "1031e": 18, "1032e": 18, "1035": 40, "1035e": 40, "104": [13, 37], "1040": 40, "10400390625": 30, "1041e": 18, "105": [15, 31, 40], "1050": 40, "1055": 40, "1055e": 40, "106": 15, "1060": 40, "1060e": 21, "1061e": 18, "1069": 40, "107": 23, "1070e": 18, "1074": 40, "1077e": 18, "1078e": 18, "1079": 40, "1079e": 18, "108": [15, 23, 40], "1084": 40, "1085e": 18, "1088": 13, "1089": 40, "109": 23, "1090e": 18, "1094": [37, 40], "1094e": 40, "10_32768": 41, "10k": 25, "10th": 27, "11": [0, 14, 16, 17, 18, 19, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40], "110": 15, "1103515625": 30, "1104": 40, "1104e": 21, "1108": 40, "111": [15, 18, 23, 37, 40], "1113": 40, "1116e": 18, "1118": 40, "1120e": 21, "1123": 40, "1124e": 18, "112577": 21, "1125e": 40, "1126e": 18, "1128": 40, "113": [15, 18, 37], "1133": [37, 40], "1138": 40, "114": [15, 18, 37], "1143": 40, "1144e": 21, "1146e": 18, "1147": 40, "1147e": 18, "114a": 22, "115": [18, 23, 37], "1152": 40, "1157": 40, "116": [18, 23, 37], "1162": 40, "11669921875": 30, "1167": 40, "1169e": 40, "117": [18, 37], "1172": 40, "1172e": 40, "1175e": 21, "1177": 40, "118": [18, 37], "1182": [37, 40], "1182e": 40, "1187": 40, "1191": 40, "1191e": 40, "1196": 40, "1197": 15, "11f29098e96": 36, "11th": 40, "12": [15, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 37, 38, 39, 40], "120": [13, 37], "1201": 40, "1202e": 21, "1206": [15, 40], "1206e": 18, "121": [37, 40], "1211": 40, "1211e": 40, "1212": 28, "1216": 40, "122": [36, 37], "1221": 40, "1224e": 18, "1226": 40, "123": [24, 37], "1230": 40, "1230e": 40, "1234e": 18, "1235": 40, "1235e": 18, "1239": 28, "124": [30, 37], "1240": [15, 40], "1245": 40, "125": [18, 23, 26, 30, 37], "1250": [17, 23, 36, 37, 40], "1250e": 40, "12545": 28, "1254e": 18, "126": [18, 37], "1260": 40, "127": [18, 37, 40], "1270": 40, "1270e": 21, "1276": 28, "1279": 40, "1279e": [18, 40], "128": [18, 25, 30, 31, 35, 37], "1280": 12, "1281e": 40, "128256": [24, 27, 30, 31, 36, 40], "1285e": 18, "1289": 40, "128998123": 38, "1289e": 40, "129": [18, 37], "1291e": 18, "1292e": 21, "1293e": 18, "1296": 37, "1298828125": 30, "1299": 40, "12f11b62de31": 31, "13": [17, 18, 20, 21, 22, 24, 27, 28, 29, 30, 31, 36, 37, 39, 40, 41], "130": [18, 31, 37], "1300": 29, "1301": 37, "1305": 13, "1309": 40, "131": [18, 24, 37, 40], "1315e": 18, "1316e": 21, "1318": 40, "132147685816016": 37, "1321e": 18, "1322": 13, "1324e": 18, "1328": [17, 36, 37, 40], "1328e": 40, "133": [37, 40], "1336e": 18, "1338": 40, "1339e": 18, "133k": 40, "134": 37, "1348": 40, "1349e": 40, "135": [37, 40], "1357": 40, "136": 40, "1367": 40, "1375e": 40, "1377": 40, "1387": 40, "139": 37, "1394e": 18, "1396": 40, "13b": 28, "14": [11, 13, 18, 21, 25, 28, 29, 30, 31, 37, 38, 40, 41], "140": [0, 37, 40], "1406": [17, 37, 40], "1406e": [37, 40], "1408": 11, "141": [18, 37], "1411": 37, "1415e": 18, "1416": 40, "142": [18, 37, 40], "1420e": 18, "1426": 40, "143": [18, 37], "1430e": 18, "14336": [24, 30, 31], "1436": 40, "144": [18, 26, 37, 40], "1443e": 18, "1445": 40, "1445e": 40, "1449e": 21, "145": [18, 37], "1450e": 18, "1455": [36, 40], "1457e": 18, "1459e": 18, "146": 37, "14619173642274605": 33, "1465": 40, "147": [18, 29, 37], "1470e": 18, "1475": 40, "1475e": 40, "1479e": 18, "148": 37, "1484": [37, 40], "1484e": [37, 40], "1485e": 18, "149": [18, 37], "1494": [37, 40], "14mb": 22, "15": [11, 13, 21, 22, 25, 27, 28, 29, 30, 31, 37, 38, 40], "150": [17, 18, 37], "1504": 40, "1504e": 40, "1508e": 18, "151": [25, 40], "1514": 40, "1515e": 18, "1516": 11, "152": [18, 19, 37], "1522e": 18, "1523": 40, "1529": 13, "153": [18, 37], "1533": 40, "1537": [11, 12], "1539e": 18, "154": [18, 37, 40], "1543": [37, 40], "15496": 28, "1553": [19, 40], "1553e": 40, "1554e": 18, "1557e": 18, "1559e": 21, "156": [13, 18, 37], "156082": 27, "1562": [15, 17, 22, 36, 37, 40], "1562e": 40, "1563": 11, "1564e": 21, "157": [18, 37, 40], "1572": [37, 40], "158": [13, 18, 37, 40], "1582": 40, "1582e": [21, 40], "1584": 11, "1587e": 21, "159": [18, 37], "1591e": 18, "1592": 40, "1596e": 18, "1599e": 18, "16": [11, 18, 21, 24, 26, 27, 28, 33, 36, 37, 38, 40], "1602": 40, "1602e": [37, 40], "1606e": 37, "1607e": 18, "161": [37, 40], "1611": 40, "1621": [37, 40], "162109375": 30, "1621e": [18, 40], "1623e": 18, "1625e": 18, "1630e": 21, "1631": 40, "1634": 11, "164": 40, "1641": [36, 40], "1641e": 40, "1646e": 21, "1648e": 18, "1649e": 18, "165": 40, "1650": 40, "166": 40, "1660": 40, "1670": [37, 40], "1676e": 21, "168": 13, "1680": [17, 36, 40], "1680e": 40, "1687": 15, "1688e": 40, "1689": [36, 40], "1690": 12, "1690e": 18, "16940": 23, "1697e": 18, "1699": 40, "16mb": 31, "17": [21, 22, 24, 27, 30, 33, 37, 38, 40], "1709": 40, "1719": [36, 37, 40], "1719e": [37, 40], "1728": 12, "1729": 40, "173": 26, "1734": 37, "1735": 37, "1736": 37, "1736e": 18, "1737": [13, 37], "1738": [37, 40], "1745": 13, "1748": [16, 37, 40], "1750e": 40, "1757": 30, "17578125": 30, "1758": 40, "176": 40, "1766e": 21, "1767e": 18, "1768": 40, "1777": 40, "1777e": 40, "1779e": 18, "1781256d9263": 24, "1782e": 18, "1787": 40, "1788": 37, "1789": 37, "179": 40, "1790": 37, "1791": 37, "1792": 37, "1792e": 18, "1797": [37, 40], "1797e": 40, "1798": 19, "1798e": 18, "18": [18, 21, 24, 26, 27, 33, 36, 37, 38, 40], "1801": 37, "1802": 37, "1803": 37, "1803e": 21, "1804": 37, "1805": 37, "1807": 40, "181": 40, "1816": 40, "181640625": 30, "1817e": 18, "1820e": 40, "1826": 40, "1832e": 18, "1834e": 18, "1836": 40, "1838e": 21, "184": 17, "1840cc1a": 26, "1841e": 21, "1842": 37, "1843": 37, "1844": 37, "1845": 37, "1846": [37, 40], "1847e": 18, "1855": 40, "1865": 40, "1865e": 40, "1875": [17, 23, 36, 37, 40], "1875e": 40, "1879": 28, "1880e": 18, "1882e": 18, "1885": 40, "1889": 22, "189": 40, "1891e": 40, "1895": 40, "1897e": 18, "19": [13, 21, 22, 24, 26, 27, 28, 29, 36, 40], "1904": 40, "191": 40, "1914": 40, "1914e": [18, 40], "192": [27, 40], "1924": 40, "1934": 40, "1936e": 18, "194": 24, "1943": 40, "195": 40, "1951": 13, "1953": 40, "1953e": [21, 40], "196": 40, "1963": 40, "1971": 13, "1973": 40, "1973e": 40, "1978": 28, "1979e": 21, "198": [15, 37, 40], "1980e": 21, "1982": 40, "1982e": 40, "1985e": 21, "1987e": 18, "1988e": 18, "1989e": 21, "1991e": 18, "1992": 40, "1992e": 40, "1994e": 18, "1999e": 18, "1a8dbeb167c0": 26, "1b": [29, 33], "1cad695cd3a9": 40, "1d": 28, "1d6d": 37, "1e": [23, 24, 27, 28, 30, 31, 36, 37, 39, 40], "1f677938": 22, "1k": 37, "1x15x4096": 30, "2": [0, 1, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23, 24, 29, 34, 36, 38, 40, 53], "20": [21, 22, 23, 24, 25, 27, 28, 34, 36, 37, 38, 40, 41], "2002": 40, "2003e": 18, "201": 40, "2012": 40, "2014e": 18, "202": 40, "2020": [25, 33], "2021": [25, 40], "2022": 25, "2023": [25, 27, 28, 35], "2024": [17, 26, 35], "2025": [22, 24, 25, 26, 30, 31, 36, 37, 40], "2026e": 18, "2028e": 18, "203": 40, "2031": [37, 40], "2031e": 40, "2036e": 18, "2041": 40, "2041e": 18, "2048": [28, 29], "2048e": 18, "205": 37, "2051": 40, "2056e": 18, "2059e": 18, "206": 17, "2061": 40, "2061e": 18, "2063e": 21, "207": 26, "2070": 40, "208": 13, "2080": 40, "2085e": [18, 40], "2090": [37, 40], "2097": 13, "2097e": 18, "21": [10, 14, 17, 18, 21, 22, 24, 27, 28, 29, 30, 31, 36, 37, 40], "2100": 40, "2103e": 18, "21077": 30, "2109": [36, 40], "2109e": [18, 40], "211": 40, "2119": 40, "2120e": 21, "2129": 40, "2131e": 21, "2137e": 21, "2139": 40, "214": 40, "2148": 40, "215": [37, 40], "2150e": 18, "2158": 40, "2159e": 18, "216": [37, 40], "2163e": 40, "2168": 40, "2168e": 40, "217": 37, "2178": 40, "218": 37, "2183e": 18, "2188": [36, 37, 40], "2188e": 40, "219": 37, "2193e": 18, "2197": 40, "21mb": 17, "22": [19, 21, 24, 27, 29, 37, 38], "2206": 11, "2207": 40, "2207e": 40, "221": 40, "2217": 40, "221b": 26, "2226e": 18, "2227": [37, 40], "2227e": [18, 40], "2229e": 18, "2232e": 18, "2236": 40, "2236e": 18, "224": [26, 37], "2244e": 21, "2246": 40, "2249e": 21, "225": 24, "2250e": 40, "2256": 40, "2262e": 18, "2263": 12, "2265": 13, "2266": [37, 40], "2266e": 40, "2267e": 18, "2275": 40, "2280e": 18, "2285": [37, 40], "2287e": 18, "2295": 40, "23": [10, 18, 19, 21, 22, 24, 27, 33, 37, 40], "2304": [23, 31], "2305": 40, "231": 40, "2314": 40, "2315e": 18, "2317e": 18, "2324": 40, "2324e": 18, "2326e": 18, "2333984375": 30, "2334": [37, 40], "2336": 11, "2344": [17, 36, 37, 40], "2344e": 40, "2348": [18, 37], "2349": [18, 37], "235": 37, "2350": [18, 37], "2353e": 21, "2354": 40, "2355": 37, "236": 40, "2362e": 18, "2363": 40, "2363e": 40, "2367": 11, "237": [37, 40], "2373": 40, "2375e": 40, "2378e": 21, "238": 13, "2382e": 18, "2383": 40, "2383e": 40, "239": [22, 37], "2391": 12, "2393": 40, "2396": 28, "2397e": 40, "23b7add": 26, "23bf": 31, "24": [10, 19, 21, 24, 27, 28, 29, 38], "240": [13, 22, 37], "2402": [37, 40], "2406e": 18, "241": 40, "2412": 40, "242": [22, 37], "2421e": 18, "2422": [37, 40], "2422e": 40, "243": 24, "2431e": 18, "2432": 40, "244": [22, 37], "2441": 40, "2446e": 21, "2451": 40, "2456": [13, 28], "246": [22, 37], "2461": [36, 40], "2461e": 40, "2465e": 18, "247": [18, 37], "2471": [36, 40], "2471e": 18, "248": [22, 37], "2480": [37, 40], "2487e": 18, "249": [18, 22, 37], "2490": 40, "2490e": 18, "2491e": 21, "2494e": 18, "2496e": 18, "24k": 37, "25": [18, 19, 21, 22, 24, 26, 27, 28, 30, 31, 37], "250": [18, 22, 37], "2500": [17, 23, 36, 37, 40], "2500e": 40, "2504e": 18, "250m": 31, "251": [18, 22, 37], "2513e": 21, "2514e": 18, "2517e": 18, "252": [18, 22, 37], "2520": [36, 40], "2526e": 18, "253": [13, 18, 22, 37], "2539": 40, "2539e": 18, "2549": 13, "255": [22, 37], "2553": 15, "2559": [11, 37, 40], "2559e": 40, "256": [24, 26, 28, 38], "2560": 26, "2560e": 21, "2561e": 40, "2562e": [18, 40], "256f": 26, "257": [15, 37], "2574e": 18, "2578": [17, 36, 37, 40], "2578e": 40, "258": [37, 40], "258k": [22, 37, 40], "259": 40, "2598": 40, "2598e": 40, "25mb": 37, "26": [19, 21, 23, 24, 25, 26, 27, 28, 30, 35, 36, 37, 40], "2606": 13, "261": [24, 40], "2610": 13, "2612": 15, "2613": 29, "2617": [17, 40], "2617e": 40, "262": [15, 16, 23, 28, 37], "2634e": 18, "2635e": 21, "2637": 40, "26399": 25, "264": 40, "2644": 13, "2656": [37, 40], "2656e": 40, "2670e": 18, "2674e": 18, "2676": 40, "2694e": 21, "2695": [37, 40], "2695e": 40, "27": [21, 24, 26, 27, 28, 30, 37, 40], "270": [37, 40], "2709999978542328": 32, "2709e": 18, "270a6e4d": 22, "271": 40, "2715": 40, "272": 30, "273": [22, 29, 37, 40], "2732": 37, "2734": [37, 40], "2734e": [18, 40], "274": [22, 37, 40], "2742": 19, "2744e": 18, "2749": 24, "2749e": 18, "2751e": 18, "2754": 40, "2754e": 40, "2757": 11, "276": [22, 24, 37], "2760e": 18, "277": 37, "2773": 40, "2773e": 40, "2778e95b745f": 37, "278": 40, "2785": 11, "2787e": 18, "279": 40, "2793": 40, "2793e": 40, "2794e": 18, "2799e": 21, "28": [13, 21, 22, 23, 24, 26, 27, 28, 30, 31, 37, 40], "280": [0, 22, 37], "2804e": 18, "2805e": 18, "281": [22, 37, 40], "2812": [37, 40], "2812e": 40, "282": [13, 22, 37], "2823": 19, "283": [22, 37], "2832": 40, "2834e": 18, "2838e": 21, "284": [22, 37], "285": [22, 37], "2852": [36, 40], "2852e": 40, "2855e": 18, "286": [15, 16, 24, 28, 37], "28672": [27, 36, 40], "2869": 15, "2869e": 21, "287": [15, 16, 22, 37], "2871": 40, "2874": 15, "2874e": 18, "2877e": 18, "2879e": 21, "288": 40, "2882e": 18, "2884e": 18, "289": [22, 37], "2891": [37, 40], "2891e": 40, "2899e": 18, "28it": 38, "28mb": 37, "29": [21, 24, 27, 30, 31, 37, 40], "290": [16, 25, 37, 40], "2901": 13, "2903e": 18, "2904e": 18, "2905e": 18, "291": [22, 37], "2910": 40, "2922e": 18, "29255": 25, "2928e": 18, "2929e": 18, "293": [22, 37], "2930": 40, "2933e": 18, "2934e": 18, "2938e": 40, "2949": 40, "2949e": 40, "2950": 15, "2955e": 18, "296": 40, "2960": 12, "2964": 12, "29656": 30, "2969": 40, "2969e": 40, "297": 37, "2979e": 40, "2981e": 18, "2988": 40, "2988e": 18, "299": 24, "2992e": 18, "29a3": 30, "2a": 24, "2ae2": 22, "2b": 24, "2bdc": 24, "2d": 28, "2f": [28, 29], "3": [0, 1, 10, 11, 12, 16, 18, 19, 21, 22, 23, 24, 26, 29, 33, 34, 35, 36, 39, 40, 41, 50, 53], "30": [17, 21, 22, 24, 27, 28, 31, 34, 36, 37, 40], "300": 40, "300000190734863": 32, "3000e": [18, 40], "3005e": 18, "3006e": [18, 21], "3008": 40, "3008e": 40, "3017e": 18, "3019e": 18, "3024": 12, "3025e": 18, "3027": 40, "3030e": 40, "3034e": 18, "3039e": 18, "3043e": 18, "3047": [37, 40], "3047e": 40, "3048e": 21, "3060e": 18, "3061e": 18, "3062e": 40, "3065": [11, 12], "3066": 40, "3066e": 21, "3067e": 21, "307": 28, "3071e": 40, "3072": [23, 27], "3074": 37, "308": 40, "3086": [36, 40], "309": [31, 40], "3095e": 18, "3099": 37, "30ab": 36, "30mb": 37, "31": [21, 24, 28, 30, 31, 37, 40], "310": [25, 40], "3105": 40, "311": 40, "3125": [36, 37, 40], "3125e": 40, "313": 40, "3130486789": 11, "3133e": 21, "3141e": 21, "3144e": 18, "3145": 40, "3145e": 40, "315": 23, "316": 36, "3164": 40, "3164e": 40, "3165e": 18, "3168e": 18, "317": [37, 40], "3176e": 21, "3178e": 18, "318": [15, 16, 37], "3184": 40, "3184e": 40, "3188e": 40, "319": [22, 23], "3190e": 18, "3191e": 18, "3193e": 40, "3199e": 40, "32": [21, 22, 24, 25, 27, 30, 31, 33, 37, 40], "3201": 37, "3203": [36, 37, 40], "3203e": [18, 40], "3205": 11, "321": 40, "3210e": 21, "3216e": 21, "3218e": 18, "322": 25, "3223": 40, "3223e": 21, "3233e": 21, "3238e": 18, "324": 40, "3242": 40, "3242e": 40, "3244e": 21, "3246e": 18, "3250e": 40, "3258e": 18, "326": 31, "3262": 40, "3262e": 40, "3263e": 18, "3268e": 21, "3272e": 18, "3275e": 40, "32768": 41, "328": 40, "3281": [37, 40], "3281e": 40, "3293e": 18, "33": [21, 27, 28, 30, 31, 37, 40], "3301": 40, "3306e": 40, "332": 40, "3320": 40, "3333e": 21, "3335e": 21, "3340": [37, 40], "3346e": 18, "3359": 40, "3359e": 40, "336": 40, "337": [13, 40], "3379": 40, "338": 37, "3398": 40, "3398e": [18, 40], "34": [11, 15, 18, 19, 21, 22, 25, 26, 27, 28, 31, 35, 37, 40], "340": 37, "3404137504": 37, "3405e": 21, "341": 26, "3410e": 18, "3418": 40, "3428e": 40, "3438": [37, 40], "3438e": 40, "344": 31, "3440e": 18, "3449e": 18, "3457": 40, "346": 40, "3467e": 18, "347": 40, "3470e": 18, "3477": 40, "348": 40, "3484e": 21, "349": 40, "3490": 13, "3495e": 18, "3496": [37, 40], "3499e": 18, "35": [15, 21, 27, 28, 31, 37, 40], "3504": 37, "3510e": 18, "3514e": 18, "3516": [17, 37, 40], "3516e": [18, 40], "3517e": 18, "352": 37, "3526e": 18, "3528e": 18, "3535": [37, 40], "3535e": 40, "3536": 37, "354": [24, 40], "355": [24, 40], "3555": 40, "3555e": 40, "356": 40, "3569e": 18, "3570": 11, "3574": 40, "3574e": [18, 40], "3576": 37, "357e3fb9": 31, "358": 40, "3594": [36, 37, 40], "3594e": 40, "3596": 15, "3599e": 21, "35it": 23, "36": [15, 21, 23, 27, 37, 40], "360": [13, 40], "3609e": 18, "3613": 40, "3620e": 18, "3625e": 18, "3627e": 18, "363": 37, "3633": [37, 40], "3633e": [37, 40], "3635": 28, "364": 37, "3648e": 18, "3652": 40, "366": 26, "3661e": 18, "3662e": 18, "3671e": 18, "3672": [17, 40], "3672e": 40, "3681783dcddb": 40, "3682e": 40, "3690e": 18, "3691": [36, 40], "3691e": 40, "36ff46f0": 17, "37": [21, 27, 28, 31, 40], "3701e": [18, 40], "3711": [17, 40], "3711e": 40, "372": 40, "3724e": 18, "3730": 40, "3730e": 40, "3734e": 18, "3741e": 18, "3746e": 18, "375": 40, "3750": [17, 22, 23, 36, 37, 40], "3750e": 40, "3756e": 18, "376": [25, 40], "3760": 15, "3767e": 18, "3770": 40, "378": 37, "3786e": 21, "3789": [37, 40], "379": [24, 37], "3794e": 21, "37m": 37, "38": [15, 21, 22, 28, 31, 37, 40], "380": 37, "3809": 40, "381": 37, "3824e": [18, 21], "3828": [17, 40], "3828e": 40, "3831e": 18, "3834e": 18, "3836e": 18, "384": 40, "3848": 40, "385": 37, "3853e": 18, "3856e": 18, "386": [22, 37], "3867": 40, "387": 37, "3875e": [37, 40], "388": [25, 37], "3880e": 21, "3887": 40, "389": 37, "3891e": 18, "38mb": 31, "39": [9, 10, 11, 12, 13, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 37, 40], "3906": [36, 37, 40], "3906e": 40, "3912e": 21, "3916": 13, "392": 40, "3925e": 18, "3926": 40, "3926e": 40, "3930": 13, "3936e": 40, "3945": 40, "3945e": 40, "3965": 40, "3965e": 40, "3966": 13, "3966e": 18, "3967e": 18, "3974e": 18, "398": [17, 40], "3983": 13, "3984": [36, 40], "3984e": 40, "3989e": 18, "3ac0836c7e28": 22, "3b": [26, 27], "3bfc792f": 24, "3d5144b4": 37, "3d5d": 37, "3e7dc3c5": 24, "3eeee112": 37, "3f": 30, "3fe9876d0974": 26, "4": [0, 1, 11, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41], "40": [15, 21, 27, 28, 29, 31, 37, 38, 40], "400": [27, 40], "4000e": 40, "4004": [19, 40], "401": [30, 40], "4012e": 21, "4014": 37, "40165": 25, "4017e": 21, "402": 37, "4023": [31, 37, 40], "4023e": 40, "4024e": 18, "4027e": 40, "4041e": 18, "4043": 40, "4048e": 18, "4054e": 18, "405b": [0, 17, 36, 50], "406": 40, "4062": [17, 36, 37, 40], "4062e": [37, 40], "4068e": 18, "407": 31, "4071": 11, "4078e": 18, "408": [37, 40], "4081e": 18, "4082": 40, "4084e": 18, "4085e": 18, "409": [37, 40], "4094e": 21, "4096": [24, 25, 28, 30, 31, 37], "41": [15, 21, 22, 24, 26, 27, 29, 31, 37, 40], "410": [37, 40], "4102": 40, "4106": 37, "411": 37, "412": [16, 37], "4121": 40, "4121e": 40, "4125e": 40, "4131e": 18, "414": [19, 40], "4141": 40, "4141e": 40, "415": 19, "4155e": 18, "416": [13, 19], "4160": 40, "4160868438": 19, "4160e": 40, "4164e": 18, "417": [15, 16, 19, 22, 37], "4170e": 40, "4177e": 18, "418": 19, "4180": 40, "4180e": 40, "4183": 13, "4186e": 21, "4193e": 18, "4195": 15, "4199": 40, "4199e": 40, "419aa1e4db6f": 24, "42": [21, 22, 24, 27, 28, 31, 32, 40], "4200e": 18, "4209e": 18, "4210": 24, "4215": 11, "4219": [37, 40], "4219e": 40, "4221e": 40, "4222e": 18, "4223e": 18, "4227e": 18, "4238": 40, "4241": 11, "4241e": 18, "4242e": 18, "4248e": 21, "4250e": 40, "4258": 40, "4258e": 40, "4259e": 21, "425a": 26, "4260e": [18, 21], "4261e": 40, "4264e": 18, "4275e": 18, "4277": 40, "4278e": 18, "4279e": 18, "428": 28, "4285": 12, "4285e": 18, "429": 36, "4291e": 18, "4297": 40, "4297e": 40, "429a": 36, "43": [21, 22, 24, 26, 27, 28, 29, 37, 40], "430": 40, "4302e": 18, "4307ba8c7258": 37, "4309e": 18, "431": 40, "4312e": 40, "4316": 40, "4316e": 40, "4317e": 18, "432": 40, "4321e": 40, "433": 40, "4332e": 40, "4335e": 18, "4336": 40, "4336e": 40, "4344e": 18, "435": 25, "4355": 40, "4355e": [21, 40], "4357e": 18, "4358e": 21, "4365e": 18, "4368e": 18, "437": 40, "4375": [23, 37, 40], "4375e": 40, "4384e": 18, "4395": 40, "4397e": 18, "43b4": 26, "43fd": 37, "43it": 38, "44": [21, 22, 24, 26, 27, 28, 30, 40], "440": [30, 37], "4407": 37, "441": 26, "4413e": 18, "4414": [17, 40], "4414e": 40, "4417": 24, "442": 40, "442c": 40, "443": [24, 40], "4431e": 18, "4432e": 18, "4434": 40, "4437e": 18, "444": 40, "4440e": 18, "4448e": 18, "444c7a53ba5a": 26, "445": 40, "4453": 40, "4453e": [37, 40], "4454e": 18, "4459e": 18, "446": 37, "4460": 12, "4460e": 18, "4464e": 21, "4473": 40, "448": [24, 37], "4482e": 18, "4486": 24, "4492": 40, "4493e": 18, "4496e": 18, "4499e": 18, "44it": 38, "45": [21, 22, 24, 27, 30, 37, 40], "4506e": 18, "4512": 40, "4512e": 40, "4526e": 40, "4530": 13, "4531": [17, 36, 37, 40], "4531e": 40, "4534e": 18, "454": 37, "4546e": 18, "4547e": 18, "4548e": 18, "455": [24, 37, 40], "4551": 40, "4551e": 21, "456": 37, "4562": 37, "4567e": 18, "4568": 24, "457": [37, 40], "4570": 40, "4570e": 40, "458": 37, "4586": 17, "4590": 40, "45it": 38, "46": [21, 24, 26, 31, 37, 40], "4609": 40, "4609e": 40, "4612": 15, "462": 40, "4629": [37, 40], "463": 40, "464": [16, 37], "4642e": 18, "4648": 40, "4648e": 40, "4659e": 18, "466": 40, "4661e": 18, "4668": 40, "467": [37, 40], "4679": 30, "468": [31, 37, 40], "4688": [17, 22, 36, 37, 40], "4688e": [37, 40], "469": [37, 40], "4691e": 18, "4695": 26, "46b1e1": 27, "46it": 38, "47": [21, 22, 24, 26, 28, 37, 40], "470": [37, 40], "4707": [37, 40], "4707e": 40, "471": 37, "4711": 28, "4718e": 18, "472": 24, "4727": [31, 40], "4727e": 40, "473": 37, "4731": 13, "4734e": 18, "474": 37, "4745e": 18, "4746": [37, 40], "4749e": 18, "475": 37, "4757e": 21, "476": [24, 37], "4764e": 18, "4766": [36, 40], "4766e": 40, "4768e": 40, "477": 37, "4770e": 21, "4776e": 21, "478": 37, "4785": 40, "4789": 15, "479": 37, "4790e": 40, "4796": [26, 37], "47ae": 31, "47mb": 37, "48": [21, 24, 37, 40], "480": [37, 40], "4800e": 18, "4802e": 18, "4805": 40, "481": [28, 37, 40], "482": 37, "4820e": 21, "4824": 40, "4828e": 18, "4831e": 18, "4834": 19, "484": 40, "4843e": 21, "4844": [37, 40], "4844e": 40, "485": 37, "4850e": 21, "4856e": 21, "485b": 37, "4860e": 18, "4861e": 40, "4863": 40, "4864e": 18, "4878": 15, "488": 26, "4883": [37, 40], "4886e": 18, "4890": 37, "48971": 28, "48ab3f593438": 24, "48ed": 36, "48it": 38, "48m": 17, "49": [21, 23, 24, 37, 40], "490": [24, 26, 40], "4900e": 18, "4902": [37, 40], "4902e": 40, "4903": 37, "4906": 37, "492": 40, "4922": [36, 37, 40], "4922e": [18, 40], "4929": 22, "492d": 37, "493": [26, 40], "4935e": 18, "4941": [37, 40], "4941e": 40, "4945e": 18, "4952e": 18, "4954e": 40, "496": [24, 36], "4961": 40, "4961e": 40, "4975": 37, "4980": 40, "4984e": 21, "4988e": 18, "4999": 11, "49it": 38, "4a1a": 40, "4ab4": 22, "4ae1": 24, "4b30": 26, "4b3e": 37, "4be4": 40, "4c20": 24, "4c24": 31, "4c3afb47007f": 40, "4ca7": 37, "4cd6": 37, "4ceb": 26, "4d00": 24, "4e70a05a43e2": 37, "4e8b": 24, "4e99c4c1": 24, "4ea72": 27, "4ecc": 37, "4ee8": 37, "4efe": 22, "4f": [11, 31], "4f21": 37, "4f2415b0eb2f": 24, "4f82": 36, "5": [0, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 41], "50": [16, 21, 22, 24, 26, 27, 28, 32, 36, 37, 39, 40], "500": [27, 30, 40], "5000": [17, 22, 36, 37, 40], "5000e": [18, 40], "5006e": 18, "501": 40, "5023e": 18, "5024": 15, "50256": [10, 28], "50257": [23, 30, 31, 37, 39], "5027e": 21, "50304": 23, "5039": [37, 40], "5039e": 40, "50400": 28, "505": 13, "5054e": 18, "5059e": 18, "5062e": 18, "507": [13, 40], "5073e": 40, "5078": [37, 40], "5078e": [18, 40], "508": 40, "509": 13, "5092e": 18, "50k": 28, "51": [21, 24, 28, 37, 40], "510": [28, 40], "5102e": 18, "5117": [37, 40], "5117e": 40, "512": [38, 41], "5129e": 18, "513": 40, "5131": 15, "5132e": 21, "5137e": 40, "5140e": 18, "514k": [22, 37], "5153e": 21, "5156": [17, 37, 40], "5156e": 40, "5164": 15, "5167e": 21, "5169e": 18, "5170e": 18, "5182e": [18, 40], "5188e": 18, "519": 37, "5194": 15, "5194e": 21, "5195": [37, 40], "5195e": 40, "5199e": 18, "52": [13, 21, 23, 28, 37, 40], "520": [26, 40], "5203e": 18, "5206e": 18, "5208e": 18, "521": 37, "5215e": 40, "5223e": 18, "5232e": 18, "5234": [37, 40], "5234e": 40, "5235": 13, "5265e": 21, "527": 40, "5273": [31, 40], "5274e": 21, "53": [21, 27, 40], "530": 28, "5301e": 18, "5312": [36, 37, 40], "5312e": 40, "5314e": 18, "5317e": 18, "532": 40, "5320e": 40, "5331e": 18, "5335": 30, "5345e": 18, "535": 37, "5352": 40, "5352e": 40, "5358e": 18, "536": 40, "5362e": 18, "5365e": 21, "5366e": 18, "5370e": 21, "5374e": 18, "5376e": 18, "5378e": [18, 40], "5380e": 18, "539": 40, "5391": [37, 40], "5391e": 40, "5393e": 18, "5395e": 18, "53a5": 22, "54": [21, 22, 26, 28, 40], "5405e": [18, 21], "5406e": 21, "541": [31, 40], "5420e": 21, "5430": 40, "5430e": 40, "5449e": 40, "545": 40, "546": 24, "5469": [17, 36, 37, 40], "5469e": 40, "5473e": 18, "5476e": 21, "5488e": 18, "5494": 15, "549c7e98": 36, "55": [21, 26, 29, 40], "5507e": 18, "5508": [37, 40], "5526e": 18, "5527e": 40, "5544": 13, "5547": [37, 40], "5547e": [18, 40], "5556": 12, "5557e": 18, "5560e": 18, "5562e": [18, 40], "558": 37, "5584": 37, "5586": [36, 40], "5586e": [18, 40], "5587e": 18, "559": 30, "5592e": 21, "5596": 19, "56": [21, 26, 28, 30, 37, 40], "5605e": 18, "5619e": 18, "562": 40, "5625": [17, 23, 37, 40], "5625e": 40, "5630e": 18, "5636e": 18, "564": [26, 37, 40], "565": [13, 37], "5650e": 18, "5656e": 18, "566": 37, "5664": 40, "5664e": 40, "5669e": 18, "567": 37, "5672e": 18, "568": 37, "5684e": 40, "5686e": 21, "56890804": 27, "5690e": 18, "57": [13, 21, 24, 28, 29, 37, 40], "570": 25, "5700e": 18, "5703": [37, 40], "5703e": [37, 40], "5704d94a35d3": 24, "570729dd": 37, "5707e": 18, "5723e": 40, "573": 40, "5742": 40, "5756e": 18, "577": 23, "5771e": 18, "5772e": 18, "5781": [17, 36, 37, 40], "5781e": 40, "5783": 11, "5786e": 18, "579": [37, 40], "5796e": 21, "57mb": 37, "58": [13, 21, 22, 24, 28, 37, 40], "580": [25, 26, 37], "581": 37, "582": 37, "5820": 40, "5820e": 40, "5823e": 18, "5825e": 18, "583": [37, 40], "5838e": 18, "5841e": 18, "5844e": 18, "5846e": 18, "585": [37, 40], "5855": 40, "5857": 19, "5858e": 40, "5859": 40, "5859e": 40, "586": [37, 40], "587": [26, 37, 40], "5879e": 40, "588": 37, "5885e": 18, "5886e": 18, "589": 37, "5898": [37, 40], "5898e": 40, "59": [21, 23, 30, 36, 37, 40], "5902e": 18, "5908e": 40, "5912e": 18, "5918e": 40, "592": 37, "5932": 15, "5933e": 18, "5938": [17, 36, 37, 40], "5938e": 40, "5940e": 18, "5942e": 18, "5953": 13, "5953e": 18, "5955e": 21, "596": 40, "5960e": 21, "5969e": 18, "597": 31, "5977": 40, "5977e": 40, "5986": 13, "5988e": 18, "5a": 33, "5abec8e78e7f": 37, "5b": 28, "5c78": 37, "5c81de91fb1f": 37, "5cd091cc": 26, "5m": 31, "5mb": 37, "5x": 28, "6": [0, 11, 12, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40], "60": [21, 22, 28, 37], "600": [28, 40], "6000e": 40, "6001e": 40, "6009e": 18, "6016": [36, 40], "6016e": 40, "602": 40, "604": 40, "6041e": 18, "605": 40, "6051e": 18, "6053e": 18, "6055": 40, "6058e": 21, "6059e": 18, "6062e": 18, "6064": 12, "6067e": 18, "607": 40, "6071": 15, "6073e": 18, "6074e": 18, "6076e": 21, "6088": 11, "609": [25, 40], "6094": [17, 36, 37, 40], "6094e": 40, "6096e": 18, "61": [21, 28, 29, 37], "6106e": 18, "6110e": 21, "6121e": 18, "6133": 40, "6133e": 40, "6134e": 18, "6139e": 21, "615": 40, "6165e": 18, "6167e": 18, "6172": [17, 37, 40], "6172e": 40, "618": [36, 40], "6191e": 40, "61it": 23, "61mb": 37, "62": [21, 22, 28, 37], "620": 40, "6211": 40, "6211e": 40, "6224e": 18, "6225e": 18, "6228": 13, "624": 40, "6242e": 21, "625": [13, 40], "6250": [17, 22, 23, 36, 37, 40], "6250e": 40, "6259e": 18, "6272e": 18, "6277": 15, "628": 40, "6286": 12, "6286e": 18, "6289": [37, 40], "6298e": 18, "62k": 37, "63": [21, 22, 28, 37], "630": [37, 40], "6301e": 18, "6309e": 40, "6327e": 18, "6328": 40, "6328e": [18, 21, 40], "634": 37, "6342": [15, 16, 28, 37], "6354e": 18, "636": [26, 37], "6367": 40, "6367e": 40, "6370e": 18, "6372e": 18, "6377e": 21, "6379e": 21, "638": [22, 40], "6382e": 18, "6389e": 18, "639": 40, "6398e": 18, "63mb": 40, "64": [21, 22, 23, 28, 29, 31, 37, 41], "6406": [22, 37, 40], "6406e": 40, "6417e": 18, "642": 40, "6433": 37, "644": 24, "6445": 40, "6448e": 18, "6451": 13, "647": 40, "6470": 11, "6484": 40, "6484e": [37, 40], "649": 24, "65": [21, 29], "650": 37, "6504e": 40, "651": 28, "6512e": 18, "6515e": 21, "6519": 15, "6523": 40, "6523e": 40, "653": [37, 40], "6543e": 18, "6547e": 21, "6551e": 21, "6553e": 18, "6556e": 21, "6561e": 18, "6562": [37, 40], "6562e": 40, "6564e": 18, "657": 40, "6576e": 18, "65mb": 37, "66": [21, 23, 28, 37], "6601e": 18, "6602": 40, "6602e": 40, "661": 40, "6613e": 21, "6626": 28, "6628e": 21, "6631e": 40, "6633": 13, "664": 40, "6641": [36, 40], "6641e": 40, "6642": 12, "6646e": 18, "6664e": 18, "6665e": 18, "667": 40, "6680": 40, "6680e": 40, "6686": 12, "6693e": 18, "6699e": 40, "67": [21, 22, 28, 37], "670": 40, "6714": 12, "6714e": 18, "6719": 40, "6719e": [37, 40], "671f": 25, "6723e": 21, "6725e": 18, "673": 40, "674": [24, 37, 40], "6750e": 40, "6751e": 18, "6758": [17, 37, 40], "6758e": 40, "6773e": 18, "6784e": [18, 21], "6791e": 21, "6795": 13, "6797": [37, 40], "6797e": 40, "68": [15, 21, 22, 28, 37], "681": 40, "6821e": 18, "6825": 11, "6827": 28, "6827e": 18, "6836": [37, 40], "6838e": 18, "6842e": 18, "6864e": 21, "6870e": 18, "6875": [17, 23, 31, 36, 37, 40], "6875e": [37, 40], "6876e": 21, "6881e": 18, "6883e": 18, "6886e": 18, "6889e": 21, "6895e": 40, "68mb": 30, "69": [18, 21, 37], "690": 22, "6902e": 18, "6913e": 21, "6914": 40, "6914e": 40, "6919e": 18, "693": 40, "694": 24, "6949e": 21, "6953": [37, 40], "6953e": 40, "6965e": 18, "6968e": 40, "697": 37, "6970e": 21, "6971e": 18, "6977e": 18, "6992": 40, "6992e": 40, "6994e": 18, "6998": 15, "69e5f67": 37, "6a": 24, "6b": [24, 28], "6e8fe35f0c03": 37, "6eee1203": 24, "6f64": 26, "6f94e6": 25, "7": [0, 11, 12, 17, 18, 21, 22, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41], "70": [0, 15, 21, 22, 28, 29, 36, 37], "700": 40, "7004e": 18, "7006e": 18, "7014e": 18, "7030e": 18, "7031": [17, 37, 40], "7031e": [37, 40], "7045e": 18, "7047e": 21, "705000638961792": 32, "706": [31, 40], "7067": 11, "7070": [37, 40], "7070e": 40, "7077e": 18, "7080e": 18, "709": 36, "7090e": 18, "7092e": 21, "70b": [0, 17, 22, 26, 35, 36, 40], "70m": 41, "71": [15, 18, 21, 28, 37], "7100e": 40, "7109": 40, "7109e": 40, "711": 40, "7115e": 18, "7123e": 18, "7125e": 18, "7129e": [37, 40], "714": [28, 37, 40], "7148": 40, "7148e": 40, "715": 40, "7153e": 18, "7155e": 18, "716": 40, "7168e": 40, "717": [26, 40], "7173e": 18, "7174e": 18, "7179e": 18, "7188": [17, 36, 37, 40], "7188e": [18, 40], "7195e": 18, "72": [18, 21, 22, 28, 37], "7206e": 18, "721": 40, "7218e": 18, "7227": 40, "7229e": 18, "724": 24, "7247": 25, "7258": 12, "7258e": 18, "7266": [37, 40], "7266e": 40, "7285e": 40, "73": [21, 28, 37], "730": 37, "7301": 11, "7302e": 40, "7305": [37, 40], "7305e": 40, "733": [16, 37], "7344": [37, 40], "7344e": 40, "7346e": 18, "7348e": 18, "736": 40, "7366": 13, "7372": 37, "7373f906": 31, "7376e": 18, "738": 40, "7383": 40, "7383e": [18, 40], "7393e": 18, "74": [18, 21, 22, 37], "740": 40, "7413e": 18, "7416e": 18, "742": 40, "7420e": 18, "7422": [37, 40], "7422e": 40, "743": 40, "7433e": 21, "744": 30, "7461": 40, "7466e": 40, "748": 26, "7480e": 40, "7482e": 18, "7484e": 18, "7487": 11, "749": 25, "7492e": 18, "7495": 12, "74mb": 37, "75": [21, 22, 28, 37], "7500": [23, 40], "7500e": 40, "750987cd": 30, "7515e": 40, "7531e": 18, "7532e": 21, "7539": [37, 40], "7539e": [21, 40], "755": 37, "756": 22, "7562e": 21, "7566e": 21, "757": 26, "7574e": 18, "7578": [37, 40], "7578e": 40, "758": [24, 40], "759": 37, "76": [15, 18, 21, 22, 37], "760": [13, 40], "7614e": 18, "7615e": 18, "7617": [37, 40], "762": 40, "7621": 11, "763": 40, "764": 37, "7648e": 18, "7656": [37, 40], "7656e": 40, "766": 19, "7662e": 18, "7676e": [21, 40], "768": [16, 18, 23, 30, 31, 37, 39], "7695": 40, "7695e": 40, "77": [15, 21, 22, 28, 37], "7706e": 18, "7709e": 18, "7716e": 18, "773": 40, "7734": [37, 40], "7734e": 40, "7736e": 18, "774": 40, "7743e": 18, "7749e": 40, "775": 24, "7763e": 21, "7770": 15, "7771e": 40, "7773": 40, "7773e": 40, "779": 40, "77e11841eecd": 37, "77mb": 22, "78": [15, 21, 22, 28, 37], "780": 40, "7801e": 18, "781": 19, "7812": [17, 22, 36, 37, 40], "7812e": 40, "7817e": 18, "782": 40, "7828e": 21, "7836e": 18, "7842e": [18, 40], "7844e": 18, "7847e": 21, "7850e": 21, "7852": [37, 40], "7852e": 40, "786": 37, "7862e": 18, "787": 22, "7881e": 18, "789": 40, "7890e": 21, "7891": 40, "7891e": [18, 40], "7896e": 18, "7897e": 18, "79": [13, 15, 17, 21, 22, 27, 36, 37, 40], "790": 40, "7916e": 21, "7930": 40, "7930e": 40, "7938e": 18, "7946": 12, "7954e": 40, "7957": 13, "796": 40, "7967": 13, "7968e": 18, "7969": [12, 17, 36, 37, 40], "7969e": [18, 37, 40], "797": 40, "7977": 13, "799": 40, "7995e": 21, "7997e": 18, "79d61f6b": 26, "79it": 38, "79mb": 40, "7b": [25, 28], "7b5bed21": 36, "7e95820c089c": 24, "7ec7": 37, "7ed9e7ca": 24, "7fa2": 36, "8": [0, 11, 12, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41], "80": [15, 21, 22, 25, 27, 36, 37, 40], "8008": 40, "801": 40, "802": 40, "8020e": 18, "8023e": 18, "8026e": 18, "8030e": 18, "804": 37, "8047": [37, 40], "8047e": [37, 40], "805": 40, "8052e": 18, "8054e": 40, "806": 40, "8066e": 40, "8069e": 21, "807": 31, "8074": 15, "8075e": 21, "8077e": 18, "808": 40, "8086": [36, 37, 40], "8086e": 40, "80gb": 36, "80mb": 37, "81": [15, 21, 22, 28, 37], "8102e": 18, "8105e": 40, "810d88f8": 37, "8111e": 18, "8113e": 18, "8118e": 18, "811d": 36, "8125": [23, 37, 40], "8125e": 40, "8129e": 18, "8135e": 18, "8138": 31, "814": 40, "8151e": 18, "8152e": 18, "8153e": 18, "8162e": 18, "8164": 40, "817": 40, "8174e": [18, 21], "8181": 28, "819": 22, "8192": [26, 27, 36, 40], "81c9f54063ab": 31, "82": [15, 21, 22, 28, 37], "8201e": 18, "8203": [37, 40], "8203e": 40, "8208e": 18, "822": [37, 40], "8242": 40, "8251e": 18, "8252e": 21, "8255e": 18, "8262e": 40, "8265e": 18, "8275e": 18, "8281": [36, 37, 40], "8281e": 40, "8289e": 40, "82mb": 37, "83": [15, 21, 37], "830": 37, "8320": [37, 40], "8359": 40, "8359e": 40, "8362e": 18, "8366": 13, "837": 40, "8375e": 18, "8376e": 18, "8379e": 40, "8385e": 18, "8387e": 40, "839": 40, "8398": 40, "83mb": 40, "84": [21, 28, 37], "8404e": 21, "8406e": 40, "8408": 15, "8417e": 18, "842": [22, 40], "843": 40, "8433e": 40, "8434e": 18, "8438": [37, 40], "8438e": 40, "8444e": 18, "8448e": 18, "846": 40, "847": 13, "8477": 40, "8477e": 40, "8478e": 18, "8480e": 18, "8481e": 21, "8486e": 21, "85": [15, 21, 37], "850": 40, "8502e": 21, "8506e": 18, "8512e": 18, "8516": [37, 40], "8516e": 40, "852": [36, 40], "8520e": 18, "853": [37, 40], "8533e": 18, "8536e": 18, "8542e": 18, "8548e": 18, "8555": 40, "8555e": 40, "8556e": 18, "8563e": 18, "8568e": 21, "856f2794": 26, "8574e": 40, "8575e": 18, "8584": 36, "8585e": 18, "859": 37, "8594": [17, 36, 37, 40], "8594e": 40, "8595": 11, "8595e": 18, "8599e": 18, "85m": 28, "86": [13, 21, 37], "861": 40, "8610e": 18, "862": 37, "8633": 40, "8633e": 40, "8641e": 18, "8645e": 21, "8651": 12, "8652e": [18, 40], "8663e": 18, "8672": [17, 40], "8672e": 40, "8677": 12, "8677e": 40, "8678": 36, "8679e": 18, "868": 13, "8683": 13, "869": [37, 40], "8697": 11, "8699e": 18, "87": [21, 37], "8703e": 18, "871": 40, "8711": 40, "8711e": 40, "872": 40, "874": 40, "875": 40, "8750": [17, 22, 23, 36, 37, 40], "8750e": 40, "8765": [15, 16, 37], "8768e": 40, "8789": [37, 40], "87cf": 37, "88": [21, 23, 28, 37], "8808e": 18, "8809e": 40, "881": 40, "8814e": 18, "8818e": 40, "8825e": 18, "8828": [36, 40], "8828e": 40, "8844e": 21, "8845e": 21, "8848e": 40, "8850e": 21, "8859e": 18, "886": 40, "8867": [37, 40], "8867e": 40, "887": 40, "8883e": 18, "8886": 15, "8896e": 21, "889999389648438": 32, "89": [21, 23], "8905e": 18, "8906": [17, 36, 37, 40], "8906e": 40, "891": 36, "8917": 12, "8918e": 18, "8927e": 18, "893": 40, "8934e": [18, 21], "894": 40, "8942e": 21, "8945": 40, "8957e": 21, "897": 24, "8978e": 18, "8981e": 18, "8983e": 18, "8984": 40, "8984e": 40, "8989e": 18, "899": 40, "89dd": 37, "8ab21f05": 24, "8b": [24, 26, 30, 31, 37], "8b5b": 22, "8bb3": 37, "8cf6": 37, "8daa5c1124c9": 24, "8ebe": 37, "8f32": 24, "8f70": 24, "8k": 30, "8th": [29, 36], "9": [12, 17, 18, 21, 22, 24, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41], "90": [21, 23, 37], "900": 37, "9002e": 18, "9006e": 18, "9014e": 21, "9016": 26, "902": [25, 40], "9023": 40, "904": 24, "9042e": 18, "9043e": 40, "905": 40, "9053e": 18, "9057": 12, "9062": [17, 36, 37, 40], "9062e": 40, "9071e": 18, "9072e": 40, "908": 40, "9099e": 18, "90acf29a": 26, "91": [21, 37], "9100e": 18, "9102": 40, "9102e": 40, "9104e": 18, "9106e": 18, "911": 40, "9111e": 40, "9114e": 18, "9126e": 18, "912f": 37, "9134e": 21, "914": 40, "9141": 40, "9141e": 40, "916": 40, "9167e": 18, "918": 40, "9180": 40, "9182e": 21, "9188": 12, "9194": 15, "9198": 11, "9198e": 18, "91mb": 37, "92": [18, 22, 23, 28, 37], "9203e": 21, "9209e": 21, "921": 40, "9210e": 18, "9211e": 18, "9217e": 21, "9219": 40, "9219e": 40, "9220e": 18, "9221e": 21, "922c": 36, "9238e": [37, 40], "9246": 11, "9247e": 21, "925": 24, "9258": 40, "9258e": 40, "9273e": 18, "9274e": 18, "9275e": 40, "928": 37, "9297": [17, 36, 40], "9297e": 40, "92mb": 22, "93": [23, 28, 37], "9303e": 18, "9307e": 40, "931": 40, "9311e": 18, "9316e": 40, "9318e": 18, "932": 40, "9329e": 18, "933": 40, "9332e": 18, "9336": 40, "9336e": 40, "934": 40, "9342e": 18, "9352": 13, "9357e": 18, "9359": 26, "936": 40, "9360e": 21, "9361e": 21, "9363e": 18, "9375": [17, 23, 36, 37, 40], "9375e": 40, "9377": 37, "938": 40, "9383e": 21, "939": 40, "93d8": 24, "94": [15, 18, 22, 25, 28, 37], "9402e": 21, "9403e": 18, "9405e": 18, "9406e": 21, "9407e": 21, "9410e": 18, "9412e": 21, "9414": 40, "9414e": 40, "9426e": 18, "944": 37, "9446": 11, "9453": [17, 40], "9453e": 40, "946": 40, "9463e": 18, "9472e": 18, "948": 36, "9492": [36, 40], "9492e": 40, "9497e": 21, "94a118bf": 37, "94c37060": 37, "95": [23, 28, 37], "950": 40, "9508e": 18, "9512e": 18, "9518e": 18, "952": 40, "9520e": 18, "9521e": 18, "9528e": 18, "9531": [36, 40], "9531e": 40, "9532e": 18, "9535e": 18, "9542e": 18, "9563e": 21, "9570": 40, "9571e": 18, "9575e": 18, "9586": 13, "9590e": 40, "9593e": 18, "96": [18, 22, 23, 37], "960": 26, "9609": [17, 40], "9609e": 40, "961": 22, "9621e": 18, "9624": 40, "9625e": 40, "9629e": 40, "9640e": 18, "9648": [37, 40], "9648e": 40, "9688": [36, 40], "9688e": [21, 40], "9690e": [18, 21], "97": [22, 28, 37], "971": 40, "9714e": 18, "9716e": 18, "972": 40, "9720e": 18, "9724": 13, "9725e": 21, "9727": 40, "9727e": 40, "9737e": 18, "974": 40, "9759e": 18, "976": 40, "9766": 40, "9766e": 40, "9774e": 18, "9776e": 18, "9784e": 18, "9788": 15, "9789e": 21, "979": 40, "98": [18, 22, 23, 26, 37], "9805": [36, 40], "9805e": 40, "9809e": 40, "9820e": 18, "9824e": 40, "9829e": 18, "9834e": 18, "9844": [17, 36, 37, 40], "9844e": 40, "9845e": 18, "9856e": 18, "986": 36, "9861": 37, "9861e": 18, "9862": 13, "9866": 12, "9866e": 18, "9869e": 21, "987": 40, "9876": 37, "9881e": 18, "9883": 40, "9883e": 40, "9884e": 18, "98it": 23, "99": [22, 37], "9907e": 21, "991": 40, "9918e": 18, "9922": 40, "9922e": 40, "993": 40, "9936e": 21, "9940": 15, "9944e": 18, "9945e": 18, "9947e": 18, "995": 28, "9961": 40, "9965e": 18, "9978e": 18, "9989": 25, "9996e": 18, "9a096378119c": 37, "9aa6": 40, "9c61": 24, "9ce5": 25, "9cea": 31, "9f088820": 37, "9f1d": 22, "9f56c971449d": 24, "A": [18, 22, 26, 27, 30, 31, 32, 34, 37, 38], "And": [0, 17, 28, 32, 33, 37], "As": [18, 20, 23, 24, 26, 27, 28, 30, 34, 35, 37, 38], "At": [28, 33, 34, 37], "Be": 20, "Being": 37, "But": [21, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37], "By": [0, 23, 24, 25, 28, 29, 30, 32, 34, 36, 37, 39], "For": [0, 7, 19, 20, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 40, 48], "IF": 38, "If": [0, 1, 7, 12, 14, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 48, 50], "In": [0, 11, 13, 14, 16, 17, 18, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40], "It": [11, 17, 18, 20, 22, 24, 25, 26, 27, 28, 32, 33, 35, 37, 40, 41], "NOT": [15, 31, 34], "No": [19, 28, 30], "Not": [28, 35], "Of": 34, "On": [0, 12, 25, 28, 37], "One": [21, 28, 29, 30, 31, 32, 37], "Or": 32, "THE": 29, "That": [25, 30, 33, 34, 37, 41], "The": [0, 1, 9, 10, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41], "Their": [1, 13], "Then": [0, 18, 24, 25, 27, 28, 29, 31, 33, 37, 40], "There": [19, 22, 26, 28, 29, 30, 32, 37, 38, 41], "These": [23, 25, 28, 29, 33, 41], "To": [10, 13, 17, 18, 21, 22, 24, 25, 26, 27, 28, 29, 32, 33, 35, 36, 37, 39, 50], "Will": 40, "With": [16, 32, 35, 37, 40], "_": [10, 24, 25, 28, 30, 32, 37], "__": 28, "____": [26, 33], "__call__": [19, 22, 37, 40], "__class__": 28, "__enter__": [7, 18, 37, 48], "__exit__": [7, 18, 19, 22, 37, 48], "__getitem__": 28, "__init__": [18, 22, 24, 28, 37, 40], "__iter__": 24, "__len__": 28, "__main__": [22, 28, 37], "__name__": [28, 37], "__setitem__": [18, 37], "__str__": [28, 37], "__torch_function__": [18, 37], "__version__": 31, "_antonym_pair": 28, "_attn_implement": 21, "_auth": 25, "_c": [18, 37], "_call_impl": 37, "_compiled_call_impl": 37, "_copying_len30_n1024": 25, "_country_capital_pair": 28, "_empti": [18, 37], "_envoi": [18, 22, 37], "_execut": 37, "_forward_hook": 37, "_global_forward_hook": 37, "_id": [22, 37], "_interleav": 19, "_ioi_patching_result": 30, "_model": [18, 22, 28, 37], "_name_or_path": 25, "_pile": 25, "_reset": [18, 22, 37], "_subclass": [18, 37], "_upcast_and_reordered_attn": 21, "_valu": 37, "_wrapped_call_impl": 37, "_zlib": [22, 37], "a02b93": 27, "a0bf6f344a85": 36, "a100": 36, "a160": 37, "a371825430db": 36, "a3c5": 40, "a3e6": 24, "a412": 24, "a59fd9": [32, 33], "a81d37fa": 31, "a928": 26, "a_plus_b": 34, "a_x": [37, 40], "aaron": 41, "ab": [24, 41], "abil": [26, 28, 31, 33, 40], "abl": [18, 25, 27, 28, 29, 33, 36, 37, 40], "ablat": [13, 22, 28, 30, 33, 37], "ablated_gener": 25, "ablated_token_gener": 25, "abort": 17, "about": [8, 9, 17, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 41, 50, 52], "abov": [10, 11, 13, 14, 17, 18, 19, 20, 24, 25, 28, 30, 31, 32, 33, 36, 37, 40], "abstract": [29, 32, 33, 34], "accept": [21, 28, 36], "access": [0, 8, 9, 10, 11, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 31, 33, 35, 37, 39, 40, 53], "accident": [26, 29], "accord": [24, 39], "accordingli": [17, 25], "account": [24, 27, 41], "accumul": 24, "accur": 40, "accuraci": [27, 32, 35], "ace2": 26, "achiev": [28, 32, 37], "acl": 38, "across": [10, 14, 16, 24, 26, 27, 30, 31, 32, 33, 34, 38, 40], "act": [16, 23, 30, 31, 37, 39], "act_add": 28, "act_add_coeff": 28, "act_add_lay": 28, "act_add_prompt": 28, "act_add_seq_len": 28, "act_add_vector": 28, "act_fn": [24, 27, 30, 31, 36, 40], "action": [28, 30, 37, 41], "activ": [10, 12, 13, 17, 19, 24, 25, 26, 29, 31, 32, 33, 34, 36, 37, 39, 40, 41, 53], "activation_addit": 28, "activation_dim": 41, "activation_funct": 28, "activation_patch": 53, "actual": [0, 11, 17, 18, 21, 26, 28, 30, 32, 33, 34, 37, 40], "ad": [17, 22, 28, 32, 35, 37, 38, 40], "ad29": 31, "ad93": 24, "adam": 29, "adamw": [37, 40], "adapt": [28, 31, 35, 37, 40, 41, 53], "add": [0, 7, 8, 17, 18, 22, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 48], "add_annot": 27, "add_generation_prompt": 35, "add_layer_norm": 38, "add_prefix_spac": 40, "add_row": 28, "add_special_token": [24, 35], "add_trac": 27, "addbackward0": [11, 12], "addit": [10, 17, 24, 34, 35, 37, 40], "address": [26, 41], "adea": 37, "adjust": [24, 38], "adversari": 28, "ae": 41, "affect": [26, 28, 32, 33, 34, 36, 37], "afraid": 28, "africa": [27, 29], "after": [7, 10, 11, 12, 13, 16, 17, 19, 21, 22, 24, 25, 26, 28, 30, 31, 33, 35, 36, 37, 38, 39, 40, 48], "afterward": [7, 48], "again": [18, 28, 31, 32, 34, 37, 38], "against": 28, "agnost": [25, 33], "ago": 41, "ah": [18, 37], "ahead": [25, 38], "ai": [23, 27, 32, 53], "aim": [28, 32], "air": 25, "aircraft": 35, "aka": 32, "al": [24, 25, 26, 28, 33, 38], "alen": 24, "alex": 28, "algorithm": [32, 34, 41], "alia": 28, "align": [32, 41], "alik": 37, "aliv": [22, 37], "all": [0, 7, 11, 13, 14, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 48, 50], "all_act": 25, "all_activ": 27, "all_attention_funct": 21, "all_correct_logprobs_intervent": 28, "all_token": [22, 37], "allow": [0, 14, 17, 18, 22, 28, 30, 31, 33, 36, 37, 38], "allow_non_fake_input": [18, 37], "alltok": 24, "almost": [26, 32, 33], "alon": [32, 35], "along": [0, 17, 26, 27, 28, 29, 32, 33, 34, 36, 37, 38], "alongsid": [0, 19, 37], "alpha": [27, 34, 37, 40], "alreadi": [16, 17, 21, 22, 26, 28, 31, 32, 33, 35, 37], "also": [0, 2, 7, 8, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 48, 52], "alter": [13, 14, 28, 37, 40, 50, 53], "altern": [27, 28, 30], "although": [7, 26, 28, 30, 31, 32, 33, 36, 41, 48], "alwai": [14, 27, 28, 30, 32, 35, 37], "am": 28, "ambigu": 33, "america": 29, "ami": 31, "amirzur": 32, "amp": 37, "amsterdam": 28, "an": [1, 7, 10, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 48, 50], "anaconda3": [14, 18, 22, 30, 31, 37], "analysi": [27, 29, 37, 41, 53], "analyz": [24, 26, 27, 32, 33, 37], "analyze_norm": 24, "anchor": [24, 27], "ancient": 28, "ani": [0, 2, 7, 9, 14, 17, 18, 21, 24, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 48], "ann": 28, "annot": [25, 28, 40], "announc": 37, "anoth": [17, 25, 29, 32, 37, 38], "answer": [16, 24, 26, 27, 30, 31, 32, 34, 35, 36, 37], "answer_token": [30, 37], "answer_token_id": 26, "answer_token_indic": [30, 31], "anthrop": [28, 41], "antistereotyp": 33, "antistereotypical_complet": 33, "antistereotypical_prob": 33, "antistereotypical_token": 33, "antonym_pair": 28, "antonym_task": 28, "anxiou": 28, "anymor": 25, "anyth": [18, 25, 28, 32, 37], "apart": 27, "api": [22, 24, 25, 26, 27, 28, 30, 31, 35, 40, 50], "api_kei": 28, "apikei": [24, 25, 26, 27, 36], "app": [22, 35, 36, 37], "appear": [24, 28, 35, 37], "append": [16, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41], "append_ax": 24, "appendix": 25, "appl": 31, "appli": [1, 7, 8, 10, 14, 15, 16, 19, 20, 22, 23, 25, 26, 28, 29, 30, 31, 32, 33, 36, 37, 38, 40, 48, 50, 53], "applic": [0, 23, 31, 37, 50], "applied_tutori": 52, "apply_chat_templ": [26, 35], "apply_rotary_pos_emb": 25, "applyn": [7, 48], "approach": [16, 28, 37, 38, 39, 41], "appropri": [20, 28, 36, 37], "approv": [17, 22, 24, 26, 30, 31, 36, 37, 40], "approxim": [30, 31, 53], "apt": 28, "ar": [0, 2, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 48, 50, 52], "arang": [24, 28], "arbitrari": 37, "architechur": 40, "architect": 28, "architectur": [28, 31, 40], "archiv": 28, "area": [28, 29], "aren": [27, 28, 35, 36, 37], "arena": [28, 31], "arena_3": 28, "arent": [37, 40], "arg": [7, 12, 18, 22, 28, 35, 37, 40, 48], "arg_depend": 37, "argmax": [9, 14, 15, 17, 23, 25, 26, 27, 28, 33, 37, 40], "argument": [0, 12, 21, 28, 35, 37], "aris": 37, "arithmet": [28, 32, 33], "around": [25, 26, 27, 28, 29, 32, 33, 34, 37, 38], "arrai": [27, 28], "arriv": 28, "arrog": 28, "arrow": [27, 28, 34], "arrowcolor": 27, "arrowhead": 27, "arrows": 27, "arrowwidth": 27, "articl": [17, 28], "as_dict": [7, 48], "ascertain": 26, "asid": 28, "ask": [8, 26, 28, 29, 32, 35, 36, 52], "asleep": 28, "aspect": [27, 28], "assert": [19, 24, 25, 28], "assess": [33, 40], "assign": [12, 19, 21, 27, 28], "assist": [26, 28, 35], "associ": [21, 28, 30, 31, 37, 39, 41], "assum": [28, 33, 37], "assume_static_by_default": [18, 37], "assumpt": 31, "asymmetr": 28, "athen": 28, "atlanta": 28, "atok": 24, "atoken": 24, "att": 24, "att_co": 24, "att_cos_al": 24, "attach": [18, 37], "attack": 28, "attempt": [18, 37], "attend": [26, 28], "attent": [21, 23, 24, 26, 30, 31, 32, 33], "attention_0": 21, "attention_interfac": 21, "attention_interface_0": 21, "attention_mask": [21, 25, 28, 40], "attention_pattern": 28, "attention_valu": 33, "atticusg": [32, 34], "attn": [21, 23, 28, 30, 31, 33, 37, 39], "attn_dim": 33, "attn_dropout": [21, 28, 30, 31, 37, 39], "attn_head_output": 28, "attn_implement": 25, "attn_mask": 21, "attn_out": [25, 28, 31], "attn_output": [21, 28], "attn_output_reshape_0": 21, "attn_output_transpose_0": 21, "attn_pattern": 28, "attn_patterns_valu": 28, "attn_pdrop": 28, "attn_weight": [21, 25], "attribut": [7, 10, 12, 13, 26, 28, 30, 37, 39, 48, 53], "attribution_patch": 53, "authent": 25, "author": [24, 26, 27, 28, 33, 38], "auto": [10, 14, 16, 18, 21, 23, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 39, 40, 41], "autoencod": 53, "autom": 31, "automat": [12, 17, 28, 36, 37, 38], "automodelforcausallm": [25, 37, 40], "automodelforsequenceclassif": 40, "autonotebook": [14, 18, 30, 37], "autorang": [26, 27, 32, 33], "autoregress": [25, 27, 28, 33], "autotoken": [35, 40], "avail": [17, 28, 35, 37], "averag": [24, 27, 28], "avoid": [17, 22, 24, 25, 28, 35, 37], "awai": [26, 27, 32, 33], "awak": 28, "awar": 26, "awesom": [31, 36], "ax": [24, 25, 27, 38], "axes_grid1": 24, "axi": [27, 38, 39], "axref": 27, "ayref": 27, "azur": 25, "b": [17, 22, 24, 26, 28, 30, 32, 34, 37], "b16d": 37, "b171": 24, "b2d3": 24, "b2df": 24, "b3d2": 26, "b47d": 37, "b53c": 31, "b53f": 30, "b559b94c3211": 31, "b55f": 37, "b7e7": 17, "b81eb518": 40, "ba25": 26, "ba43": 37, "ba_x": [37, 40], "back": [17, 22, 25, 28, 29, 32, 33, 34, 36, 37], "backend": [17, 18, 19, 21, 22, 23, 28, 37], "backpropag": [13, 37], "backpropagr": 13, "backward": [13, 23, 24, 28, 29, 31, 37, 40], "backwards_check": [18, 37], "bag": 31, "baker": 26, "balanc": 28, "ball": 31, "bangkok": 28, "bar": [24, 25], "barbilla": 25, "barca": 25, "barcelona": 28, "bare": 37, "barrier": 10, "base": [14, 18, 19, 22, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41], "base_causal_input": 32, "base_countri": 33, "base_h12_valu": 32, "base_input": 32, "base_logit": [27, 29, 33], "base_output": 32, "base_prob": 29, "base_prompt": [25, 27, 29, 33], "base_prompt_token_id": 27, "base_stat": 27, "base_token": 25, "base_token_id": 27, "baseexcept": [18, 37], "baselin": [24, 30, 31], "baseline_residu": 24, "basi": 29, "basic": [0, 28, 32, 37, 50, 53], "bat": 33, "batch": [8, 23, 24, 28, 31, 36, 40], "batch1": 10, "batch2": 10, "batch_decod": [10, 28, 37], "batch_process_lay": 28, "batch_siz": [28, 37, 40], "batchnorm": 28, "bc": [26, 34], "bcbd9294": 40, "bdec": 24, "be77": 22, "be93": 26, "beat": 28, "beauti": 28, "bec33e406bf6": 26, "becaus": [16, 17, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40], "bedf": 31, "been": [7, 17, 22, 24, 25, 26, 28, 30, 31, 35, 36, 37, 40, 48], "bef0": 24, "befor": [10, 13, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 37, 38, 40, 41], "begin": [27, 28, 29, 32, 33], "begin_of_text": [24, 33, 35, 37], "behav": [28, 37], "behavior": [23, 24, 25, 28, 29, 30, 32, 33, 34, 37, 38, 41], "behind": [27, 28, 32, 37], "behold": [27, 32, 33], "beij": 28, "being": [0, 11, 17, 21, 22, 24, 25, 28, 32, 37, 40], "belgium": 29, "belief": 39, "believ": [37, 39], "below": [0, 1, 16, 25, 28, 32, 34, 37, 53], "belt": 37, "benchmark": [24, 29, 40], "benefit": [17, 28, 31, 37], "berlin": [28, 33], "best": [18, 27, 28, 37], "beta": 34, "better": [27, 28, 29, 37, 40], "between": [0, 1, 10, 14, 17, 24, 27, 28, 30, 32, 33, 34, 37, 38, 41], "betweent": 33, "beyond": [15, 25, 37], "bf34e807": 22, "bf6360": 25, "bfloat16": [17, 22, 24, 28, 35, 36, 37, 38], "bia": [23, 24, 27, 28, 29, 30, 31, 32, 36, 37, 39, 40, 41], "bidirect": 28, "big": [26, 31, 37], "bigger": [26, 33, 53], "billion": [0, 36], "bird": 25, "birth": 28, "bit": [25, 26, 28, 32, 35], "bitsandbyt": 25, "bitsandbytesconfig": [24, 25], "black": [25, 38], "blank": 37, "blindli": 25, "blob": 25, "block": [0, 10, 13, 22, 28, 29, 31, 37, 38, 40], "block_siz": 24, "blocking_request": [22, 37], "blog": [26, 28, 31, 39], "blue": [25, 27], "blueski": [36, 37], "blunt": 28, "bnb_8bit_compute_dtyp": 24, "bnb_config": 24, "bo": [24, 25, 26, 28, 35], "board": [37, 38], "boat": 25, "bodi": 37, "bold": 28, "bone": 37, "bonu": 1, "bool": [7, 21, 22, 24, 28, 37, 48], "boolean": 37, "born": 28, "borrow": 25, "bos_token": 28, "bos_token_id": [25, 28], "both": [19, 21, 24, 27, 28, 31, 32, 33, 37, 38, 40], "bottl": 30, "bottom": [25, 27, 28], "bound": [18, 28, 37], "boundari": 27, "bounti": 36, "branch": 28, "brave": 28, "brazil": [29, 33], "break": [11, 24, 28, 29, 30, 31, 32, 33, 35], "bridg": [27, 36], "brief": 32, "briefli": 28, "bring": [27, 28, 37, 41], "broadcast": 37, "broaden": 33, "broader": 28, "broke": 30, "bsky": 37, "bsz": 25, "btw": [27, 32, 33], "buckingham": [17, 37], "budapest": 28, "bug": [0, 21], "bui": 28, "build": [22, 28, 37], "built": [0, 22, 37, 38], "bulb": 28, "bump": 27, "bunch": [24, 25, 26, 28, 37], "bupu_r": 26, "burt": 28, "bw_hook": 37, "bypass": 28, "byte": [22, 37], "bytearrai": 37, "bytes_io": 25, "c": [7, 26, 32, 34, 48], "c0f0a7c4d784": 37, "c12991ff": 24, "c1e7": 37, "c820": 26, "c9fcc827": 37, "c_": 34, "c_attn": [21, 23, 30, 31, 37, 39], "c_fc": [23, 30, 31, 37, 39], "c_proj": [21, 23, 30, 31, 33, 37, 39], "cach": [21, 25, 31], "cache_posit": 21, "cache_util": 28, "caja": 25, "calcul": [0, 24, 25, 30, 31, 38, 40], "calculate_and_apply_steering_vector": 28, "calculate_and_intervene_with_h": 28, "calculate_fn_vector": 28, "calculate_h": 28, "calculate_h_and_interven": 28, "calculate_h_and_intervene_logprob": 28, "call": [0, 7, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 28, 30, 32, 36, 37, 40, 41, 48], "callabl": [7, 21, 39, 48], "callum": 28, "callummcdougal": 28, "came": [26, 27, 28, 29, 34], "can": [0, 1, 2, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 50, 52], "canada": 27, "canda": 27, "cannot": [35, 37], "canva": 25, "capabl": [9, 26], "capit": 28, "captur": [10, 12, 13, 17, 37], "car": [28, 41], "card": 25, "cardin": 25, "care": [7, 27, 28, 29, 33, 37, 48], "carri": [7, 25, 27, 48], "case": [16, 17, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 40], "cat": [24, 25, 27, 29, 39], "catch": 18, "categori": 28, "caught": 25, "caus": [22, 26, 27, 28, 34, 35, 37], "causal": [0, 13, 25, 27, 28, 29, 31, 53], "causal_effect": [32, 33], "causal_effect_per_lay": 33, "causal_effects_per_lay": 32, "causal_mask": 25, "causal_mediation_analysi": 53, "causal_mediation_analysis_i": 53, "causal_mediation_analysis_ii": 53, "causal_mediation_util": 32, "causal_model": 34, "causal_models_intro": 53, "causal_scor": 25, "causalabstract": [32, 34], "causalmodel": 34, "caution": [18, 37], "cautiou": 20, "cautious": [14, 37], "cax": 24, "cb86": 24, "cbar": 24, "cc": 28, "ccd16638": 36, "cd": 41, "cd09": 40, "ceil": 38, "cell": [11, 18, 19, 22, 25, 28, 32, 33, 37, 39], "center": [25, 27], "certain": [11, 28, 29, 30], "certainli": [28, 33], "cfa97488": 37, "chain": 15, "challeng": 28, "chanc": 29, "chang": [0, 14, 17, 18, 19, 21, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40], "channel": 28, "chapter": 28, "chapter1_transformer_interp": 28, "charact": [26, 28], "charg": 32, "chat": [16, 28, 36, 53], "chat_templ": [35, 53], "chatbot": 35, "chatcomplet": 28, "chatgpt": 26, "chdir": 28, "cheapli": 28, "check": [0, 2, 8, 17, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 36, 37, 50, 52], "check_function_whitelist": [22, 37], "chess": 38, "chicago": 27, "child": [16, 37], "children": [16, 37], "chines": 25, "choic": [27, 28, 32, 34], "choos": [25, 28, 30, 34, 37, 53], "chop": 25, "chose": [28, 32, 33], "chosen": [0, 27, 28], "chunk": 40, "cie": 28, "cinema": 30, "circl": 27, "circuit": [0, 30, 31, 32], "circuitsvi": [28, 41], "circul": 41, "citi": [0, 9, 10, 12, 14, 16, 17, 18, 21, 22, 23, 27, 28, 29, 33, 36, 37, 39], "cjk": 25, "ckpt": 25, "cl": [7, 22, 37, 48], "claim": [25, 32], "clamp": 24, "class": [7, 9, 16, 21, 24, 27, 28, 36, 37, 38, 40, 48, 51], "classic": [28, 37], "classifi": [22, 37], "classmethod": [22, 37], "claus": 30, "clean": [23, 26, 28, 31, 32], "clean_act": 31, "clean_activ": 28, "clean_baselin": 31, "clean_decoded_token": [26, 30], "clean_h": 30, "clean_input": 28, "clean_logit": [23, 30, 31], "clean_logit_diff": 30, "clean_logprob": 28, "clean_out": 31, "clean_prompt": 30, "clean_token": [28, 30, 31], "clean_x": 31, "cleaner": 13, "clear": [14, 24, 28, 36, 37, 50], "clear_edit": [14, 37], "clear_output": [22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41], "clearer": 41, "clearli": [25, 28], "clever": 28, "cli": [22, 24, 30, 31, 35, 36], "click": 28, "client": [24, 28, 35, 38], "clone": [2, 8, 13, 18, 19, 24, 25, 28, 29, 32, 34, 37, 41, 50, 52], "clonebackward0": 21, "close": [26, 27, 28, 37], "cloud": [25, 26], "cls_index": 28, "clunki": 16, "cluster": 27, "cmap": [24, 25], "cnt": 24, "co": [25, 37], "code": [0, 8, 13, 16, 17, 18, 19, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 39], "coef_": 27, "coeff": 28, "coeffici": [28, 32], "coffin": 41, "coher": 28, "col1": 28, "col2": 28, "colab": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 50], "cold": 28, "collabor": [17, 37], "collaps": 28, "colleagu": 28, "collect": [7, 10, 18, 24, 26, 27, 28, 29, 30, 32, 33, 36, 37, 38, 39, 48], "color": [25, 26, 27, 28, 29, 30, 31, 32, 34, 39], "color_continuous_midpoint": [26, 30, 31, 39], "color_continuous_scal": [26, 27, 30, 31, 32, 33, 39], "colorbar": 24, "colored_tokens_multi": 41, "colormap": 24, "colosseum": 28, "column": [24, 25], "columnparallellinear": 23, "com": [21, 25, 27, 28, 32, 34, 41], "combin": [25, 29, 30, 31, 37, 38], "come": [10, 22, 28, 29, 32, 33, 34, 35, 37], "comfort": 28, "comma": 37, "command": [17, 28, 35], "comment": [25, 27, 28], "commerci": [0, 37], "common": [21, 28, 30, 36, 37, 38, 50], "commonli": [28, 40], "commun": [0, 9, 10, 14, 16, 18, 21, 30, 31, 36, 37, 39, 40], "compar": [14, 17, 19, 28, 30, 32, 33, 37], "comparison": [30, 37], "compat": 18, "compil": 21, "compl": 37, "complementari": 37, "complet": [0, 11, 17, 22, 24, 25, 26, 28, 30, 31, 32, 33, 36, 37, 40], "completely_different_quest": 26, "completion_i": 28, "completion_intervent": 28, "completion_ni": 28, "completions_intervent": 28, "completions_zero_shot": 28, "complex": [9, 16, 27, 28, 32, 34, 35, 36, 37, 38], "complic": [28, 36, 38], "compon": [0, 16, 29, 30, 32, 34, 36, 37, 41], "compos": [24, 28, 37], "composit": 24, "composition": 24, "compound": [38, 41], "compounded_orig": 41, "comprehens": [25, 28, 36], "compress": 25, "compulsori": 28, "comput": [0, 7, 8, 13, 17, 19, 22, 25, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 39, 48], "computation": [29, 30], "compute_causal_effect": 32, "concat": 28, "concaten": [24, 27, 28], "concept": [1, 27, 33, 38], "concept_cmap": 25, "concept_copying_len30_n1024": 25, "concept_head_ord": 25, "concept_plt": 25, "concept_scor": 25, "concept_vec": 25, "conceptu": 28, "conclud": [28, 37], "conclus": 35, "concurr": [17, 37], "cond": 37, "condit": [21, 28], "conduct": [35, 53], "confid": 39, "config": [17, 21, 22, 24, 25, 26, 27, 30, 31, 33, 35, 36, 37, 38, 40], "configur": [19, 23, 24, 30, 31, 36, 37, 40, 50], "confirm": [24, 32], "confus": [28, 32], "congratul": [26, 28], "connect": [22, 27, 33, 37, 38], "consequ": [14, 37], "conserv": 37, "consid": [27, 28, 31, 32], "consist": [27, 28, 32, 37, 40], "constant": 32, "constantli": 28, "construct": [20, 24, 27, 28, 29, 32], "consum": 35, "consumpt": [22, 37], "contact": 25, "contain": [24, 28, 30, 33, 37, 40, 51], "content": [22, 24, 26, 35, 37], "context": [0, 7, 10, 12, 13, 14, 16, 17, 18, 21, 22, 23, 25, 27, 28, 30, 31, 35, 36, 48, 49], "contigu": 21, "contiguous_0": 21, "contin": 29, "continu": [26, 32, 33, 37], "continuation_token": 26, "continue_final_messag": [26, 35], "contrast": 38, "contribut": [1, 26, 30, 31, 32, 33, 37, 38], "control": [11, 16, 27, 28, 32, 34, 37], "conv1d": [30, 31, 37, 39], "convei": 32, "convent": 37, "convers": [28, 35, 36], "convert": [21, 25, 27, 28, 29, 35, 40], "convert_ids_to_token": 24, "convinc": [25, 32], "cool": [28, 37, 38], "coordin": 27, "copenhagen": 28, "copi": [14, 25, 28, 31, 32, 34], "copy_paragraph": 25, "copy_prompt": 25, "copyright": 26, "core": [13, 25, 37], "correct": [18, 28, 30, 31, 33, 37], "correct_complet": 28, "correct_completion_first_token": 28, "correct_completion_id": 28, "correct_countri": 27, "correct_index": 30, "correct_logit": 31, "correct_logprob": 28, "correct_logprobs_corrupt": 28, "correct_logprobs_dict": 28, "correct_logprobs_intervent": 28, "correct_logprobs_zero_shot": 28, "correct_token": [37, 40], "correctli": [18, 20, 28, 30, 32, 37], "correl": 27, "correspond": [24, 25, 27, 28, 30, 32, 33, 35, 37, 39], "corrup": 31, "corrupt": [23, 28, 31, 32], "corrupt_id": 30, "corrupted_act": 31, "corrupted_baselin": 31, "corrupted_dataset": 28, "corrupted_grad": 31, "corrupted_grad_act": 31, "corrupted_grad_x": 31, "corrupted_input": 28, "corrupted_logit": [23, 30, 31], "corrupted_logit_diff": 30, "corrupted_out": 31, "corrupted_prompt": 30, "corrupted_token": [30, 31], "corrupted_x": 31, "cosine_similar": 24, "cost": [18, 28, 37], "could": [0, 20, 25, 28, 29, 32, 33, 34, 35, 36, 37, 39, 40], "couldn": [27, 28], "count": [24, 25], "count_neg": 40, "count_posit": 40, "counterfactu": [26, 29, 30, 34], "counterfactual_answ": 29, "counterfactual_input": 34, "counterfactual_loss": 29, "counterpart": 28, "countri": [27, 28, 29, 33], "country_capital_pair": 28, "coupl": 37, "courag": 28, "cours": [18, 28, 34, 37], "cover": [26, 28, 32, 33, 37], "cowardli": 28, "cpu": [16, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 39, 41], "cpu_model": 25, "creat": [0, 10, 13, 14, 18, 22, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 40, 41], "create_corrupted_dataset": 28, "creativ": 26, "creator": 26, "credenti": 35, "crocevia": 25, "cross": [0, 8, 21, 29, 37, 40], "cross_attention_cach": 21, "cross_entropi": [37, 40], "cross_prompt": 8, "crossentropyloss": 29, "crowd": 28, "crux": 28, "csordas_llm_depth": 1, "csord\u00e1": 24, "csv": 27, "cubla": 24, "cuda": [11, 13, 22, 23, 25, 27, 28, 29, 33, 37, 38, 41], "culprit": 33, "cultur": 28, "curiou": [17, 28, 33], "curr": 21, "curr_head": 25, "curr_lay": 25, "curr_past_key_valu": 21, "curr_past_key_value_update_0": 21, "current": [17, 19, 22, 23, 24, 25, 26, 28, 29, 31, 37], "current_lin": [22, 37], "current_line_length": [22, 37], "custom": [20, 21, 22, 36], "custom_chunk": 25, "custom_sum": 37, "cut": [33, 35], "cv": 28, "cwd": 28, "cyan": 28, "cytoscap": [32, 34], "d": [0, 13, 16, 24, 25, 26, 28, 30, 32, 33, 35, 36, 37, 38], "d0b4": 37, "d3f6": 37, "d81a": 17, "d82e4471": 37, "d82fdef7292d": 22, "d_head": [28, 30], "d_model": [28, 30], "d_vocab": 28, "da": [32, 33, 53], "dai": 26, "dall": 24, "dall_out": 24, "damp": 41, "dan": 31, "dark": [29, 34], "dark_orang": 28, "darker": [27, 33], "dash": [27, 28, 32, 34], "data": [7, 17, 18, 22, 24, 26, 27, 28, 31, 37, 41, 48, 53], "dataload": [37, 40], "datapoint": 32, "dataset": [22, 24, 25, 26, 27, 29, 32, 33, 37, 40], "dataset_mediating_a": 32, "dataset_mediating_b": 32, "dataset_mediating_c": 32, "datatyp": 37, "date": 35, "dawn": 28, "db294082eeae": 30, "dc59df682635": 26, "dd856905edc9": 37, "de": 37, "de3f072d": 37, "deadlock": [17, 22, 37], "death": 28, "debug": [2, 8, 18, 28, 37], "decemb": [28, 35], "decent": 31, "decid": [25, 30], "decim": 32, "decis": [0, 31], "decod": [14, 15, 16, 17, 21, 22, 23, 25, 26, 27, 29, 30, 33, 35, 36, 37, 39, 40, 41, 53], "decoded_answ": 16, "decoded_prompt": 16, "decoded_token": [22, 37], "decomposit": 27, "decreas": [28, 30, 31], "dedup": 41, "deduplicate_token": 26, "deep": [0, 28, 36, 37, 50], "deeper": [24, 33, 36], "deepfloyd": 38, "deepli": 1, "deepseek": [36, 50], "def": [18, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 40], "default": [0, 10, 13, 14, 17, 23, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40], "defaultdict": 28, "defeat": 28, "defer": 37, "defici": 28, "defin": [0, 7, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 24, 25, 28, 30, 31, 35, 36, 37, 38, 40, 48], "definit": [17, 28, 37], "degre": [26, 27], "dejavu": 25, "del": 33, "delet": [12, 33, 37], "deliber": 41, "deliv": [22, 37], "delta": [17, 25], "delta_logprob": 28, "delv": 37, "democrat": 37, "demonstr": [13, 14, 16, 18, 28, 35, 37, 41], "demystifi": 1, "deni": 17, "denois": 38, "denot": [16, 28], "dens": 25, "dep": [24, 35, 38], "depart": 28, "depend": [0, 18, 24, 25, 28, 30, 33, 34, 37], "deploy": 28, "deprec": 13, "depth": [1, 13, 27, 28], "descent": 28, "describ": [28, 35, 37], "descript": [28, 37], "design": [27, 28, 35, 37], "desir": [12, 16, 37], "desk": 35, "despit": [24, 28], "destroi": [28, 37], "detach": [24, 25, 27, 31, 39], "detail": [10, 12, 25, 28, 29, 31, 36, 37, 41, 50], "detect": [26, 28, 30], "determin": [25, 28, 30, 31, 32, 35, 40], "determinist": 28, "detoken": 25, "dev": [26, 27, 29], "develop": [9, 17, 28, 37, 38], "devic": [11, 12, 13, 16, 18, 22, 23, 24, 25, 26, 27, 28, 29, 33, 37, 38], "device_map": [10, 14, 16, 17, 18, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 39, 40, 41], "df": 27, "df66": 26, "dh": 30, "diagram": 28, "dict": [7, 22, 24, 25, 26, 27, 28, 32, 33, 37, 39, 48], "dict_learn": 53, "dict_of_kwarg": 28, "dictionari": [12, 28, 35, 37, 53], "dictionary_learn": 41, "dictionary_s": 41, "did": [19, 26, 27, 28, 29, 32, 33, 37], "didn": [10, 26, 27, 28, 29, 32, 33, 34, 37], "diff": [24, 30, 31], "diff_now": 24, "diff_out": 24, "differ": [0, 10, 16, 17, 19, 20, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "difference_in_mean": 27, "different_harri": 26, "difficult": [0, 37, 41], "difficulti": 28, "diffus": 53, "diffusion_len": 53, "diffusionmodel": 38, "digit": [32, 34], "dim": [9, 14, 15, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 36, 37, 39, 40, 41], "dimens": [18, 19, 27, 28, 29, 30, 31, 37, 38, 40, 41], "dimension": [27, 29, 40, 41], "diminish": 24, "dir": 25, "direct": [0, 24, 27, 29, 34, 37], "directli": [14, 25, 26, 28, 29, 30, 32, 34, 37], "directori": 28, "disabl": [13, 17, 22, 28, 36, 37], "disabletorchfunctionsubclass": [18, 37], "disappear": 28, "discard": 28, "disclaim": 25, "disconnect": [27, 38], "discord": [0, 28, 36, 37], "discov": [32, 37], "discoveri": [0, 31], "discuss": [0, 2, 8, 28, 34, 37, 50, 52], "disentangl": 25, "disk": 27, "dispatch": [21, 23, 25, 31, 37, 38, 39], "displai": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41], "display_forward_pass": [32, 34], "display_interchang": [32, 34], "display_model_completions_on_antonym": 28, "display_model_completions_on_h_intervent": 28, "display_model_logprobs_on_h_intervent": 28, "display_structur": [32, 34], "dispos": [18, 28], "disrupt": 32, "dist": [19, 25, 37], "distinct": [28, 33], "distinguish": 1, "distribut": [24, 26, 27, 37], "dive": 36, "diverg": [24, 39], "divid": 24, "do": [1, 13, 14, 17, 18, 19, 20, 21, 22, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 40], "do_sampl": 28, "doc": [9, 23, 28, 37], "docstr": 28, "document": [23, 28, 37], "doe": [15, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 37], "doesn": [18, 25, 26, 27, 28, 29, 32, 33, 37, 38], "domain": [28, 40], "domest": 28, "dominican": 27, "don": [10, 11, 16, 17, 18, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37], "done": [10, 24, 25, 28, 31, 32, 37], "door": 32, "dot": 28, "doubl": [28, 37], "down": [17, 25, 27, 28, 29, 31, 32, 33], "down_proj": [24, 27, 30, 31, 36, 40], "downgrad": 26, "download": [17, 22, 24, 25, 28, 30, 31, 36, 37, 40], "downstream": [19, 22, 28, 30, 34, 37], "dr": [16, 31, 37], "dramat": 35, "draw": [26, 27, 28], "drawn": 27, "drink": 31, "drive": [26, 27, 41], "drizzli": 41, "drop": [24, 30, 31, 37, 39], "dropdown": 28, "dropout": [21, 28, 30, 31, 37, 39], "dropout_p": 21, "dry": 28, "dtype": [17, 22, 23, 24, 25, 35, 36, 37], "dual": 1, "dublin": 28, "duck": 41, "due": [21, 28], "duma": 25, "dummi": 28, "duplic": [25, 35], "dure": [10, 13, 15, 16, 17, 19, 21, 22, 28, 29, 30, 31, 33, 36, 37, 38], "durslei": 26, "dursnei": 26, "dusk": 28, "dynam": [21, 23, 32], "dynamiccach": [17, 28], "e": [7, 17, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 37, 48], "e092d2e58585": 26, "e0b6": 37, "e97132": 27, "eabbb6090ebf": 22, "each": [10, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41], "eaf6f97d6c0b": 17, "eager": [21, 25], "eager_attention_forward": 21, "earli": [8, 17, 20, 27, 28, 31], "earlier": [17, 24, 28, 30, 31, 33, 37, 38], "early_stop": 8, "earlystopexcept": 37, "earlystopprotocol": 37, "earth": 28, "eas": 30, "easi": [0, 16, 27, 32, 37], "easier": [26, 28, 32], "easili": [0, 9, 28, 36, 37, 41], "eat": 35, "eb3b": 26, "ed8eb309": 40, "edg": 32, "edibl": 35, "edit": [8, 9, 19, 25, 26, 33, 34], "edited_tensor": 19, "editor": [14, 37], "edu": 25, "effect": [9, 14, 19, 20, 25, 26, 27, 28, 30, 31, 33, 34, 35, 37, 38, 40], "effici": [1, 11, 13, 17, 18, 21, 23, 28, 31, 37, 40], "effort": 0, "eiffel": [0, 9, 12, 14, 16, 17, 18, 21, 22, 23, 28, 36, 37, 39], "einop": [28, 30, 31, 37], "either": [17, 22, 28, 34, 37, 40], "el": 15, "element": [28, 36, 37], "elementwise_affin": [23, 30, 31, 37, 39], "eleutherai": [26, 28, 41], "elhag": 25, "elif": [25, 37], "elig": 17, "els": [18, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 37, 38, 39, 40], "elto": 25, "email": 17, "emb": 38, "embd_pdrop": 28, "embed": [10, 23, 24, 27, 28, 30, 31, 36, 37, 38, 39, 40, 53], "embed_token": [24, 27, 30, 31, 36, 40], "embedding_dim": 23, "emerg": 27, "emmabortz": 37, "empti": [22, 24, 28, 37, 38], "empty_cach": 33, "en": [14, 18, 23, 30, 31, 37], "enabl": [0, 9, 10, 13, 14, 17, 18, 20, 22, 28, 37, 41], "enable_gqa": 21, "enable_grad": 29, "encod": [1, 18, 21, 22, 27, 37, 39, 41], "encoder_attention_mask": 21, "encoder_hidden_st": 21, "encoderdecodercach": 21, "encount": 18, "encourag": [26, 27, 29, 32, 33], "end": [10, 16, 22, 24, 25, 26, 27, 28, 30, 32, 35, 37], "end_header_id": 35, "end_it": 16, "endoft": 28, "endoftext": 28, "enforc": 13, "engin": [23, 32], "english": [29, 30], "enjoi": 28, "enough": [25, 27, 28, 32, 37, 38], "ensur": [10, 12, 17, 35, 38], "entangl": 26, "enter": [12, 13, 17, 25, 26, 27, 30, 36, 37], "entir": [17, 25, 26, 28, 31, 32, 33, 37, 40], "entropi": [28, 29, 37, 40], "entrypoint": 13, "enumer": [24, 25, 26, 27, 28, 29, 30, 38, 39], "env": [14, 18, 22, 30, 31, 37], "environ": [17, 22, 24, 28, 37], "envoi": [19, 37, 40], "eo": 35, "eos_token": 40, "eos_token_id": [10, 16, 26, 28, 37], "eot_id": 35, "ep": [23, 24, 27, 30, 31, 36, 37, 39, 40], "epoch": 29, "equal": [19, 28, 32, 36], "equit": 17, "equival": [12, 28], "era": [0, 37], "eras": 24, "erasure_effect": 24, "eric": 28, "error": [18, 22, 23, 28, 35, 37], "esp": 25, "espa\u00f1ol": 25, "especi": [28, 33, 41], "essenti": [28, 30], "est": 23, "establish": [13, 31], "estim": [31, 34, 39], "et": [24, 25, 26, 28, 33, 38], "etc": [17, 28, 37], "europ": 29, "eval": [24, 28], "evalu": [24, 26, 28, 29, 31, 32, 34, 40], "even": [25, 26, 27, 28, 30, 31, 32, 35, 37], "evenli": 37, "event": 19, "eventu": [28, 37], "ever": [28, 35], "everi": [7, 16, 17, 20, 25, 26, 28, 30, 31, 32, 37, 39, 41, 48], "everyon": 27, "everyth": [24, 26, 28, 33, 37], "everywher": 24, "evok": 28, "exact": [25, 28, 33], "exactli": [25, 28, 31, 32, 34, 37], "examin": [25, 28, 30, 33], "exampl": [0, 1, 10, 11, 13, 16, 17, 18, 19, 20, 23, 24, 25, 27, 28, 29, 32, 33, 34, 38, 40], "example_antonym": 28, "example_token": 26, "exc_tb": [18, 19, 22, 37], "exc_typ": [18, 19, 22, 37], "exc_val": [18, 19, 22, 37], "exce": [22, 37], "except": [17, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41], "exchang": 30, "excit": [28, 37], "exclud": 31, "execut": [0, 8, 10, 11, 13, 15, 18, 19, 20, 22, 30, 31, 35, 36, 40, 50], "exemplar": 28, "exercis": [23, 30, 33, 36, 38], "exercises_dir": 28, "exhibit": [26, 38], "exist": [22, 25, 28, 37], "exit": [0, 12, 19, 22, 36, 37], "exit_global_tracing_context": [18, 37], "exp": 24, "expand": 25, "expect": [14, 16, 23, 25, 28, 30, 31, 33, 35, 37], "expens": 30, "experi": [0, 1, 11, 16, 18, 25, 26, 28, 31, 32, 33, 37, 38, 52, 53], "experiment": [14, 37], "explain": [24, 27, 28, 32, 53], "explan": [25, 27, 28], "explanatori": 37, "explicit": [22, 37], "explicitli": [17, 22, 24, 28, 33, 37], "explor": [10, 14, 22, 27, 28, 30, 31, 33, 36, 37, 38, 39, 41, 50, 53], "expos": [9, 12, 29, 37], "exposur": 25, "express": [26, 27, 28, 30, 31, 32, 33, 39], "extend": [28, 37], "extens": 26, "extent": [32, 33], "exterior": 28, "extern": 28, "extra": [28, 35], "extract": [26, 27, 41], "f": [11, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 37, 38], "f00d": 37, "f1fc": 37, "f2aa84": 27, "f_api": 28, "fabric": [0, 37], "face": [23, 25, 28], "fact": [0, 28, 29, 32, 35, 37], "factor": 28, "factual": [27, 33], "fail": [21, 27, 28], "failur": 28, "fairli": [28, 37], "faith": [28, 32], "fake": [18, 27, 28, 37], "fake_mod": [18, 37], "fake_tensor": [18, 37], "fake_valu": [18, 37], "fakecopymod": [18, 37], "faketensormod": [18, 37], "fall": 28, "fals": [0, 7, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41, 48], "false_activ": 27, "false_activations_mean": 27, "false_token_id": 27, "famili": 40, "familiar": [27, 28, 37], "famou": [22, 26, 28], "fan": [25, 26], "fantast": 28, "far": [25, 28, 32], "farmer": 33, "fascin": 38, "fast": [8, 21, 23, 28, 37], "faster": [28, 37, 40], "fatal": 35, "favorit": 37, "fax": 37, "fb00": 40, "feasibl": 37, "featur": [0, 2, 9, 14, 21, 24, 27, 28, 30, 37, 41, 50], "fed": 28, "feedback": 37, "feel": [27, 28, 32, 34, 40], "felt": 28, "femal": 33, "fetch": [7, 13, 48], "fetch_attr": [7, 37, 48], "feucht": 25, "feucht_dual_route_induct": 1, "few": [0, 22, 25, 26, 27, 28, 29, 37, 38, 41], "ffaaaf3c": 24, "ffffff": [25, 27, 32, 33], "field": [26, 34, 37, 41], "fieri": 25, "fig": [24, 25, 26, 27, 30, 31, 33, 38, 39], "fig2": 30, "fig_a": 32, "fig_b": 32, "fig_c": 32, "figsiz": [24, 25, 38], "figur": [24, 25, 26, 27, 28, 32, 33, 38], "file": [17, 18, 19, 22, 28, 36, 37], "fill": [26, 28, 33], "filter": [25, 28], "final": [19, 24, 26, 27, 28, 30, 32, 33, 34, 36, 37, 38], "final_chat": 35, "final_layer_norm": 38, "final_token_index": 27, "find": [18, 23, 24, 26, 27, 28, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 53], "fine": [24, 37, 53], "finetun": 28, "finish": [24, 28, 38], "first": [10, 12, 13, 16, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30, 32, 33, 34, 38, 40, 53], "firstli": 28, "fit": [27, 28, 41], "fit_intercept": 27, "fit_transform": 27, "five": 25, "fix": [32, 37], "flag": [0, 18, 21, 25, 37], "flash": 21, "flat": 37, "flatten": [37, 38], "flaviu": 28, "flexibl": 28, "flight": 35, "flip": [27, 28, 33], "float": [21, 24, 25, 28, 31, 37, 40], "float16": [23, 25, 38], "float64": 27, "floattensor": [21, 34], "flock": 28, "floor": 25, "flow": [19, 29, 30, 37], "fluent": 26, "flush": [22, 37], "fmt": 25, "fn": [7, 22, 37, 48], "fn_vector": 28, "fn_vector_list": 28, "focu": [25, 27, 28, 32], "focus": [28, 39, 41], "folder": 37, "follow": [1, 13, 15, 16, 17, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 50, 53], "font": 25, "font_manag": 25, "fontsiz": [24, 38], "foo": 25, "food": 35, "fool": 26, "footag": 35, "forc": 25, "foreign": 28, "forest": 38, "forev": 28, "forg_vocab_s": 23, "forget": 28, "fork": [17, 22, 37], "form": [27, 28, 32, 33, 37, 41], "formal": 34, "format": [20, 22, 24, 26, 27, 28, 30, 31, 35, 37, 53], "format_exampl": 24, "formatted_chat": 35, "former": [7, 28, 37, 48], "forth": [17, 37], "forum": [0, 41, 50], "forward": [7, 10, 11, 12, 13, 14, 16, 21, 23, 25, 30, 31, 32, 33, 34, 37, 40, 48], "forward_cal": 37, "found": [14, 18, 24, 25, 28, 30, 31, 32, 33, 37, 38, 40], "four": 26, "fourth": 28, "fp16": 38, "fraction": 28, "frame": [22, 32, 37], "framework": [28, 29], "franc": [22, 28, 29, 33], "free": [27, 32, 34, 40], "freedom": 28, "freez": 28, "french": [28, 29], "freq_penalti": 28, "frequenc": 28, "friend": 28, "friendli": [28, 35, 37], "from": [0, 1, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 48], "from_list": 25, "from_pretrain": [25, 35, 40], "fromtok": 25, "front": 34, "frozen": 29, "ftfy": 38, "fulfil": 37, "full": [0, 2, 8, 11, 16, 21, 25, 28, 29, 30, 32, 34, 36, 37, 50, 52], "fulli": [37, 40], "fun": 28, "func": [18, 37], "function": [0, 1, 7, 13, 15, 21, 23, 24, 27, 30, 31, 32, 36, 39, 40, 48, 50], "function_nam": [22, 37], "functionmodel": [22, 37], "functions_whitelist": [22, 37], "functionwhitelisterror": [22, 37], "fund": 17, "fundament": [12, 32, 34], "funer": 41, "funni": [28, 32], "further": [25, 30, 31], "futur": [25, 28, 29], "fuzzi": 25, "fwd": 28, "g": [21, 25, 26, 27, 28, 29, 30], "gain": [11, 31, 39], "game": 37, "gameplan": 32, "garden": [10, 23], "gardient": 24, "gate": [17, 36, 37], "gate_proj": [24, 27, 30, 31, 36, 40], "gatewai": 28, "gather": [24, 31, 32], "gather_output": 23, "gave": [30, 31], "gc": 33, "gca": 25, "gelu_new": 28, "gen": 35, "gener": [8, 10, 11, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 35, 36, 38, 39, 40], "generate_antonym_dataset": 28, "generate_dataset": 28, "gennaro": 28, "geometri": [1, 33], "germani": 33, "get": [0, 7, 8, 9, 13, 15, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 48, 52], "get_causal_graph_of_toy_model": 32, "get_function_nam": [22, 37], "get_futur": 24, "get_height": 24, "get_igrad": 24, "get_intervent": 37, "get_l2_attn_weight": 25, "get_logit_diff": 31, "get_mean_head_valu": 25, "get_ov_sum": 25, "get_start": [50, 53], "get_toy_model": 32, "get_xtick": 25, "get_xticklabel": 25, "get_ytick": 25, "get_yticklabel": 25, "getattr": 21, "getattr_0": 21, "getcwd": 28, "giant": 29, "gift": 27, "gigabyt": 0, "git": [25, 28, 32, 34, 35, 41], "github": [0, 21, 25, 28, 32, 34, 36, 41, 50], "githubusercont": 27, "give": [0, 7, 22, 24, 25, 26, 27, 28, 32, 35, 37, 48, 50], "given": [7, 9, 11, 24, 25, 26, 28, 30, 31, 34, 35, 36, 37, 39, 40, 41, 48], "glimps": 39, "global": [18, 19, 22, 37], "globaltracingcontext": [18, 22, 37], "globaltracingexit": [18, 37], "glue": 40, "glyph": 25, "go": [0, 11, 17, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 40], "goal": 28, "goe": [28, 33], "gone": 25, "good": [28, 29, 33, 37], "googl": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41], "got": [17, 22, 28, 32, 37], "gotcha": 28, "gpt": [13, 16, 23, 28, 30, 31, 37], "gpt2": [1, 9, 10, 14, 16, 18, 21, 23, 30, 31, 33, 37, 39, 40], "gpt2_xl": 28, "gpt2attent": [21, 23], "gpt2block": [23, 30, 31, 37, 39], "gpt2lmheadmodel": [23, 30, 31, 37, 39], "gpt2mlp": [23, 30, 31, 37, 39], "gpt2model": [23, 30, 31, 37, 39], "gpt2sdpaattent": [30, 31, 37, 39], "gpt2token": 28, "gpt2tokenizerfast": 37, "gpt4": 28, "gpt_neox": [25, 26, 41], "gptj": 28, "gptjattent": 28, "gptjconfig": 28, "gptjforcausallm": 28, "gpu": [0, 23, 25, 26, 27, 28, 33, 36, 37, 38], "gqa": 25, "grab": [0, 10, 22, 30, 36, 37, 38], "grad": [13, 24, 31, 37], "grad_env": 29, "grad_fn": [11, 12, 15, 18, 21], "grade": 27, "gradient": [0, 8, 19, 23, 25, 28, 29, 31], "gradient_checkpoint": 28, "gradio": 28, "grain": 24, "grandios": 28, "grant": 39, "graph": [0, 13, 18, 21, 22, 24, 28, 30, 32, 37, 40], "graph_object": 27, "graphbasedcontext": 37, "graphmodel": [22, 37], "great": [16, 18, 26, 27, 28, 31, 32, 33, 38], "greater": [10, 33], "greatest": 28, "greatli": 37, "greedi": 28, "greedili": 28, "greek": 28, "green": [27, 28], "grid": [25, 32, 38], "grid_siz": 38, "grim": 41, "ground": [24, 29], "group": [24, 25, 27], "grow": [24, 41], "gsm8k": 24, "gt": [11, 12, 15, 18, 19, 21, 22, 24, 25, 28, 33, 35, 37], "guarante": [27, 28, 37], "guess": [28, 32, 33, 39], "gui": [25, 28], "guid": [28, 38], "guidanc": 28, "guidance_scal": 38, "guilti": 28, "gurne": 25, "h": [7, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 30, 31, 33, 35, 37, 39, 40, 48], "h1": [32, 34], "h11": 34, "h12": [32, 34], "h13": [32, 34], "h2": [28, 32, 34], "h21": 34, "h22": [32, 34], "h23": [32, 34], "h3": 32, "h31": 34, "ha": [7, 17, 19, 22, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 48], "hacki": 26, "had": [24, 25, 28, 32], "hagrid": 26, "half": [24, 25, 28, 37], "halfwai": 24, "halt": [11, 37], "hand": [12, 25, 28, 35, 36, 41, 52], "handi": [22, 30, 37], "handl": [17, 22, 24, 28, 37], "hang": 28, "hanoi": 27, "happen": [19, 24, 26, 27, 28, 30, 32, 33, 34, 37, 40], "happi": 26, "har": 24, "hard": [0, 27, 32, 34, 37], "harder": [28, 29, 32], "hardwar": 17, "harm": [26, 35], "harri": 26, "hasattr": 21, "hasattr_0": 21, "hat": 41, "hate": 28, "have": [1, 10, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 50], "haven": [28, 31], "he": [25, 27, 28], "head": [1, 24, 27, 30, 31, 32, 33, 39], "head_act": 25, "head_dict": 28, "head_dim": [21, 25], "head_idx": [25, 28, 30], "head_index": 33, "head_list": 28, "head_mask": 21, "head_mean": 25, "head_ord": 25, "head_set_vi": 25, "head_siz": 23, "headach": 37, "header": [22, 28, 37], "heads_to_abl": [25, 28], "heads_to_grab": 25, "heads_to_patch": 25, "heads_to_show": 25, "heads_to_sub": 25, "hear": 37, "heard": 25, "heart": [15, 28], "heatmap": [25, 30], "heavi": [25, 28], "hei": 28, "height": [24, 27, 28, 38], "helicopt": 35, "hello": [13, 22, 23, 28, 37], "help": [0, 1, 11, 14, 18, 21, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40, 41, 50], "helper": [24, 28], "henc": [11, 26, 28, 33, 37], "her": [28, 33], "here": [0, 10, 15, 16, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41], "heurist": 31, "hex": 27, "hex_color": 27, "hex_to_rgba": 27, "hf": 25, "hf_token": [17, 22, 24, 25, 30, 31, 37, 40], "hi": [25, 27, 28, 38], "hidalgo": 28, "hidden": [0, 1, 9, 12, 13, 14, 15, 16, 17, 18, 19, 22, 25, 26, 29, 30, 32, 33, 36, 37, 38, 40], "hidden_dim": [9, 27, 37], "hidden_s": [25, 33], "hidden_st": [0, 12, 13, 15, 16, 17, 21, 28, 36, 37, 38], "hidden_state_input": 9, "hidden_state_output": 9, "hidden_states1": [16, 37], "hidden_states2": [16, 37], "hidden_states3": 16, "hidden_states_grad": 13, "hidden_states_grad_aft": 13, "hidden_states_grad_befor": 13, "hide": [28, 38], "hierarch": 34, "hierarchi": [7, 16, 37, 48], "high": [24, 25, 27, 28, 32, 37, 41], "high_group_effort": 27, "high_group_grad": 27, "higher": [25, 28, 33], "highest": [16, 28, 37], "highli": 41, "highlight": [24, 28, 32], "hint": [28, 33], "historian": 28, "hm": [25, 29], "hold": [28, 32, 37, 38], "holdout": 28, "honest": 28, "hook": [7, 24, 31, 37, 48], "hook_id": 37, "hook_result": 37, "hookhandl": 37, "hope": [26, 28], "hopefulli": [28, 33], "horizon": 33, "horizont": 25, "host": [24, 25, 28, 31, 36, 37, 50, 53], "hot": 28, "hour": 17, "how": [1, 22, 23, 24, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 53], "howev": [16, 24, 27, 28, 29, 30, 32, 33, 34, 35, 37, 41], "hs11": [14, 37], "hs_1": 11, "hs_31": 37, "hs_79": 17, "html": [14, 18, 23, 28, 30, 31, 37], "http": [0, 2, 8, 14, 17, 18, 21, 23, 24, 25, 27, 28, 30, 31, 32, 34, 37, 41, 50, 52], "huang": 26, "huang_demystifying_memor": 1, "hub": 25, "hug": [23, 25, 28], "huge": [0, 32, 35, 36, 53], "huggingfac": [0, 17, 22, 24, 25, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 40], "huggingface_hub": [25, 26, 27, 29, 33], "human": [30, 35, 40, 41], "humbl": 28, "hurt": 35, "hybrid": 28, "hypo": 41, "hypothes": [25, 26], "hypothesi": [24, 28, 29, 33, 34, 38], "i": [1, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 41, 50, 53], "i0": 19, "icldataset": 28, "iclsequ": 28, "id": [21, 22, 24, 26, 28, 34, 36, 37, 39], "idea": [24, 25, 28, 29, 32, 34, 41], "ident": [28, 30], "identif": 30, "identifi": [27, 28, 29, 30, 33], "ideograph": 25, "idx": [24, 25, 28], "idxss": 25, "ignor": [7, 26, 28, 37, 38, 48], "igrad": 24, "ii": [20, 23, 53], "illustr": 28, "iloc": 27, "im": 24, "imag": [38, 41], "imagin": [27, 29, 32, 33, 34], "immedi": [0, 11, 22, 28, 32, 37], "immut": 19, "impact": [26, 30], "implement": [11, 13, 21, 32, 33, 36, 37, 38, 50], "implic": 19, "implicitli": [28, 31], "import": [0, 9, 10, 11, 14, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "importantli": 27, "importerror": [22, 23, 24, 26, 27, 29, 30, 31, 32, 35, 38, 39, 40, 41], "imposs": 28, "improv": [27, 28, 30, 35, 37], "imshow": [24, 26, 27, 28, 30, 31, 32, 33, 38, 39], "in_colab": 28, "in_feat": 28, "in_featur": [23, 24, 25, 27, 30, 31, 32, 36, 37, 39, 40, 41], "inabl": 28, "inal": 25, "includ": [16, 17, 20, 22, 23, 24, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 40, 50], "incorrect": [30, 31, 35], "incorrect_index": 30, "incorrect_logit": 31, "increas": [25, 28, 29, 30, 40], "increment": 37, "incur": [18, 28, 37], "inde": [27, 32, 37, 40], "indep": 28, "independ": [24, 25, 28, 37], "index": [18, 19, 24, 26, 27, 28, 29, 30, 32, 33, 37, 39, 40], "indexerror": [18, 28, 37], "indic": [0, 22, 24, 26, 27, 28, 29, 30, 31, 37, 40, 41], "indirect": [28, 30], "individu": [29, 30, 31, 32, 38, 41], "induc": [28, 30, 33], "induct": [1, 24], "infeas": 29, "infer": [0, 8, 23, 31, 34, 36, 37, 40, 53], "influenc": [30, 31, 32, 35, 37], "info": [17, 19, 24, 25, 26, 28, 36, 40], "inform": [0, 12, 16, 18, 19, 23, 24, 28, 30, 31, 32, 36, 37], "infrastructur": 30, "inher": 28, "init": [29, 37, 40], "initi": [10, 13, 16, 22, 28, 30, 37], "initializer_rang": 28, "inject": [0, 28, 37, 38], "injuri": [33, 35], "inlin": [21, 37], "inner": [22, 37, 38, 39, 40], "innoc": 28, "inplac": [7, 14, 28, 30, 31, 37, 39, 48], "input": [0, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "input1": 37, "input_featur": 23, "input_id": [24, 25, 26, 27, 28, 29, 30, 31, 33, 38, 39, 40], "input_layernorm": [24, 27, 30, 31, 36, 40], "input_s": [9, 37], "input_word": 39, "inquiri": 35, "inquisit": 35, "ins": 37, "insecur": 28, "insert": 28, "insid": [0, 13, 21, 26, 28, 37], "insight": [0, 31, 37, 38, 39], "inspect": [18, 32, 33, 37], "inspir": 33, "instal": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 53], "instanc": [7, 14, 27, 28, 37, 38, 48], "instanti": [21, 27, 36, 38], "instead": [0, 7, 13, 16, 17, 19, 20, 21, 25, 26, 27, 28, 29, 31, 32, 34, 36, 37, 40, 48], "instruct": [17, 25, 26, 33, 35, 37, 53], "instrument": 28, "int": [24, 25, 27, 28, 30, 32, 34, 37, 40], "integ": [28, 37], "integr": [13, 17, 23], "intemedi": [27, 32], "intend": [27, 28], "intens": [11, 18, 31], "interact": [0, 19, 28, 30, 34, 35, 36, 37, 40, 41], "interchang": [27, 32], "interest": [0, 11, 12, 13, 17, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 41], "interfac": 37, "interfer": 29, "interleav": [0, 18, 19, 22, 35, 37], "interleavingtrac": [18, 22, 35, 37], "intermedi": [8, 12, 13, 15, 17, 21, 24, 29, 32, 33, 34, 37, 38], "intern": [0, 9, 12, 23, 27, 28, 29, 31, 32, 33, 34, 37, 53], "internet": 28, "interpol": 24, "interpret": [1, 9, 28, 29, 30, 33, 34, 36, 37, 38, 41, 50, 52, 53], "interrup": 11, "interrupt": 11, "interven": [8, 10, 15, 19, 21, 24, 26, 32, 37], "intervene_logprob": 28, "intervene_token": 28, "intervene_with_fn_vector": 28, "intervene_with_h": 28, "intervened_logit": 33, "intervened_output": 32, "intervened_prob": 33, "intervened_prob_diff": 33, "intervent": [0, 2, 8, 9, 11, 12, 14, 17, 18, 19, 22, 24, 26, 27, 31, 32, 33, 35, 36, 40, 49, 53], "intervention_graph": 37, "intervention_handl": 37, "interventionnod": [18, 37], "interventionprotocol": 37, "interventionproxi": 37, "intro": 53, "introduc": [28, 30, 32, 38, 40], "introduct": 1, "introductori": [32, 33, 34], "intuit": [13, 24, 25, 28, 30, 33, 37], "invent": 9, "invert": 29, "invert_yaxi": 24, "investig": [23, 24, 26, 27, 28, 29, 33, 35, 37, 38], "invis": 28, "invoc": 30, "invok": [0, 9, 10, 18, 20, 22, 23, 30, 31, 36, 37, 39, 40], "invoker_arg": 37, "invoker_clean": 31, "invoker_corrupt": 31, "involuntarili": 41, "involv": [28, 30, 40], "io": [14, 18, 22, 25, 27, 29, 30, 31, 32, 37, 39], "ioi_metr": 31, "ioi_patching_result": 30, "ioi_patching_results_al": 30, "iprogress": [14, 18, 30, 31, 37], "ipykernel_80599": 37, "ipynb": [1, 8, 50, 53], "ipython": [11, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41], "ipywidget": [14, 18, 30, 31, 37], "is_avail": [28, 38], "is_caus": 21, "is_causal_item_0": 21, "is_colab": [22, 23, 24, 26, 27, 29, 30, 31, 32, 35, 36, 38, 39, 40, 41], "is_correct": 28, "is_cross_attent": 21, "is_improv": 28, "is_protocol": [18, 37], "is_trac": 21, "is_upd": 21, "ishmael": 41, "isinst": [18, 21, 37, 38], "isinstance_0": 21, "isn": [1, 16, 22, 23, 25, 26, 27, 28, 30, 33, 37, 38, 40], "isol": 38, "issu": [0, 18, 21, 25, 36], "istanbul": 28, "italian": [25, 28, 29], "italiano": 25, "item": [21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 40, 41], "item_2": 37, "iter": [20, 23, 24, 26, 28, 30, 33, 40], "iterat": 37, "itopl": 24, "its": [12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38], "itself": [28, 37, 40], "iz": 28, "j": [28, 30, 31], "jailbreak": 28, "jame": [28, 31], "japan": 27, "japanes": 25, "jaxtyp": 28, "jean": 28, "jerusalem": 28, "jit": 21, "job": [17, 22, 24, 26, 27, 28, 29, 30, 31, 36, 37, 40], "john": [30, 31], "join": [0, 26, 28, 36, 37], "josephu": 28, "jot": 27, "json": [22, 25, 35, 37], "jul": 35, "junior": 28, "jupyt": [14, 18, 28, 30, 31, 37], "just": [0, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 40], "k": [11, 12, 13, 21, 24, 25, 28, 33], "k_emb": 25, "k_layer_output": 12, "k_proj": [24, 25, 27, 28, 30, 31, 36, 40], "keep": [11, 17, 18, 24, 27, 28, 29, 32, 33, 34, 37, 40], "keepdim": [24, 25], "kei": [7, 18, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 48, 50], "kept": [24, 28], "kernel": [21, 24], "key_contiguous_0": 21, "key_stat": [21, 25], "key_states_view_0": 21, "key_states_view_1": 21, "keyword": [12, 28, 37], "kind": [7, 25, 28, 32, 37, 48], "kl": 24, "kl_div": 24, "knew": [26, 32], "knock": 41, "know": [22, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 40], "knowledg": [33, 35, 38, 40], "known": [25, 26, 27, 36], "krasnodar": 27, "kw": 25, "kwarg": [7, 12, 18, 21, 22, 28, 37, 48], "kwargs_get_0": 21, "kwargs_get_1": 21, "l": [15, 24, 25, 38], "l1": [32, 34, 37], "l178": 25, "l1_amax": 37, "l1_out": 37, "l1_output": [19, 37], "l1_output_aft": [19, 37], "l1_output_befor": [19, 37], "l2": [11, 24, 25, 32, 34, 37], "l2_inp": 19, "l2_input": 37, "l2_out": 37, "l2_output": 19, "l3": [32, 34], "l8h1": 28, "l_igrad": 24, "lab": [37, 38], "label": [24, 26, 27, 28, 30, 31, 39, 40], "label_to_str": 40, "ladrillo": 25, "lag": 37, "lambda": [24, 25, 30, 34, 37, 40], "landmark": [22, 28], "landscap": 38, "languag": [0, 1, 13, 27, 29, 30, 31, 32, 33, 36, 37, 40], "language_model": 23, "languagemodel": [0, 9, 10, 14, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 39, 40, 41], "laptop": 36, "larg": [0, 1, 17, 18, 22, 24, 27, 28, 29, 31, 32, 33, 36, 37, 38, 40], "larger": [25, 28, 30, 32, 37], "largescal": 30, "largest": 26, "last": [11, 14, 15, 16, 17, 18, 19, 21, 22, 25, 27, 29, 33, 37, 38, 40], "last_example_index": 27, "lastli": [28, 29], "late": 28, "latent": [25, 27], "later": [12, 16, 17, 24, 26, 28, 30, 32, 36, 37], "latest": 11, "latter": [7, 35, 37, 48], "lawsuit": 26, "layer": [0, 1, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 40, 41], "layer1": [9, 19, 37], "layer1_output_grad": 37, "layer2": [9, 19, 37], "layer2_output_grad": 37, "layer_attribut": 24, "layer_co": 24, "layer_cos_al": 24, "layer_diff": 24, "layer_idx": [21, 25, 26, 30, 33, 39], "layer_index": [27, 29], "layer_input": 24, "layer_log": 24, "layer_norm": 38, "layer_norm_epsilon": 28, "layer_output": [24, 39], "layer_token": 39, "layernorm": [23, 24, 28, 30, 31, 37, 39], "layers_in_ord": 25, "layerset": 25, "layout": 38, "lead": [23, 26, 28, 33], "leak": 26, "learn": [0, 24, 25, 26, 29, 32, 33, 36, 37, 50, 52, 53], "least": [18, 28, 37], "leav": [0, 18, 25, 27, 28, 37], "left": [10, 24, 28, 32, 34], "legend": 24, "len": [0, 15, 16, 18, 22, 23, 26, 27, 28, 30, 31, 32, 33, 37, 53], "lenght": 24, "length": [10, 16, 17, 22, 28, 30, 37], "lengthi": 18, "less": [28, 31, 33], "lesser": 28, "lesswrong": [28, 39], "let": [0, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 41, 53], "letter": 26, "level": [7, 16, 24, 25, 28, 32, 37, 48], "leverag": [23, 37], "li": 37, "li2": 37, "lib": [14, 18, 19, 22, 25, 30, 31, 37], "librari": [0, 13, 18, 23, 24, 28, 30, 31, 32, 34, 36, 37, 39, 41], "lie": 28, "life": 28, "lifelong": 25, "light": [25, 28, 29, 34], "light_blu": 27, "light_orang": 27, "lightweight": 53, "like": [0, 11, 12, 13, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 50], "likelihood": [28, 29], "likewis": 32, "limit": [24, 27, 28, 53], "linalg": 25, "line": [0, 11, 18, 19, 22, 25, 26, 27, 28, 35, 37, 40], "linear": [9, 24, 28, 30, 31, 32, 34, 36, 37, 39, 40, 41], "linear_model": 27, "linearli": 27, "linearsegmentedcolormap": 25, "linguist": 31, "link": [25, 28, 32, 37], "linkedin": [36, 37], "linspac": 27, "liquid": 28, "lisa": 30, "list": [1, 7, 16, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 39, 40, 48, 50], "listen": 37, "liter": 25, "literatur": 32, "littl": [25, 28, 33, 36, 37, 38, 41], "live": [17, 28, 35], "lk_out": 11, "ll": [10, 11, 17, 22, 25, 26, 27, 28, 29, 31, 32, 33, 34, 37, 38, 39], "llama": [0, 17, 22, 24, 25, 26, 29, 30, 31, 33, 35, 36, 37, 40, 50], "llama3": 17, "llamaattent": [24, 27, 36, 40], "llamadecoderlay": [24, 27, 30, 31, 36, 40], "llamaforcausallm": [24, 27, 30, 31, 36, 40], "llamamlp": [24, 27, 30, 31, 36, 40], "llamamodel": [24, 27, 30, 31, 36, 40], "llamarmsnorm": [24, 27, 30, 31, 36, 40], "llamarotaryembed": [24, 27, 30, 31, 36, 40], "llamasdpaattent": [30, 31], "llayer": 24, "llm": [1, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 53], "llm_edit": 37, "lm": [1, 24, 25, 27, 33], "lm_head": [9, 14, 15, 16, 17, 20, 22, 23, 24, 25, 27, 28, 30, 31, 36, 37, 39, 40], "ln_1": [23, 30, 31, 37, 39], "ln_2": [23, 30, 31, 37, 39], "ln_f": [15, 23, 30, 31, 37, 39], "load": [0, 16, 17, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 50], "load_dataset": [24, 40], "load_in_8bit": [24, 25], "load_state_dict": 41, "loc": 27, "local": [0, 8, 17, 19, 25, 27, 28, 29, 30, 31, 33, 36, 38, 53], "local_backend_execut": 37, "localbackend": 37, "localmixin": 37, "locat": [0, 10, 14, 21, 23, 27, 36, 37], "lodz": 27, "log": [17, 22, 24, 25, 27, 28, 29, 33, 36, 37, 40], "log_softmax": [24, 28], "logger": 21, "logger_warning_once_0": 21, "logic": [37, 38], "login": [17, 22, 24, 28, 30, 31, 35, 36, 37], "logisticregress": 27, "logit": [0, 13, 15, 17, 23, 25, 26, 27, 28, 29, 30, 31, 33, 36, 37, 40, 53], "logit_len": [25, 53], "logit_lens_result": 25, "logitlen": 24, "logitlens_oh": 24, "logits_as_input": 23, "logits_grad": 13, "logits_processor": 23, "logitsprocessor": 23, "logprob": [24, 28], "logprob_i": 28, "logprob_ni": 28, "logprobs_diff": 28, "london": [23, 28, 33, 36, 37], "long": [20, 25, 26, 28, 32, 41], "longer": [16, 28, 33, 40], "longtensor": 21, "look": [0, 15, 17, 19, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41], "lookup": 25, "loop": [16, 18, 27, 28, 30, 33], "loos": 28, "lora": [14, 53], "lora_dim": [37, 40], "lora_tutori": 53, "loss": [29, 37, 40], "loss_fn": 29, "lot": [0, 25, 28, 32, 33], "lout": 24, "love": [28, 29, 33, 37], "low": [17, 25, 27, 32, 33, 37, 40], "low_cpu_mem_usag": 25, "low_dim_activ": 27, "low_group_effort": 27, "low_group_grad": 27, "lower": [24, 25, 27, 33], "lowest": [24, 40], "lr": [37, 40], "lr_probe": 27, "lskip": 24, "lst": 27, "lstrip": 27, "lt": [11, 12, 15, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 35, 37, 38, 40], "luck": 25, "l\u00e1piz": 25, "m": [28, 35, 40], "machin": [0, 17, 22, 28, 32, 35, 37], "made": [14, 26, 28, 35, 37], "madison": [10, 23], "madrid": 28, "magenta": 34, "magic": 34, "magnitud": 29, "mai": [14, 16, 20, 22, 25, 26, 28, 29, 30, 31, 33, 34, 35, 37, 38, 41], "mail": 37, "main": [24, 25, 27, 28, 29, 30, 37, 38, 52], "mainli": 21, "mainprocess": 17, "maintain": 28, "major": [25, 28], "make": [0, 11, 13, 14, 18, 19, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41], "make_axes_locat": 24, "man": [28, 33], "manag": [0, 7, 28, 48], "mani": [0, 1, 24, 25, 27, 28, 29, 30, 32, 35, 37, 41], "manipul": [9, 22, 28, 34, 36, 37, 50], "manual": [15, 28, 37, 38], "manual_se": [25, 27, 29], "map": [24, 25, 28, 40], "maracai": 27, "margin": 27, "mari": [30, 31], "mark": [25, 27, 41], "markdown": 28, "marker": 27, "marks_geometry_of_truth": 1, "marri": 28, "martin": 31, "mask": [24, 28, 38], "mask_input": 38, "massiv": [0, 37], "match": [19, 20, 28, 32, 35, 37], "materi": [28, 35], "math": [25, 26, 28, 38], "mathemat": 28, "matita": 25, "matmul": [24, 25, 29, 37, 40], "matplotlib": [24, 25, 38], "matric": [25, 40], "matrix": [25, 28, 29, 30, 40], "matter": [8, 25, 32, 35, 37], "matton": 25, "max": [22, 24, 36, 37, 39, 41], "max_future_lay": 24, "max_future_out": 24, "max_length": [22, 28, 37, 38, 40], "max_logit": 28, "max_new_token": [10, 16, 22, 25, 26, 28, 35, 37], "max_prob": [22, 36, 37, 39], "max_tok": 25, "max_token": 23, "maxim": [27, 29], "maximum": [17, 24, 28, 36, 39], "maxsiz": 28, "mayb": [26, 29, 32], "mayor": 28, "mcdougal": 28, "me": [26, 28, 37, 41], "mean": [11, 16, 17, 18, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 37], "mean_high": 27, "mean_low": 27, "mean_low_transform": 27, "mean_mass_prob": 27, "mean_mass_probe_orthogon": 27, "mean_relative_contribution_att": 24, "mean_relative_contribution_lay": 24, "mean_relative_contribution_mlp": 24, "meaning": [25, 27, 29, 32, 33], "meant": 35, "measur": [9, 27, 28, 29, 32, 33], "measure_token_skip": 24, "mechan": [23, 24, 26, 31, 33, 34], "mechanist": 41, "media": [22, 37], "mediat": [25, 27, 53], "meet": [25, 41], "melt": 28, "member": [7, 22, 37, 48], "memo": [22, 37], "memoiz": [22, 37], "memor": 1, "memori": [18, 21, 24, 28, 37], "mention": [17, 19, 28, 37], "mento": 25, "merg": 24, "merge_io": 24, "mess": 29, "messag": [18, 28, 37], "messi": 31, "met": 37, "meta": [0, 17, 22, 24, 25, 26, 27, 29, 30, 31, 33, 35, 36, 37, 40], "metal": 35, "metaphor": 28, "method": [0, 13, 14, 16, 17, 18, 27, 28, 29, 31, 38, 40, 41], "methodolog": 28, "methodologi": 28, "metric": [24, 28, 31], "miami": 28, "mib": 25, "michael": 38, "middl": [25, 27, 28, 30, 32], "might": [25, 26, 27, 28, 29, 32, 33, 34, 41], "milk": 30, "mimic": 37, "min": [24, 26, 27, 28, 32, 33], "mind": [11, 26, 28, 33, 34, 41], "mini": [13, 52], "minimum": 28, "minneapoli": 28, "minu": 25, "minut": [25, 28, 33], "misc": 37, "misconcept": 35, "mispel": 26, "miss": [19, 25, 37], "misspel": 26, "mistak": [19, 28], "mix": [21, 28, 34], "ml": 37, "mlp": [0, 9, 20, 23, 24, 27, 30, 31, 33, 34, 36, 37, 39, 40, 41], "mlp_0": 41, "mlp_co": 24, "mlp_cos_al": 24, "mlp_input": 24, "mlp_out_layer0": 41, "mlp_output": 24, "mmlu_quest": 26, "mmlu_question_different_numb": 26, "mmlu_question_reord": 26, "mock": [18, 20], "mode": [22, 27, 28, 29, 37], "model": [0, 1, 2, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 22, 27, 31, 41, 49, 53], "model_answer_id": 26, "model_complet": 28, "model_dim": [25, 29], "model_doc": 37, "model_dump": [22, 37], "model_edit": [8, 14], "model_from_huggingfac": 17, "model_hidden_dim": 29, "model_kei": [22, 37], "model_max_length": 38, "model_nam": [24, 25, 40], "model_s": 25, "model_typ": 28, "modeling_llama": 25, "modern": [27, 28, 33], "modif": 28, "modifi": [14, 17, 18, 25, 28, 30, 36, 37, 40], "modified_output": [18, 28], "modified_token": [14, 37], "modul": [0, 7, 8, 9, 10, 11, 12, 13, 16, 18, 19, 21, 28, 37, 40, 48, 49], "module_path": [19, 37], "modulelist": [23, 24, 27, 30, 31, 36, 37, 39, 40], "moment": 28, "monei": 41, "monosemant": 41, "montreal": 28, "moral": 41, "more": [0, 11, 12, 16, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 36, 37, 38, 39, 40, 41, 50], "morn": 25, "moscow": 28, "most": [0, 11, 12, 18, 19, 21, 22, 25, 28, 31, 37, 41], "mostli": [25, 28], "motiv": [29, 32], "mouth": 41, "move": [16, 17, 26, 28, 31, 33, 37, 38], "movi": 40, "mp": [12, 16, 18, 28, 37], "mpl_toolkit": 24, "mr": [26, 28], "msgspec": [22, 24, 35, 37, 38], "much": [24, 25, 26, 28, 30, 31, 32, 33, 37, 40], "mueller": 41, "multi": [11, 23, 25, 37], "multihead": 30, "multilay": 40, "multipl": [8, 10, 13, 14, 17, 20, 24, 30, 34, 36, 38, 41, 50, 53], "multiple_token": 8, "multipli": [25, 28, 40], "mumbai": 28, "music": 35, "must": [13, 19, 21, 24, 25, 28, 32, 33, 36, 37, 50], "mv": 28, "my": [25, 28, 35, 41], "my_antonym_pair": 28, "my_decoding_funct": [22, 37], "my_local_fn": [22, 37], "myfil": 37, "myopia": 28, "myself": [25, 28, 41], "n": [16, 22, 24, 25, 26, 27, 28, 29, 31, 32, 37, 40], "n_chunk": 24, "n_comparison": 28, "n_compon": 27, "n_embd": [28, 33], "n_exampl": 24, "n_head": [25, 28, 30, 33], "n_inner": 28, "n_layer": [28, 30, 33], "n_new_token": [16, 37], "n_patching_dim": 29, "n_posit": 28, "n_prepend": 28, "n_step": 24, "n_token": 28, "na": 28, "nactual": 28, "naiv": 26, "name": [11, 18, 21, 22, 26, 27, 28, 30, 35, 37], "nameerror": 11, "nanda": 31, "narrow": [33, 37], "nation": [0, 37], "natur": [30, 40], "nclean": [23, 31], "ncorrupt": 23, "ncsa": 17, "ndi": 28, "ndif": [0, 2, 8, 18, 24, 25, 26, 28, 30, 31, 33, 37, 40, 50, 52, 53], "ndif_api": [17, 22, 24, 28, 30, 31, 36, 40], "ndif_team": 37, "ndim": 21, "nearest": 24, "neat": 37, "neatli": 27, "necessari": 28, "necessarili": 37, "need": [7, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 48, 50], "neel": 31, "neg": [24, 27, 28, 40, 41], "negat": [27, 28], "neighbor": 32, "neither": [28, 33], "nest": [28, 37], "net": [9, 17, 19, 24, 28, 37, 50], "netherland": 28, "network": [0, 9, 24, 25, 29, 30, 33, 34, 36, 37, 40, 41], "neural": [0, 9, 25, 26, 29, 33, 34, 36, 37, 40, 41], "neural_network": 34, "neuron": [29, 32, 33, 41], "neuron_indic": 29, "never": [11, 17, 18, 28, 37, 40, 41], "nevertheless": [26, 34], "new": [8, 10, 13, 14, 16, 18, 19, 22, 24, 25, 26, 28, 29, 34, 35, 37, 40, 52], "new_base_answ": 29, "new_base_loss": 29, "new_base_prompt": [29, 33], "new_gui": 25, "new_h23_valu": 32, "new_log": 24, "new_shap": 28, "new_source_propmt": 33, "new_tensor": 19, "new_valu": 28, "newgelu": 23, "newgeluactiv": [30, 31, 37, 39], "newli": 28, "newlin": [22, 25, 37], "newline_token_id": 27, "newsworthi": 37, "next": [10, 14, 20, 23, 25, 27, 28, 29, 30, 31, 32, 33, 38, 39, 40, 53], "next_tok_id": 28, "nfor": 28, "nh": 30, "nice": [28, 31, 37], "niec": 37, "night": 28, "nin": 28, "nina": 28, "nlist": 37, "nlp": 40, "nn": [9, 21, 22, 24, 28, 29, 34, 37, 39, 40, 41], "nnsight": [1, 2, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 31, 32, 33, 35, 38, 39, 40, 41, 49, 50, 52, 53], "nnsight_remot": [17, 24, 26, 36, 40], "nnsighterror": [28, 37], "nnsightexcept": 19, "nnsightmodel": 37, "no_grad": [24, 25, 26, 27, 29, 32, 33, 38], "no_skip_front": 24, "no_stop_exc_tim": 11, "node": [0, 18, 22, 34, 37], "node_class": [18, 37], "nodemodel": [22, 37], "nois": 18, "noisi": 28, "non": [21, 22, 25, 28, 30, 37], "non_blocking_request": [22, 37], "non_rand_int": 37, "none": [7, 16, 18, 19, 21, 22, 24, 25, 28, 34, 37, 40, 48], "nonsens": 25, "norigin": [14, 18, 37], "norm": [24, 25, 27, 30, 31, 36, 38, 40], "normal": [0, 18, 19, 24, 25, 26, 27, 28, 30, 31, 37, 39, 40], "north": [28, 29], "northeastern": 25, "northern": 25, "nostalgebraist": [25, 39], "not_base_a": 32, "not_base_b": 32, "not_base_c": 32, "note": [10, 12, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 41], "notebook": [1, 8, 17, 24, 25, 27, 28, 29, 30, 31, 32, 33, 36, 39, 50, 53], "notebook_connect": [27, 29, 30, 31, 32, 39], "notebook_login": [25, 26, 27, 29, 33], "notebook_tqdm": [14, 18, 30, 37], "noth": [29, 32, 41], "notic": [0, 19, 28, 32, 37], "notif": 36, "notimplementederror": 28, "noun": 38, "novemb": 41, "now": [14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 50], "np": [27, 28, 39], "npredict": 40, "nproblem": 24, "nprompt": 24, "nresid": 28, "nsf": 17, "nt1": [17, 37], "ntodai": 26, "ntoken": 37, "nube": 25, "null": 28, "nullifi": 38, "num": 37, "num_attention_head": [25, 33], "num_embed": 23, "num_embeddings_pad": 23, "num_exampl": 27, "num_examples_with_effect": 32, "num_head": [23, 28], "num_hidden_lay": [25, 26, 27, 33, 38], "num_imag": 38, "num_inference_step": 38, "num_key_value_group": [21, 25], "num_key_value_head": 25, "num_kv_head": 23, "num_per_class": 27, "num_to_displai": 28, "num_token": [26, 28, 33], "number": [16, 24, 26, 27, 28, 32, 33, 34, 37, 38, 40, 41], "number_of_token": 18, "numer": [38, 40], "numpi": [24, 25, 27, 28, 31, 39], "nurs": 33, "nuvola": 25, "nyou": 26, "nyour": 24, "o": [11, 17, 24, 25, 28, 33, 35, 37], "o_proj": [24, 25, 27, 30, 31, 33, 36, 40], "o_proj_in": 25, "o_proj_inp": 25, "obj": [7, 37, 48], "object": [0, 7, 9, 12, 16, 17, 19, 24, 25, 29, 30, 35, 37, 39, 40, 48], "observ": [25, 28, 30, 38, 39], "obtain": [22, 24, 28, 30, 37, 39, 40], "obviou": 28, "occur": [11, 22, 28, 37], "occurr": 30, "ocean": 38, "oclass": 24, "odd": [31, 37], "off": [18, 26, 28, 33, 37, 38, 41], "offer": [17, 37], "offici": [22, 37], "offload": [27, 29, 33], "offset": 25, "often": [19, 28, 35, 37], "oftentim": 32, "oh": [28, 37], "okai": [21, 27, 30, 32, 33, 36], "old": [16, 28, 37], "omit": 25, "onc": [16, 17, 18, 25, 28, 31, 32, 36, 37, 38, 40], "one": [0, 7, 8, 10, 12, 16, 17, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 48], "one_hot": 24, "ones": [8, 24, 25, 27, 28, 29, 37], "onion": 28, "onli": [11, 12, 13, 17, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 37, 38, 40, 41], "onlin": 28, "onto": 37, "onward": 24, "ood": 28, "op": 25, "opac": 27, "opalesc": 25, "opaqu": [0, 28], "open": [0, 2, 8, 10, 16, 25, 26, 28, 36, 37, 50, 52], "openai": [9, 10, 14, 16, 18, 21, 24, 28, 30, 31, 37, 39, 40], "openai_api_kei": 28, "oper": [0, 10, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31, 32, 33, 36, 38, 40], "opinion": 27, "opportun": [0, 28], "oppos": 28, "opposit": [13, 28, 30], "oprob": 24, "opt": [14, 18, 22, 30, 31, 37], "optim": [0, 10, 17, 28, 29, 32, 37, 40], "optimist": 28, "option": [14, 21, 24, 25, 29, 37, 40], "orang": 27, "orb": 25, "order": [0, 8, 10, 13, 15, 17, 27, 28, 33, 35, 36, 37, 38, 40], "ordereddict": [9, 37], "ordinari": [0, 37], "ordinarili": 0, "org": 28, "org_vocab_s": 23, "orig": 24, "orig_output": 24, "origin": [7, 9, 10, 14, 17, 18, 19, 24, 25, 26, 27, 28, 29, 30, 32, 33, 37, 38, 39, 40, 41, 48], "original_output": [18, 28], "original_token": [14, 37], "ortherwis": 24, "orthogon": [24, 29], "orthogonal_": 29, "ostensibli": 37, "other": [0, 12, 17, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38], "other_input": 28, "otherwis": [18, 21, 22, 24, 25, 28, 32, 33, 37], "otopl": 24, "our": [0, 1, 8, 13, 16, 17, 18, 19, 22, 23, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 41, 50, 52, 53], "ourselv": 32, "out": [0, 2, 7, 8, 11, 13, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 48, 50, 52], "out_diff": 24, "out_feat": 28, "out_featur": [24, 25, 27, 30, 31, 32, 36, 37, 39, 40, 41], "out_logit": 24, "out_proj_output": 28, "outag": 17, "outcom": [27, 28, 30], "outofordererror": 19, "outperform": [28, 31], "output": [0, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "output_attent": 21, "output_featur": 23, "output_hook": 37, "output_logit": 36, "output_s": [9, 37], "outright": 19, "outsid": [28, 37], "ov": 25, "ov_len": 25, "ov_sum": 25, "over": [24, 25, 26, 27, 28, 29, 32, 33, 34, 37, 40], "overal": [36, 40], "overlap": [24, 28], "overrid": 28, "overridden": [7, 48], "overrod": 34, "overview": [0, 32, 36], "overwrit": [24, 28], "own": [0, 15, 17, 18, 21, 25, 33, 37, 38, 40, 53], "p": [21, 26, 27, 28, 30, 31, 33, 37, 39], "pack": 25, "packag": [7, 9, 14, 17, 18, 19, 22, 25, 30, 31, 36, 37, 40, 48, 50], "pad": [10, 24, 37, 38, 40], "pad_token": [28, 40], "pad_token_id": [10, 16, 26, 37], "page": [0, 23, 25, 27, 28, 29, 33, 36, 37], "pagedattent": 23, "pagin": 51, "pai": 26, "paid": 38, "pain": 33, "pair": [32, 33, 35, 37], "pairwis": 24, "palac": [17, 37], "panda": [27, 40], "paper": [13, 24, 25, 26, 27, 29, 33, 38, 52], "paradigm": 32, "parallel": [17, 22, 25, 28, 37], "paramet": [0, 7, 17, 23, 26, 27, 28, 29, 32, 33, 36, 37, 38, 40, 41, 48, 53], "parametr": 29, "parent": [7, 28, 34, 48], "pari": [14, 15, 16, 22, 23, 28, 29, 33, 36, 37], "park": 31, "part": [24, 26, 28, 30, 34, 36, 37, 40, 41], "part42_function_vectors_and_model_st": 28, "particip": 28, "particular": [25, 28, 29, 31, 35, 37, 41], "particularli": [11, 18, 29, 30, 37], "pass": [7, 8, 10, 11, 12, 13, 14, 16, 20, 21, 23, 25, 27, 30, 31, 32, 33, 34, 35, 36, 37, 40, 48], "passag": [26, 33], "passion": 37, "past": [25, 28], "past_key_valu": 21, "past_key_value_is_updated_get_0": 21, "patch": [0, 7, 10, 13, 19, 28, 29, 32, 33, 48, 49, 53], "patch_end": 26, "patch_linear_subspac": 29, "patch_start": 26, "patched_diff": 27, "patched_false_prob": 27, "patched_logit": [26, 29, 30], "patched_logit_diff": 30, "patched_prob": [26, 27, 29], "patched_result": 30, "patched_true_prob": 27, "patcher": [7, 18, 37, 48], "patching_per_lay": 27, "patching_result": [26, 27, 31], "patching_results_per_lay": 26, "path": [0, 7, 28, 32, 33, 34, 48], "pathlib": 28, "pattern": [25, 28, 32, 38], "paul": 28, "paus": [35, 41], "pca": 27, "pd": [27, 40], "pedestrian": 28, "peft": 40, "penal": 28, "penalti": 28, "penguin": 38, "penultim": 38, "peopl": [27, 28, 29, 33, 38, 41], "per": [28, 31], "per_layer_result": 26, "perceptron": 40, "perf_count": 11, "perfect": 28, "perfectli": [25, 26], "perform": [7, 10, 15, 16, 19, 23, 27, 28, 30, 31, 32, 33, 34, 35, 36, 48], "perhap": [29, 32, 33], "period": 30, "permiss": [25, 27, 29, 33], "perplex": 28, "persist": [8, 12, 14, 37], "person": 28, "perturb": 28, "pessimist": 28, "phase": 28, "phenomenon": [25, 41], "photograph": 28, "phrase": [28, 40], "physic": [25, 32], "pick": [27, 28, 32, 33], "pickl": 25, "pictur": 24, "piec": [28, 32, 35, 37], "pil": 38, "pile": 26, "pilot": 50, "pio": [27, 29, 30, 31, 32, 39], "pip": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 50], "pipelin": [0, 31, 35, 38], "place": [13, 14, 17, 25, 26, 28, 32, 36, 37, 40], "placehold": 37, "plai": [0, 25, 26, 27, 28, 29, 32, 33, 34, 35, 38], "plain": 28, "plan": [12, 17, 28, 38], "plastic": 35, "pleas": [1, 14, 17, 18, 21, 23, 25, 27, 28, 29, 30, 31, 33, 36, 37, 38, 50], "pleasur": 25, "plot": [24, 26, 27, 28, 30, 31, 32, 33, 38], "plot_effect": 24, "plot_igrad": 24, "plot_ioi_patching_result": 30, "plot_layer_diff": 24, "plot_logit_diff": 24, "plot_logit_effect": 24, "plot_patching_result": 26, "plot_residual_stat": 24, "plot_titl": 30, "plotli": [26, 27, 28, 29, 30, 31, 32, 33, 39], "plotly_mimetyp": [27, 29, 30, 31, 32, 39], "plotly_util": 28, "plt": [24, 25, 38], "plu": 28, "plug": [31, 32, 34], "po": [28, 31, 40], "poet": 25, "point": [11, 24, 25, 28, 30, 32, 33, 34, 37], "pointer": 28, "poland": 27, "pop": [18, 22, 37], "popul": [12, 37, 40], "popular": [23, 40], "portug": 29, "portugues": 29, "pose": 28, "posit": [12, 24, 25, 26, 27, 28, 30, 33, 37, 39, 40], "position_embed": 25, "position_id": 25, "positional_embed": 25, "possibl": [17, 21, 22, 24, 28, 35, 37, 41], "possibli": [25, 28], "post": [16, 26, 31, 37, 39, 41], "post1": 23, "post_attention_layernorm": [24, 27, 30, 31, 36, 40], "potenti": [24, 28, 29, 37, 40], "potter": 26, "power": [28, 33, 34, 37, 39], "practic": [31, 32, 37], "prbabil": 33, "pre": [24, 25, 37, 40, 41], "precis": [25, 29, 31, 41], "predict": [0, 14, 17, 24, 26, 27, 28, 30, 33, 34, 37, 39, 40], "predicted_token_id": 28, "predictor": 27, "prefer": [25, 26, 27, 28, 32, 33, 34, 36], "prefil": 35, "premis": 35, "prepar": [10, 17, 27, 37, 53], "prepare_input": [18, 37], "prepared_input": 37, "prepend": 28, "preposit": 30, "preprocess": [22, 35, 37], "present": 28, "preserv": [14, 37], "press": [22, 37], "presum": 27, "pretoken": 36, "pretrain": [38, 41], "pretrained_dictionary_download": 41, "pretti": [0, 28, 33, 36, 37, 38], "prevent": [21, 41], "previou": [10, 16, 20, 24, 25, 26, 28, 31, 33, 37], "previous": [16, 28, 37], "primarili": 28, "principl": [37, 41], "print": [0, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40], "print_figur": 25, "print_k": 25, "prior": [10, 13, 20, 25, 31, 37], "privat": 28, "privet": 26, "prob": [22, 25, 27, 33, 37, 39], "probabl": [22, 24, 25, 26, 27, 28, 29, 32, 33, 37, 39], "probe": [22, 28, 37, 53], "probe_i": 27, "probe_x": 27, "problem": [24, 30, 34, 37], "probs_lay": 39, "probss": 25, "procedur": [29, 30], "process": [10, 16, 17, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 37, 38, 39, 40], "produc": [16, 28, 37, 38], "product": 28, "prof": 27, "profession": 28, "profit": 28, "profoundli": 37, "program": [28, 50], "progress": [30, 38], "progress_bar": 29, "proj": 33, "proj_onto_ov": 25, "projd": 25, "project": [0, 1, 25, 27, 28, 30, 31, 33, 37, 38, 50, 52], "promin": 41, "promis": 28, "promot": 25, "prompt": [0, 8, 11, 13, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 37, 38, 39, 40, 41], "prompt2": 28, "prompt_2": 20, "prompt_id": [26, 30], "prompt_templ": [26, 27, 28], "prompt_token_id": 27, "promtps_10": 24, "propag": 37, "proper": 10, "properti": [16, 29, 37], "protocol": [10, 18, 37], "proud": 26, "prove": 28, "provid": [0, 17, 20, 22, 23, 24, 25, 27, 28, 32, 34, 35, 37, 39, 50], "proxi": [10, 18, 22, 28, 30, 37], "proxy_class": [18, 37], "pt": [28, 30, 31, 38, 40, 41], "public": [17, 25, 36, 50], "publicli": 31, "publish": 1, "punctuat": [26, 27], "punctuation_index": 27, "punctuation_token_id": 27, "punish": 28, "purpl": [25, 27], "purpos": [22, 28, 32, 37], "purposefulli": [32, 33], "purs": 41, "push": 28, "put": [27, 32, 33, 34, 37, 50], "puzzl": 32, "px": [26, 27, 30, 31, 32, 33, 39], "py": [11, 14, 18, 19, 22, 25, 30, 31, 37], "pyarrow": 40, "pydant": 28, "pylabtool": 25, "pyplot": [24, 25, 38], "pythia": [25, 26, 28, 41], "python": [0, 19, 24, 28, 35, 36, 37, 38], "python3": [14, 18, 19, 22, 25, 30, 31, 37], "pytorch": [0, 9, 18, 21, 28, 37], "q": [24, 25, 26, 28, 33], "q3": 28, "q_attn": 21, "q_emb": 25, "q_proj": [24, 25, 27, 28, 30, 31, 36, 40], "qcfg": 25, "qkvparallellinear": 23, "qualit": [24, 28], "qualiti": 28, "qualnam": [22, 37], "quantiti": 24, "quantiz": 25, "quantization_config": [24, 25], "queri": [21, 25, 28], "query_contiguous_0": 21, "query_st": [21, 25], "query_states_view_0": 21, "question": [8, 24, 25, 26, 28, 29, 32, 35, 36, 52], "question_premis": 26, "question_premise_id": 26, "queue": [17, 37], "quick": [25, 28, 31, 36], "quickli": [25, 28, 37], "quiet": 28, "quit": [26, 28, 32, 33, 35, 37], "r": [24, 25, 28, 37, 40, 41], "r1": [36, 50], "rais": [18, 19, 21, 22, 28, 37], "ram": [0, 38], "ran": [19, 37], "rand": 37, "rand_int": 37, "randint": 37, "randn": [37, 40], "random": [24, 25, 26, 27, 28, 29, 32, 34, 37, 38], "random_activ": 26, "random_ord": 28, "random_pair": 28, "random_st": 27, "randomli": [28, 32], "rang": [16, 20, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 38, 39, 40], "rank": [25, 37, 40], "rapidli": 24, "rather": [24, 28, 31, 33, 35, 40], "ratio": [27, 28, 33], "ravel": 29, "raw": [25, 27, 34], "raw_head_activ": 25, "raw_input": 34, "raw_output": 34, "rc_att": 24, "rc_layer": 24, "rc_mlp": 24, "rdbu": [30, 31], "rdylbu_r": 39, "re": [13, 16, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 38, 40], "reach": [17, 33], "read": [0, 2, 8, 25, 26, 27, 28, 29, 31, 32, 33, 37, 39, 50, 52], "read_csv": 27, "readabl": 28, "readi": [36, 38], "readlin": 28, "readthedoc": [14, 18, 30, 31, 37], "real": [0, 11, 18, 23, 37], "real_oh": 24, "realli": [17, 28, 32, 37], "realtiv": 24, "rear": 41, "rearrang": [28, 30, 31], "reason": [24, 26, 27, 28, 29, 34], "recal": 33, "receiv": [17, 22, 24, 25, 26, 30, 31, 36, 37, 40], "recent": [1, 11, 18, 19, 22, 26, 28, 37, 52], "reciev": 36, "recip": [7, 48], "recit": 26, "recommend": [17, 20, 25, 26, 27, 28, 36], "record": [18, 30, 37], "recov": 33, "recreat": [1, 26, 27, 33], "recurs": [16, 21, 28, 37], "red": 25, "redefin": 28, "redirect": [18, 37], "reduc": [24, 26, 28, 31, 37], "reduce_result": 23, "ref": [27, 28], "refer": [17, 21, 23, 27, 28, 30, 32, 33, 36, 37, 50], "referenc": 19, "refin": [24, 38], "reflect": [31, 37], "refus": [28, 30], "regist": [7, 17, 37, 48], "registr": [36, 50], "regress": 21, "regul": 41, "regular": [0, 29, 37], "reject": 28, "rel": 26, "relat": [28, 30, 31, 32, 33, 37], "relationship": [28, 41], "relative_contribution_att": 24, "relative_contribution_lay": 24, "relative_contribution_mlp": 24, "relative_diff": 24, "releas": [22, 37], "relev": [32, 37], "reli": 28, "remain": [24, 30], "rememb": [26, 28, 32], "remind": 28, "remot": [0, 8, 13, 18, 24, 25, 26, 27, 30, 35, 40, 53], "remote_execut": 8, "remote_graph": [22, 37], "remote_log": [22, 35, 36, 37], "remotebackend": [22, 37], "remov": [14, 24, 26, 28, 35, 37], "render": [11, 27, 29, 30, 31, 32, 39], "reorder_and_upcast_attn": 21, "repeat": [24, 25, 26, 28, 30, 32], "repeat_cutoff": 25, "repeat_kv": [21, 25], "repeat_kv_0": 21, "repeat_kv_1": 21, "repeated_ratio": 25, "repeatedli": 37, "repetit": 28, "repetition_penalti": 28, "replac": [7, 10, 17, 18, 19, 20, 24, 25, 28, 29, 30, 33, 34, 37, 38, 40, 48], "replacement_output": 20, "repli": 35, "replic": [25, 26, 33, 38], "repo": [25, 28], "report": [0, 35, 38], "reporterus": 35, "repositori": 41, "repr": 28, "repres": [7, 25, 27, 28, 30, 32, 34, 38, 40, 48], "represent": [26, 27, 28, 31, 33, 34, 38, 40, 41], "reproduc": [24, 27, 28, 29], "republ": 27, "repurpos": 28, "request": [0, 17, 18, 19, 22, 25, 27, 28, 29, 33, 37, 52], "requestmodel": [22, 37], "requir": [10, 13, 16, 17, 23, 28, 30, 31, 32, 35, 36, 37, 41], "requires_grad": [13, 31, 37, 40], "requires_grad_": [24, 37], "reread": 25, "rerun": 38, "res_kl_div": 24, "res_overlap": 24, "rescu": [29, 35], "research": [0, 1, 17, 28, 30, 31, 33, 36, 37, 50, 53], "reset": [22, 37], "reshap": [21, 25, 28, 30], "resid": [17, 26, 28], "resid_dropout": [21, 30, 31, 37, 39], "resid_pdrop": 28, "residu": [25, 27, 28, 30, 31, 32, 33], "residual_attr": 31, "residual_log": 24, "resiz": [30, 38], "resolv": [25, 33], "resolved_sent": 33, "resourc": [17, 25, 31, 36, 37, 41], "respect": [12, 28, 31, 32, 37], "respond": [26, 30, 35, 41], "responisbl": 40, "respons": [19, 22, 24, 25, 26, 27, 28, 30, 32, 33, 37], "rest": [11, 28, 32, 37], "restart": [25, 26, 38], "restaur": 28, "restor": [7, 14, 32, 37, 48], "restrict": 17, "result": [0, 1, 13, 17, 19, 21, 22, 24, 27, 29, 31, 32, 33, 34, 36, 37, 39, 40], "retain": 13, "retain_grad": 13, "retain_graph": 13, "retriev": [7, 37, 40, 48], "return": [7, 12, 16, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 40, 48], "return_context": 37, "return_dict": 35, "return_length": 38, "return_overflowing_token": 38, "return_tensor": [28, 30, 31, 38, 40], "reus": 25, "reusabl": 24, "reveal": [30, 38], "revers": [13, 25, 27, 28, 32, 38], "revert": [14, 37], "review": 40, "reward": 28, "rewrit": 28, "rgb": 27, "rgba": 27, "rich": 28, "rid": 28, "right": [24, 26, 28, 32, 33, 34, 37], "rightmost": 27, "rigid": 28, "rigor": [26, 28, 32], "rimski": 28, "rindex": 27, "rio": [29, 33], "rlhf": 28, "rm": 28, "rmdir": 28, "robot": 28, "robust": 28, "robustli": 28, "rock": 28, "role": [0, 26, 27, 28, 32, 33, 34, 35], "rome": [14, 28, 37], "room": 38, "root": [7, 28, 37, 48], "root_dir": 28, "rotari": 28, "rotary_dim": 28, "rotary_emb": [24, 27, 30, 31, 36, 40], "rotat": [24, 25, 29], "rotate_half": 25, "rotated_bas": 29, "rotated_patch": 29, "rotated_sourc": 29, "rotation_mod": 24, "rough": 28, "roughli": [26, 27, 33, 34], "round": [16, 32, 34], "rout": 1, "row": [24, 25, 27], "rowparallellinear": 23, "rprint": 28, "rubber": 41, "rule": 28, "run": [0, 7, 10, 11, 15, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 37, 40, 48, 53], "run_logitlen": 24, "run_on_ndif": 25, "runner": 37, "runtim": [25, 26, 27, 37], "russia": 27, "rx": 37, "s1": 30, "s2": 30, "sae": [11, 37, 53], "safe": [14, 37], "safeti": 28, "sai": [10, 20, 25, 26, 28, 32, 34, 37], "said": [28, 32, 35, 53], "sail": 41, "same": [0, 7, 10, 13, 16, 17, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 48], "sampl": 24, "sampler": 23, "sampling_kwarg": 28, "samuel": 41, "san": 25, "saprmark": [27, 41], "sarah": 30, "sartr": 28, "satisfi": 28, "save": [0, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "saw": [26, 27, 32, 33], "sa\u026at": [9, 50], "sc": 28, "scalabl": [23, 31, 37], "scale": [0, 17, 21, 23, 24, 28, 30, 31, 36, 37, 41], "scale_attn_weight": 28, "scaleanchor": 27, "scaled_dot_product_attent": 21, "scaleratio": 27, "scan": [8, 40], "scan_valid": 8, "scatola": 25, "scatter": 27, "scenario": 37, "scene": 37, "schema": [2, 22, 37], "scope": 37, "score": [27, 28], "scratch": 28, "scream": 33, "screen": 35, "script": 25, "sd1": 38, "sdpa": 21, "sdpa_attention_forward": 21, "sdpa_kwarg": 21, "sdxl": 38, "se": 25, "sea": 41, "seaborn": 25, "seamlessli": 37, "search": [28, 32, 33], "second": [10, 13, 24, 25, 26, 28, 30, 32, 37, 38], "secondli": 28, "secret": [17, 22, 24, 25, 28, 30, 31, 35, 36, 37, 40], "section": [16, 25, 27, 28, 31, 32, 33, 37, 38], "section_dir": 28, "secur": 28, "see": [0, 1, 14, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 50], "seed": [24, 27, 28, 29, 32, 38], "seek": [28, 34], "seem": [24, 25, 26, 27, 28, 29, 32, 33, 37], "seemingli": 41, "seen": [0, 28], "seismic": 24, "select": [17, 20, 25, 32, 33], "selectbackward0": 18, "self": [18, 19, 21, 22, 24, 25, 28, 37, 40], "self__upcast_and_reordered_attn_0": 21, "self_attention_cach": 21, "self_attn": [24, 25, 27, 30, 31, 33, 36, 40], "self_attn_output": 24, "self_c_attn_0": 21, "self_c_attn_1": 21, "self_c_proj_0": 21, "self_q_attn_0": 21, "self_resid_dropout_0": 21, "sell": 28, "semant": 25, "send": [8, 18, 19, 22, 37, 38], "senior": 28, "sens": [25, 26, 27, 28, 32, 33], "sensit": [24, 25, 26], "sent": [0, 22, 37, 40], "sentenc": [26, 27, 28, 30, 31, 33, 40], "sentiment": [28, 53], "seoul": 28, "separ": [7, 10, 24, 25, 26, 27, 28, 29, 31, 34, 37, 41, 48], "seq": [28, 30, 35], "seq_len": [25, 28], "seqpo": 28, "sequenc": [23, 24, 25, 28, 33, 35, 37], "sequenti": [9, 17, 37, 40], "seri": 28, "serial": [19, 22, 37], "seriou": 35, "serv": [20, 26, 28, 31, 35, 37, 40, 41], "server": [0, 8, 17, 18, 22, 26, 28, 31, 37, 40], "servic": [0, 17, 36, 37], "session": [24, 25, 26, 27, 38, 40], "session_id": [22, 37], "set": [0, 8, 10, 12, 13, 14, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 35, 36, 38, 50], "set_color": 25, "set_default_api_kei": [17, 22, 24, 28, 30, 31, 35, 36, 37, 40], "set_grad_en": 28, "set_linewidth": 25, "set_postfix": 29, "set_titl": 38, "set_valu": 37, "set_vis": 25, "set_xtick": 25, "set_xticklabel": 25, "set_ytick": 25, "set_yticklabel": 25, "set_zord": 24, "setitem": [18, 37], "setitem_0": 37, "setup": 53, "setup_input_hook": 37, "seuss": 26, "sever": [28, 35], "sfeucht": 25, "sgd": 28, "sh": 41, "shabbi": 33, "shape": [8, 16, 18, 21, 24, 25, 26, 27, 28, 29, 37, 40], "shape_env": [18, 37], "shape_kv": 21, "shape_q": 21, "shapeenv": [18, 37], "share": [1, 25, 36, 37, 52], "sharp": [28, 30], "she": [25, 33], "shift": [25, 27], "shop": 31, "shore": 41, "short": [27, 28], "shorter": [26, 28], "shot": [27, 28], "should": [7, 16, 18, 24, 25, 26, 27, 28, 30, 32, 33, 35, 37, 48], "shouldn": [28, 30, 32, 35], "show": [24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40], "show_lin": 28, "showarrow": 27, "showlegend": 27, "shown": [0, 25], "shuffl": [24, 28], "sid": [22, 31, 37], "side": [10, 28, 34], "sign": [17, 25, 50, 53], "signal": [26, 28], "signific": [24, 26, 28, 33], "significantli": [24, 31], "silent": [7, 28, 48], "silu": [24, 27, 30, 31, 36, 40], "similar": [0, 15, 28, 29, 30, 31, 32, 33, 35, 37, 38], "similarli": 37, "simon": 28, "simpl": [0, 14, 17, 26, 27, 28, 30, 34, 36, 37, 40], "simple_whit": [27, 32, 33], "simpler": [28, 37], "simplest": 28, "simpli": [16, 17, 26, 29, 31, 32, 35, 37, 40], "simplifi": [26, 37, 39], "simul": [25, 34], "simultan": [24, 28, 31], "sin": 25, "sinc": [0, 7, 10, 17, 25, 28, 29, 32, 33, 34, 37, 48], "singl": [17, 24, 26, 27, 28, 29, 33, 34, 36, 37, 41], "singular": 33, "sio": [22, 37], "sit": 35, "site": [14, 18, 22, 28, 30, 31, 37], "situat": 18, "size": [16, 18, 24, 26, 27, 28, 29, 30, 32, 33, 36, 37, 40, 50], "skill": 32, "skip": [1, 8, 22, 24, 28, 37, 38], "skip_lay": 38, "skip_special_token": 35, "skipped_output": 20, "sklearn": 27, "slack": [28, 33], "slap": 28, "slice": 28, "slight": [26, 29], "slightli": [26, 27, 28, 32], "slowli": 28, "small": [0, 17, 26, 27, 28, 30, 31, 32, 33, 40, 53], "smaller": [0, 28, 29, 40], "smallest": 28, "sn": 25, "snippet": [25, 28, 31, 37], "snowi": 38, "so": [11, 12, 13, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40], "social": [32, 37], "socket": [22, 37], "socketio": [24, 35, 38], "socketio_path": [22, 37], "soft": [25, 28], "softmax": [15, 22, 24, 25, 26, 27, 28, 29, 33, 37, 39], "sole": 33, "solid": 28, "solut": 28, "solv": [28, 33, 34, 37], "solvabl": 28, "some": [7, 13, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 40, 41, 48], "somehow": [32, 33], "someon": [28, 37], "someth": [27, 28, 32, 36, 37], "sometim": [14, 22, 28, 30, 32, 37], "somewhat": [26, 28], "somewher": [32, 33], "song": 28, "soon": [32, 33, 34, 41], "sophist": 20, "sort": [24, 25, 27, 29, 41, 51], "sort_zord": 24, "soul": 41, "soulmat": 28, "sourc": [2, 7, 8, 25, 26, 27, 28, 29, 32, 33, 34, 48, 50, 52], "source_activ": [27, 29], "source_causal_input": 32, "source_countri": [29, 33], "source_h12_valu": 32, "source_head_activ": 25, "source_hidden_st": [29, 33], "source_input": 32, "source_logit": 27, "source_output": 32, "source_prompt": [25, 27, 29, 33], "source_prompt_id": 27, "source_prompt_token_id": 27, "source_run_dict": 25, "source_sequ": 25, "source_stat": 27, "source_token": 25, "south": [27, 28, 29], "space": [15, 22, 25, 27, 28, 29, 30, 32, 33, 34, 37, 41], "spanish": [25, 29], "spars": 53, "speak": 28, "speaker": 35, "special": [17, 24, 28, 29, 35, 36, 37], "specif": [23, 25, 26, 27, 28, 29, 30, 31, 35, 36, 37, 40], "specifi": [17, 20, 21, 29, 31, 34, 35, 36, 37, 38], "speed": [10, 23, 26, 28, 30], "spend": 28, "spine": 25, "splash": 38, "spleen": 41, "splice": 20, "split": [21, 24, 25, 27, 28, 33], "split_0": 21, "split_1": 21, "split_siz": 21, "spoiler": 28, "spuriou": 27, "sqrt": [25, 26, 38], "squar": [10, 23, 25, 27], "squeez": [24, 25, 28], "src": [25, 37], "sst2": 40, "stabilityai": 38, "stabl": [14, 18, 28, 30, 31, 37], "stack": [18, 22, 24, 25, 26, 27, 28, 37, 41], "stage": 18, "stai": [28, 29], "stand": 32, "standard": [19, 28, 40], "stanford": 40, "star": [0, 50], "start": [0, 9, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 40], "start_header_id": 35, "start_it": 16, "start_of_respons": 28, "start_of_respos": 28, "start_remote_access": [24, 50, 53], "start_tim": 11, "state": [0, 1, 9, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 25, 26, 29, 30, 32, 33, 36, 37, 38, 40], "statement": [21, 22, 27, 28, 37, 40], "staticmethod": [22, 24, 37], "statu": [17, 22, 24, 28, 36, 37, 50], "steer": [1, 53], "steer_factor": 27, "steered_complet": 28, "steered_out": 28, "steered_prompt": 28, "step": [24, 25, 27, 28, 29, 31, 33, 35, 38, 39, 40, 41, 52, 53], "step_block": 24, "step_siz": 38, "stereotyp": 33, "stereotypical_complet": 33, "stereotypical_prob": 33, "stereotypical_token": 33, "still": [13, 25, 26, 28, 30, 32, 33, 34, 37], "stochast": 28, "stop": [8, 17, 20, 25, 28], "stop_exc_tim": 11, "store": [0, 16, 17, 26, 27, 28, 29, 30, 32, 33, 37], "stori": 27, "str": [7, 22, 24, 25, 28, 37, 48], "str_token": [28, 41], "straightforward": 37, "strang": 37, "strategi": 41, "stream": [8, 24, 25, 28, 30, 31, 32, 33, 40], "streamer": [24, 27, 30, 31, 36, 37, 39, 40], "streamlin": 37, "streamlit": 28, "street": [26, 41], "strengthen": 24, "strictli": [17, 37], "string": [7, 24, 25, 27, 28, 36, 37, 38, 39, 48], "strip": [24, 25, 26, 28], "strong": [25, 26, 28, 41], "stronger": 28, "strongli": [26, 27, 28, 33], "structur": [16, 27, 28, 31, 32, 37], "stuck": 28, "student": [27, 35], "studi": [0, 25, 28, 33], "stumbl": 32, "style": 27, "sub": 37, "subbed_gener": 25, "subclass": [7, 36, 37, 48], "subdirectori": 28, "subgraph": 30, "subject": [30, 33], "sublay": 24, "submit": [22, 37], "submodul": 37, "subplot": [24, 25, 38], "subplots_adjust": 38, "subresult": 24, "subsect": 28, "subsequ": [11, 16, 21, 28, 37], "subset": [28, 29, 32, 40], "substep": 32, "substitut": [25, 28], "success": [28, 37], "successfulli": [16, 23, 28, 29, 31, 32], "sudo": 28, "suffici": 28, "suggest": [1, 8, 18, 25, 26, 27, 32, 33], "suit": 32, "sum": [13, 24, 25, 28, 31, 32, 34, 37, 40, 41], "summari": 28, "summary_activ": 28, "summary_first_dropout": 28, "summary_proj_to_label": 28, "summary_typ": 28, "summary_use_proj": 28, "summed_activ": 41, "summed_activations_or": 41, "super": [18, 22, 37, 40], "superposit": 24, "suppli": 28, "support": [0, 8, 16, 21, 24, 28, 36, 37, 38, 50], "supported_model": 23, "suptitl": 38, "sure": [21, 24, 25, 28, 29, 30, 32, 33, 35, 37, 40], "surpris": [26, 32], "surprisingli": 26, "suspect": 29, "swap": [13, 17, 30, 31, 32, 36, 37], "switch": [26, 30, 32], "sy": [28, 32, 34], "sycoph": 28, "symbol": [27, 28], "symbool": 21, "symmetr": [24, 28], "syntax": [10, 13, 19, 37], "system": [28, 32, 34, 35], "systemat": [26, 30], "t": [1, 7, 10, 11, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 48], "t0": 28, "t1": [17, 37], "t1_tokens_out": [17, 37], "t2": [17, 37], "t2_tokens_out": [17, 37], "t3": [17, 37], "t4": 38, "ta": 28, "tab": 25, "tabl": [28, 38], "tail": 27, "take": [0, 7, 14, 17, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 41, 48], "takeawai": [26, 27, 29], "taken": [24, 28], "talk": [26, 28, 29, 37], "tangent": 27, "tap": 24, "target": [7, 11, 18, 19, 22, 24, 30, 37, 48], "task": [1, 25, 32, 33, 37, 40], "task_specific_param": 28, "taught": 28, "teach": [28, 33], "teacher": 35, "teacherus": 35, "teal": 34, "team": [0, 2, 8, 17, 33, 35, 37, 50, 52], "techinc": 32, "technic": 28, "techniqu": [17, 28, 30, 31, 33, 36, 37, 38, 40, 50], "tegmark": 27, "tell": [10, 27, 28, 29, 32, 33, 36], "temp": 25, "temperatur": [23, 28], "templ": 28, "templat": [27, 28, 32, 33, 36, 53], "temporari": [14, 37], "tend": [26, 28, 29, 38], "tenedor": 25, "tensor": [8, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 36, 37, 40], "tensor_sum": 37, "term": 28, "termin": [11, 17, 28, 36, 37], "terrif": 0, "test": [20, 24, 25, 27, 28, 30, 32, 37, 38, 40], "test_all_max_effect": 24, "test_calculate_fn_vector": 28, "test_calculate_h": 28, "test_effect": 24, "test_fn": 24, "test_future_max_effect": 24, "test_intervene_with_h": 28, "text": [0, 1, 16, 24, 25, 26, 28, 35, 37, 38, 39, 40, 53], "text_auto": 39, "text_encod": 38, "text_encoder_2": 38, "text_model": 38, "texttempl": 39, "th": 28, "than": [16, 19, 23, 24, 26, 28, 29, 31, 32, 33, 35, 37, 38, 40, 41], "thank": [26, 28, 30], "thankfulli": 33, "the_mean": 25, "thei": [0, 18, 20, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 40, 41], "them": [7, 10, 12, 13, 17, 18, 24, 25, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 48], "theme": 35, "themselv": [32, 37], "theoret": 29, "theori": [29, 34], "therefor": [19, 37], "theta": 27, "theta_orthogon": 27, "thi": [0, 7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 48, 50], "thing": [25, 28, 29, 32, 33, 37, 38], "think": [1, 25, 28, 29, 32, 33, 34, 35], "third": 32, "this_attn": 25, "this_sequ": 25, "thorough": 35, "those": [19, 21, 27, 28, 31, 33, 34, 37], "though": [18, 32, 37], "thought": [28, 34, 41, 53], "thread": 28, "three": [16, 28, 30, 32, 34], "through": [0, 11, 18, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 36, 37, 38, 39, 50, 52], "throughout": [7, 18, 19, 22, 36, 37, 38, 39, 48], "throught": [18, 37], "throw": [22, 23, 26, 37], "thrown": 32, "thu": [30, 31, 37], "thursdai": 28, "ti": 37, "tick": 25, "ticket": 30, "ticktext": 27, "tickval": 27, "tid": 24, "tie_word_embed": 28, "tight": 28, "tight_layout": [25, 38], "tile": 24, "time": [0, 8, 13, 17, 18, 22, 25, 26, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41], "timeout": 17, "timestamp": [22, 37], "tini": [19, 37], "tiny_model": [19, 37], "tire": 41, "titl": [25, 28, 30, 31, 38, 39], "tl": [16, 31, 37], "tldr": 28, "tmp": [11, 19], "to_model": [22, 37], "to_print": 25, "to_str_token": 28, "to_sum": 25, "todai": [28, 29, 35], "todd": 28, "todd_function_vector": 1, "todo": 37, "togeth": [0, 17, 25, 26, 27, 28, 29, 32, 34, 35, 36, 37, 50], "toggl": [25, 32, 37], "toi": 33, "tok": [23, 28], "token": [1, 8, 10, 11, 14, 15, 17, 18, 22, 24, 26, 27, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41], "token_cmap": 25, "token_completions_intervent": 28, "token_completions_zero_shot": 28, "token_copying_len30_n1024": 25, "token_head_ord": 25, "token_id": [37, 40], "token_ids_intervent": 37, "token_ids_origin": 37, "token_idx": [26, 30, 33], "token_index": [27, 29], "token_indic": 26, "token_label": [26, 30], "token_plt": 25, "token_scor": 25, "token_str": [24, 27], "tokenize_funct": 40, "tokenized_label": 25, "tokenized_train_dataset": 40, "tokenizer_class": 28, "tokenizers_parallel": [17, 22, 37], "tokens_intervent": 28, "toker": 38, "tokyo": 27, "told": [26, 33], "tolist": [22, 28, 32, 37], "tom": 31, "tone": 28, "too": [0, 1, 28, 33, 38], "took": 25, "tool": [17, 18, 28, 31, 37, 39], "toolbox": 28, "top": [24, 25, 28, 38, 39, 41], "top_activations_indic": 41, "top_activations_indices_or": 41, "top_complet": 29, "top_k": 28, "top_p": [23, 28], "topic": 28, "topk": [24, 25, 28, 29, 41], "torch": [9, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "torch_dtyp": [24, 25, 28, 38], "torch_jit_is_tracing_0": 21, "torch_nn_functional_scaled_dot_product_attention_0": 21, "torchrec": 37, "toronto": 27, "tortur": 28, "total": [24, 25, 28, 33, 37], "touch": 28, "toward": [27, 33, 41], "tower": [0, 9, 12, 14, 15, 16, 17, 18, 21, 22, 23, 28, 36, 37, 39], "toy_model": 32, "toy_model_compon": 32, "toy_model_graph": 32, "toymodel": 32, "tp_size": 23, "tqdm": [14, 18, 26, 27, 29, 30, 31, 37], "tqdmwarn": [14, 18, 30, 31, 37], "trace": [0, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 39, 40, 41, 49], "traceabl": 37, "traceback": [11, 18, 19, 22, 37], "tracer": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 30, 31, 33, 36, 37, 39, 40, 41], "track": [27, 30, 32, 33], "tradit": 39, "train": [11, 21, 22, 26, 29, 34, 38, 40, 41, 53], "train_data": 40, "trainer": 40, "trainingargu": 40, "trait": 28, "trang": [26, 27, 29], "transfer": 37, "transform": [0, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 23, 24, 25, 28, 29, 30, 31, 33, 35, 37, 39, 40, 48], "transformer_len": 28, "transformerlen": 28, "transformers_vers": 28, "transit": 30, "translat": [25, 28], "transmit": [37, 40], "transpar": 36, "transport": [22, 35, 37], "transpos": [21, 25], "transpose_0": 21, "transpose_1": 21, "transpose_2": 21, "transpose_3": 21, "transpose_4": 21, "treat": 0, "treebank": 40, "trendlin": 27, "tri": [18, 28, 33, 37], "trick": [0, 28, 37], "tricki": 28, "trigger": 28, "triton": 23, "troubleshoot": [18, 36, 37], "true": [0, 1, 13, 14, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 41], "true_activ": 27, "true_activations_mean": 27, "true_token_id": 27, "truncat": [37, 38, 40], "truth": [1, 24, 33], "try": [10, 11, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 53], "try_deregist": [18, 22, 37], "tun": 11, "tune": [37, 53], "tup": 25, "tupl": [12, 19, 21, 22, 24, 25, 27, 28, 29, 30, 33, 37], "tuple_of_arg": 28, "turbo": 28, "turn": [18, 27, 28, 29, 32, 34, 36, 37], "turner": 28, "tutori": [9, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 50], "twice": [25, 28, 33], "twist": 29, "two": [10, 19, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 40], "txt": [28, 37, 41], "type": [7, 18, 22, 24, 25, 26, 28, 33, 37, 38, 39, 48], "typic": [30, 37], "u": [0, 1, 2, 8, 10, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 50, 52], "umbrella": 28, "unchang": [28, 40], "uncom": 25, "uncommon": 38, "uncorrupt": 28, "uncov": [32, 33], "under": [18, 27, 28, 37], "underli": [19, 27, 28, 37], "underlin": 28, "understand": [0, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41], "understood": 28, "undesir": 23, "undo": 29, "unembed": 28, "unfamiliar": 26, "unfortun": 32, "unicode_escap": [22, 37, 39], "unifi": 25, "uniform": 28, "unimport": 28, "uninform": [24, 28], "uninterpret": 28, "union": [18, 21, 37], "unit": [25, 32, 41], "unknown": 26, "unless": 32, "unlik": [0, 14, 26, 27, 28, 37, 39], "unmodifi": [14, 37], "unnam": 28, "unplan": 17, "unrel": [28, 41], "unreli": [25, 26], "unrot": 29, "unsafeviewbackward0": 15, "unsqueez": [24, 25, 28, 31], "unsqueeze_dim": 25, "unsteer": 28, "unsteered_complet": 28, "unsteered_out": 28, "unsteered_prompt": 28, "unsuccess": 28, "unsur": [18, 37], "until": [22, 24, 33, 37], "unus": 38, "unusu": 35, "unwant": 28, "unzip": 28, "up": [0, 10, 11, 16, 17, 20, 23, 24, 25, 28, 29, 30, 32, 33, 37, 38, 41, 50, 53], "up_proj": [24, 27, 30, 31, 36, 40], "updat": [0, 14, 17, 18, 21, 28, 30, 31, 37, 39], "update_layout": [26, 27, 32, 33, 39], "update_trac": 39, "upgrad": 28, "upload": [22, 37], "upon": [0, 12, 32, 37], "upper": 41, "upset": 40, "us": [1, 7, 8, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 48, 50, 53], "usag": [17, 35], "usc": 28, "use_bo": 28, "use_cach": 28, "use_gqa_in_sdpa": 21, "use_gqa_in_sdpa_0": 21, "use_safetensor": 38, "user": [14, 17, 20, 22, 26, 28, 35, 36, 37, 40], "user_instal": [14, 18, 30, 31, 37], "userdata": [17, 22, 24, 28, 30, 31, 36, 40], "userwarn": 25, "using_eag": 21, "usr": [19, 25, 37], "usual": [12, 26, 28, 32], "utf": 28, "util": [2, 25, 27, 28, 29, 30, 32, 35, 37, 40, 49], "v": [12, 17, 24, 25, 29, 30, 31, 33, 37, 38], "v0": [10, 13, 23, 26], "v1": 38, "v_proj": [24, 25, 27, 30, 31, 36, 40], "vale": 21, "valid": [8, 17, 36, 40], "validatinginterventionnod": [18, 37], "validation_data": 40, "valu": [8, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], "value_contiguous_0": 21, "value_lay": 21, "value_norm": 25, "value_st": [21, 25], "value_states_view_0": 21, "value_states_view_1": 21, "value_weight": 25, "valueerror": [21, 37], "valueerror_0": 21, "vanilla": 17, "var": [34, 37], "vari": [27, 32, 38], "variabl": [10, 12, 13, 16, 17, 21, 22, 28, 32, 34, 37, 53], "varianc": 27, "variant": [14, 37, 38], "variat": 31, "varieti": 28, "variou": [36, 37, 40, 50], "vatican": [14, 37], "ve": [14, 16, 17, 23, 24, 25, 26, 27, 28, 31, 32, 34, 36, 37, 50], "vector": [1, 25, 27, 29], "vector_norm": 25, "venezuela": 27, "verbatim": [1, 25], "veri": [0, 18, 22, 24, 26, 28, 32, 33, 34, 37, 40], "verifi": [11, 28], "version": [10, 13, 14, 17, 21, 23, 28, 30, 31, 35, 36, 37, 39, 40, 41], "vertic": [25, 39], "via": [17, 21, 22, 36, 37, 41], "victori": 28, "video": 28, "view": [17, 18, 21, 25, 28, 29, 36, 37, 50], "vig": 33, "vigil": 28, "violat": 17, "violet": 34, "visibl": 28, "visit": [17, 28], "visual": [26, 32, 33, 34], "visualis": 28, "viusal": 25, "vllm": 8, "vllm_gpt2": 23, "vllm_support": 8, "vmax": [24, 25], "vmin": [24, 25], "vocab_s": [23, 26, 28], "vocabparallelembed": 23, "vocabulari": [15, 25], "voluntari": 28, "vram": 36, "w": [11, 22, 25, 28, 37], "wa": [0, 11, 16, 17, 18, 19, 22, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40], "wai": [18, 19, 22, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 40, 41], "wait": [10, 17, 22, 24, 25, 26, 27, 30, 31, 36, 37, 40], "wait_timeout": [22, 37], "walk": [33, 34, 50], "walkthrough": [9, 31, 36, 50, 52, 53], "want": [0, 10, 11, 12, 14, 16, 18, 19, 20, 21, 22, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38], "warehous": 41, "wari": 28, "warn": [17, 22, 25, 28, 37], "warning_onc": 21, "watch": 28, "water": 38, "wateri": 41, "wb": [37, 40], "we": [0, 1, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 50], "weakli": 28, "websit": [25, 33, 36, 38], "websocket": [22, 37], "wed": 28, "week": 28, "weight": [21, 24, 25, 28, 29, 32, 36, 37, 40], "weights_onli": 41, "weights_path": 41, "weird": 38, "welcom": [0, 1, 28, 53], "well": [0, 18, 25, 27, 28, 29, 32, 33, 34, 35, 37], "went": [28, 30, 31, 37], "were": [26, 27, 28, 29, 33, 36, 37], "weren": [28, 38], "wet": 28, "wget": 28, "what": [1, 18, 19, 27, 28, 29, 30, 33, 35, 36, 37, 39, 41], "whatev": [26, 28, 29, 32], "when": [0, 1, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40], "whenev": [12, 16, 28, 41], "where": [16, 18, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37], "wherea": [25, 28], "whether": [25, 26, 27, 28, 29, 30, 32, 35, 40], "which": [0, 10, 11, 12, 14, 16, 19, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41], "whichev": 35, "whie": 31, "while": [0, 7, 14, 16, 24, 25, 28, 31, 35, 37, 38, 39, 48], "white": 25, "whitelist": [22, 37], "who": [9, 25, 27, 28, 35], "whole": [27, 29, 30, 32, 37], "whose": [28, 29], "why": [24, 25, 27, 28, 30, 37], "wide": 37, "width": [24, 27, 28, 38], "wife": 28, "wil": 26, "window": 25, "windowpan": 25, "winogend": 33, "winogender_sent": 33, "winograd": 33, "wish": [14, 28, 35, 37], "wit": 28, "with_grad": 29, "within": [0, 7, 10, 12, 13, 14, 16, 17, 18, 21, 22, 28, 29, 30, 31, 32, 33, 36, 37, 39, 48], "without": [11, 13, 14, 17, 18, 22, 24, 25, 26, 28, 29, 32, 36, 37, 40], "won": [27, 28, 32, 33, 34, 36, 37], "wonder": 28, "wooden": 38, "word": [18, 22, 25, 26, 28, 30, 36, 37, 39], "word_list": 28, "word_pair": 28, "work": [0, 10, 16, 17, 18, 21, 22, 25, 28, 29, 30, 32, 33, 36, 37, 38, 39, 41], "workaround": 25, "workshop": 28, "workspac": [17, 30, 40], "workstat": 0, "world": [13, 23, 28, 41], "worri": [17, 27, 28, 36, 37], "worth": 19, "would": [0, 1, 10, 12, 13, 14, 17, 19, 20, 21, 22, 25, 28, 29, 35, 36, 37, 40, 41, 50], "wow": 32, "wpe": [23, 30, 31, 37, 39], "wrap": [9, 24, 28, 37], "wrap_except": 19, "wrapper": [23, 31, 36, 37, 38, 40], "wrappermodul": [7, 23, 48], "wrestl": 28, "write": [0, 1, 24, 25, 28, 32, 35], "written": [28, 37], "wrong": 28, "wrote": [28, 33], "ws_address": [22, 37], "wte": [10, 23, 30, 31, 37, 39], "x": [7, 10, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 39, 40, 48], "x1": 25, "x2": 25, "x_label": [25, 26, 30], "x_posit": 25, "xaxi": 27, "xaxis_tickangl": 39, "xaxis_titl": [27, 32, 33], "xformersimpl": 23, "xl": 1, "xlabel": [24, 25], "xlim": 24, "xref": 27, "xtick": [24, 25], "y": [10, 25, 26, 27, 28, 30, 31, 32, 33, 34, 39], "y_label": 25, "y_posit": 25, "yaxi": [26, 27, 32, 33], "yaxis_titl": [27, 32, 33], "ye": 28, "yeah": 28, "year": [27, 28, 41], "yet": [25, 27, 28, 29, 31, 33, 34, 37, 39], "yield": [13, 24, 28], "ylabel": [24, 25], "ylim": 24, "yoda": 26, "york": 10, "you": [0, 1, 2, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 50, 52, 53], "young": 28, "your": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 35, 37, 38, 40, 50, 52, 53], "your_api_kei": [17, 37], "your_hf_token": 36, "your_hugging_face_token": [17, 37], "your_huggingface_token": 35, "your_ndif_api_kei": 35, "yourself": [17, 20, 25, 28, 37], "yref": 27, "ytick": 25, "z": [24, 28, 30], "z_ablat": 28, "z_corrupt": 30, "z_dict": 28, "z_h": 30, "z_reshap": [28, 30], "zero": [13, 16, 24, 25, 28, 30, 35, 37, 39, 40], "zero_grad": [29, 37, 40], "zero_shot_dataset": 28, "zero_shot_prompt": 28, "zeroth": 28, "zip": [24, 28, 29, 31, 38], "zlib": [22, 37], "\u0121": [24, 28], "\u0121be": 28, "\u0121i": 28, "\u0121jame": 28, "\u0121name": 28, "\u0121sentenc": 28, "\u0121token": 28, "\u0121will": 28, "\u025bn": [9, 50], "\u30dc\u30fc\u30eb\u30da\u30f3": 25, "\u4e2d\u6587": 25, "\u54bd\u5934": 25, "\u5589": 25, "\u5706\u73e0\u7b14": 25, "\u6307\u74b0": 25, "\u6307\u8f2a": 25, "\u65e5\u672c\u8a9e": 25, "\u76d1\u72f1": 25, "\u76e3\u7344": 25, "\u821f": 25, "\u984e": 25, "\u9894": 25}, "titles": ["About NNsight", "Mini Paper Tutorials", "Documentation", "nnsight.intervention", "nnsight.modeling", "nnsight.schema", "nnsight.tracing", "nnsight.util", "Features", "nnsight", "Cross-Prompt Intervention and Batching", "Early Stopping", "Getting", "Gradients", "Model Editing", "Modules", "Multiple Token Generation", "Remote Execution", "Scan and Validate", "Setting", "Skipping Modules", "Source Code Interventions", "Streaming", "vLLM Support", "Do Language Models Use Their Depth Efficiently?", "The Dual-Route Model of Induction", "Demystifying Verbatim Memorization in Large Language Models", "The Geometry of Truth", "Function Vectors", "Distributed Alignment Search (DAS): Searching for Linearly Encoded Concepts in Model Representations", "Activation Patching", "Attribution Patching", "Causal Mediation Analysis I: Introduction", "Causal Mediation Analysis II: Explaining LLMs", "What\u2019s a causal model?", "Chat Templates", "Access LLMs with NDIF and NNsight", "Walkthrough", "Diffusion Lens", "Logit Lens", "LoRA for Sentiment Analysis", "Dictionary Learning", "nnsight.contexts", "nnsight.intervention", "nnsight.models", "nnsight.module", "nnsight.patching", "nnsight.tracing", "nnsight.util", "Documentation", "Getting Started", "Status", "Tutorials", "Main Tutorials"], "titleterms": {"": [26, 27, 34, 37], "0": [25, 26, 27, 32, 33], "1": [17, 25, 26, 27, 28, 30, 31, 32, 33, 37, 38], "2": [17, 25, 26, 27, 28, 30, 31, 32, 33, 37, 39], "3": [17, 25, 27, 28, 30, 31, 32, 37], "4": [17, 25, 27, 28], "5": [25, 38], "70b": 27, "A": 28, "At": 32, "In": 19, "Not": 19, "The": [25, 27, 28, 37], "Their": 24, "With": 41, "ablat": 25, "about": 0, "access": [13, 17, 36, 50], "accuraci": 28, "across": 37, "activ": [27, 28, 30], "actual": 25, "addit": 28, "ai": [0, 37], "aka": 27, "algebra": 28, "align": 29, "all": [16, 37], "alter": 36, "an": 0, "analysi": [26, 32, 33, 40], "anoth": 28, "answer": 28, "antonym": 28, "api": [0, 17, 36, 37], "appli": [35, 39, 41], "ar": [25, 32], "architectur": 39, "attend": 25, "attent": [25, 28], "attribut": 31, "autoencod": 41, "automat": 29, "batch": [10, 30, 37], "behavior": 26, "behaviour": 28, "behind": 0, "bia": 33, "bigger": [30, 37], "black": [0, 37], "bonu": [28, 38], "box": [0, 37], "cach": 28, "calcul": 28, "calculate_fn_vectors_and_interven": 28, "captur": 29, "causal": [26, 32, 33, 34], "chang": 28, "chat": [22, 35, 37], "choos": [27, 29, 36], "classifi": 27, "clean": 30, "clip": 38, "code": [21, 25, 28], "combin": 28, "comparison": 41, "compon": [31, 33], "comput": [24, 28, 29], "concept": [25, 29], "conceptu": 25, "condit": 37, "config": 28, "configur": 17, "consider": 17, "content": 28, "context": [37, 42], "continu": 35, "contrast": 28, "contribut": 24, "control": 53, "corrupt": 30, "cosin": 24, "cross": 10, "custom": 37, "da": 29, "data": 40, "dataset": 28, "decod": 28, "decor": [22, 37], "deep": 38, "deeper": 32, "delv": 32, "demystifi": 26, "depend": 32, "depth": 24, "dictionari": 41, "differ": 27, "diffus": 38, "direct": 32, "distribut": 29, "do": [0, 24, 25, 29], "document": [2, 49], "doe": 26, "dual": 25, "earli": [11, 37], "edit": [14, 29, 37], "effect": [24, 32], "effici": 24, "elicit": 28, "encod": [28, 29, 38], "engin": 28, "enter": 29, "erasur": 24, "exampl": [22, 26, 37], "execut": [17, 28, 37], "exercis": [28, 32], "experi": [17, 24, 30, 36], "explain": 33, "expos": 26, "extens": [28, 33], "extract": 28, "featur": 8, "final": 35, "find": [25, 29], "fine": 40, "first": 37, "flow": [27, 33], "floyd": 38, "flux": 38, "forward": 28, "free": 36, "from": 28, "function": [22, 28, 37], "futur": 24, "fv": 28, "gender": 33, "gener": [16, 28, 37], "geometri": 27, "get": [12, 37, 50, 53], "gpt": [33, 39], "gpt2": 28, "gradient": [13, 24, 37], "graph": 34, "h": 28, "happen": [0, 25], "head": [25, 28], "here": 36, "hidden": 28, "host": 17, "how": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 29], "huge": 37, "i": [0, 32, 37], "icl": 28, "idea": 1, "identif": 31, "ii": 33, "implement": [25, 28], "import": 28, "indic": 35, "indirect": [31, 32], "induct": 25, "infer": 28, "inform": [25, 26, 27, 29, 33], "input": 28, "instal": [36, 50], "integr": 24, "interact": 25, "interchang": 34, "intern": [36, 50], "interpret": [26, 32, 39], "interven": [13, 28, 33, 34], "intervent": [3, 10, 16, 21, 23, 28, 30, 34, 37, 43], "introduct": [28, 32, 38, 39], "invari": 25, "invok": 28, "involv": 37, "ioi": [30, 31], "issu": [2, 8, 23, 52], "iter": [16, 37], "kei": [17, 28, 36], "known": 23, "languag": [24, 25, 26, 28], "languagemodel": 37, "larg": 26, "last": [28, 32], "layer": [24, 39], "learn": [28, 41], "len": [24, 25, 38, 39], "let": [26, 27, 34, 37], "limit": [17, 30], "linear": [27, 29], "linearli": 29, "littl": 32, "live": [22, 37], "llama": [27, 28], "llm": [33, 36, 40, 50], "load": 38, "local": [22, 37], "logist": 27, "logit": [24, 39], "loop": 37, "lora": [37, 40], "lr": 27, "main": 53, "make": 29, "mani": 16, "mass": 27, "matter": 19, "mean": 27, "measur": 24, "mediat": [26, 32, 33], "memor": 26, "messag": 35, "method": 37, "mini": 1, "mm": 27, "mmlu": 26, "model": [4, 14, 17, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 44, 50], "modul": [15, 20, 45], "much": 29, "multi": [28, 29], "multipl": [16, 28, 35, 37], "ndif": [17, 27, 36], "network": 32, "neural": 32, "next": [0, 16, 36, 37, 50], "nnsight": [0, 3, 4, 5, 6, 7, 9, 22, 28, 30, 36, 37, 42, 43, 44, 45, 46, 47, 48], "note": [13, 28, 30], "object": [28, 31], "onli": 16, "oper": [34, 37], "optim": 30, "option": [28, 41], "order": 19, "other": 28, "our": [26, 32, 40], "out_proj": 28, "output": 28, "over": 31, "own": [1, 28, 36], "pad": 28, "pair": 28, "paper": [1, 28], "paramet": 35, "paraphras": 25, "pass": 28, "patch": [25, 26, 27, 30, 31, 46], "piec": 25, "place": 19, "polysemant": 41, "posit": 31, "post": 28, "practic": 28, "predict": 53, "prepar": 40, "probe": 27, "prompt": 10, "put": 28, "re": 32, "red": 28, "regist": 36, "regress": 27, "rel": 24, "relat": [10, 12, 13, 14, 18, 19, 20, 21], "relev": 29, "remot": [17, 22, 28, 31, 36, 37, 50], "replic": 28, "report": [2, 8, 52], "repres": 29, "represent": [25, 29], "residu": [24, 29], "respons": 35, "result": [25, 26, 28, 30, 38], "right": [27, 29], "rout": 25, "run": [30, 36, 38], "sae": 41, "said": 37, "sampl": [23, 28], "save": [11, 28], "scale": [26, 27], "scan": [18, 28, 37], "scene": 0, "schema": 5, "schnell": 38, "scienc": [0, 37], "score": 25, "search": 29, "sentenc": 25, "sentiment": 40, "session": [17, 37], "set": [19, 34, 37], "setup": [22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41], "sign": 36, "similar": 24, "skip": 20, "small": 37, "sourc": 21, "spars": 41, "specif": [16, 33], "stabl": 38, "start": [35, 37, 50, 53], "state": 28, "statu": 51, "steer": [27, 28], "step": [0, 30, 36, 37, 50], "stop": [11, 37], "stream": [22, 29, 37], "streamlin": [16, 17], "submit": 1, "subspac": 29, "suggest": 28, "summari": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "support": 23, "surgic": 29, "syntax": 28, "system": 17, "t5": 38, "task": [28, 29, 30, 31], "team": 28, "templat": 35, "test": 26, "thi": 28, "thing": [26, 27], "thought": 37, "time": [11, 28], "tip": 28, "toi": 32, "token": [16, 23, 25, 28, 37], "too": [29, 32], "total": 32, "trace": [6, 22, 37, 47], "traceabl": 23, "train": [35, 37], "transfer": 25, "transpar": [0, 37], "trigger": 26, "truth": [27, 28], "try": [30, 32], "tune": 40, "tutori": [1, 52, 53], "two": [28, 38], "understand": 53, "unit": 29, "up": [26, 27, 34, 36], "us": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 28, 37], "util": [7, 48], "v": [27, 28], "valid": [18, 28, 37], "valu": 28, "vector": 28, "verbatim": 26, "via": 28, "visual": [25, 27, 28, 30, 38, 39, 41], "vllm": 23, "vocabulari": 28, "walkthrough": 37, "we": [25, 32], "what": [0, 25, 26, 32, 34], "when": [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25], "where": [10, 25], "which": 28, "without": 41, "workflow": 30, "xl": [28, 38], "xxl": 38, "you": [25, 37], "your": [1, 28, 36]}})