{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa120177",
   "metadata": {},
   "source": [
    "# DAS Puzzle! Mystery toy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efeefe3",
   "metadata": {},
   "source": [
    "In the last tutorial, we went over <a href=\"https://arxiv.org/abs/2303.02536\">DAS</a> and used it to identify a linear subspace in an LLM that stored information about the country of Paris.\n",
    "\n",
    "Now it's time to put your learning to the test, and investigate a mystery neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    is_colab = True\n",
    "except ImportError:\n",
    "    is_colab = False\n",
    "\n",
    "if is_colab:\n",
    "    !pip install -U nnsight\n",
    "    !git clone https://github.com/AmirZur/nnsight-tutorials.git\n",
    "    %cd nnsight-tutorials/\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036d7c0",
   "metadata": {},
   "source": [
    "## Exploring our mystery model\n",
    "\n",
    "Our mystery model simulates the RAVEL example we went over in the previous tutorial. The model takes in a sentence with two words,\n",
    "* **city**: \"Paris\", \"Rome\", or \"Seattle\"\n",
    "* **property**: \"language\", \"food\", \"country\", or \"?\"\n",
    "\n",
    "and outputs the chosen city's specified property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda7946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnsight\n",
    "import torch\n",
    "from puzzle_utils import construct_mystery_model\n",
    "\n",
    "mystery_model = nnsight.NNsight(construct_mystery_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e8c2b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French\n",
      "pizza\n",
      "USA\n"
     ]
    }
   ],
   "source": [
    "# play around with the model!\n",
    "print(mystery_model(\"Paris language\"))\n",
    "print(mystery_model(\"Rome food\"))\n",
    "print(mystery_model(\"Seattle country\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e507f95",
   "metadata": {},
   "source": [
    "The model architecture is as follows:\n",
    "* **city embedding** (`entity_embed`): linear embedding of the city token (first word).\n",
    "* **property embedding** (`property_embed`): linear embedding of the property token (second word).\n",
    "* **hidden layer** (`hidden_layer`): linear layer over the concatenated city and property embeddings.\n",
    "* **output layer** (`out_head`): classification head for output token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94979c68",
   "metadata": {},
   "source": [
    "![Layer 1: 6-neuron vector over the token Paris, 6-neuron vector over the token Language. Layer 2: 6-neuron vector. Layer 3: single neuron, decoded to French.](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/mystery_model_architecture.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6389ed5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MysteryModel(\n",
       "  (entity_embed): Linear(in_features=3, out_features=6, bias=False)\n",
       "  (property_embed): Linear(in_features=4, out_features=6, bias=False)\n",
       "  (hidden_layer): Sequential(\n",
       "    (linear): Linear(in_features=12, out_features=6, bias=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (out_head): Linear(in_features=6, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystery_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f5cb3",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Note</b>\n",
    "\n",
    "In this tutorial, we'll focus on the <b>city embedding</b>. Follow the code below to inspect the city embeddings for different city tokens. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf048f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Italy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0., 12., 14., 18.,  0., 16.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use nnsight to read the model's representation of Rome\n",
    "source_prompt = \"Rome country\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    with mystery_model.trace(source_prompt):\n",
    "        source_activations = mystery_model.entity_embed.output.save()\n",
    "        source_output = mystery_model.output.save()\n",
    "\n",
    "# entity_embed\n",
    "print('Output:', source_output)\n",
    "source_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b10c8",
   "metadata": {},
   "source": [
    "## Puzzle #1: Parsing the city embeddings\n",
    "\n",
    "Cities are embedded in a 6-dimensional vector. **Each dimension corresponds to a property**, such as the city's language, food, or country. Your puzzle is to figure out how these properties are encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb92a4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Puzzle #1</b>\n",
    "\n",
    "**Your mission, should you choose to accept it**: find out which dimension corresponds to which property. To get you started, we set up a single-dimension version of DAS as in the previous tutorial.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb65c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this is a faster variant of DAS.\n",
    "# instead of creating a full (model dim x model dim) rotation matrix, we focus only on the dimensions we care about with a rotation matrix of size (model dim x # patched subspaces)\n",
    "N_PATCHING_DIMS = 1\n",
    "\n",
    "one_dim_rotator = torch.nn.Linear(mystery_model.hidden_dim, N_PATCHING_DIMS, bias=False)\n",
    "one_dim_rotator.weight.data = torch.tensor([[1., 0., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598d9c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output token ID: 1.0\n",
      "Token ID for \"Italian\": 5\n",
      "Output token: French\n"
     ]
    }
   ],
   "source": [
    "with mystery_model.trace(\"Paris language\") as tracer:\n",
    "    base = mystery_model.entity_embed.output.clone().save()\n",
    "\n",
    "    one_dim_rotation_vector = one_dim_rotator.weight\n",
    "    # get rotated dims from base\n",
    "    rotated_base = torch.matmul(\n",
    "        one_dim_rotation_vector, base\n",
    "    )\n",
    "\n",
    "    # get rotated dims from source\n",
    "    source = source_activations\n",
    "    rotated_source = torch.matmul(\n",
    "        one_dim_rotation_vector, source\n",
    "    )\n",
    "\n",
    "    # remove the rotated base & replace it with the rotated source \n",
    "    rotated_patch = rotated_source - rotated_base\n",
    "\n",
    "    # unrotate patched vector\n",
    "    patch = base + torch.matmul(\n",
    "        one_dim_rotation_vector.T, rotated_patch\n",
    "    )\n",
    "\n",
    "    # replace base with patch\n",
    "    mystery_model.entity_embed.output = patch\n",
    "\n",
    "    # token id of output (with gradient)\n",
    "    patched_output = mystery_model.out_head.output.save()\n",
    "    # decoded token of output (no gradient)\n",
    "    patched_answer = mystery_model.output.save()\n",
    "\n",
    "print(\"Output token ID:\", patched_output.item())\n",
    "print(\"Token ID for \\\"Italian\\\":\", mystery_model.tokenizer.tokenize(\"Italian\", type=\"output\"))\n",
    "print(\"Output token:\", patched_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52a33c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Puzzle #1</b>\n",
    "\n",
    "Can you find the right dimension to change the patched output from \"French\" to \"Italian\"? How about for the other properties (country and food)?\n",
    "\n",
    "Create a map from concept (\"language\", \"food\", and \"country\") to dimension (either one-hot vector or index of the neuron that stores the concept).\n",
    "\n",
    "<i>Hint: applying a softmax to the rotation vector can help reveal the single most important dimension!</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cccd062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60317e16",
   "metadata": {},
   "source": [
    "## Puzzle #2: what's the missing property?\n",
    "\n",
    "We haven't revealed everything to you quite yet! There's a mysterious property - **\"?\"** - that retrieves a city feature. However, right now it isn't working..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb37e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'France'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# something's wrong...\n",
    "mystery_model(\"Seattle ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52016af",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Puzzle #2</b>\n",
    "\n",
    "**Your mission, should you choose to accept it**: using your knowledge from the previous puzzle, inspect the **property embeddings** of the model. Can you **debug the \"?\" embedding**? What property was it supposed to encode?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d509d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
