
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../../../" data-theme="dark">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>A Causal Model of Simple Multiple Choice Question Answering &#8212; nnsight</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "dark";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "dark";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../../../_static/documentation_options.js?v=187304be"></script>
    <script src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/tutorials/causal_mediation_analysis/CausalAbstraction/demos/MCQA_tutorial';</script>
    <script src="../../../../../../_static/js/custom.js?v=1e4be224"></script>
    <script src="../../../../../../_static/js/code.js?v=34343d0c"></script>
    <link rel="icon" href="../../../../../../_static/icon.ico"/>
    <link rel="author" title="About these documents" href="../../../../../../about/" />
    <link rel="index" title="Index" href="../../../../../../genindex/" />
    <link rel="search" title="Search" href="../../../../../../search/" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
<link href="../../../../../../_static/css/custom.css?v=1754348346" rel="stylesheet" type="text/css" />
<link href="../../../../../../_static/css/home.css?v=1754348346" rel="stylesheet" type="text/css" />

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="dark">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../../../">
  
  
  
  
  
    
    
    
    <img src="../../../../../../_static/nnsight_logo.svg" class="logo__image only-dark" alt="nnsight - Home"/>
    <img src="../../../../../../_static/nnsight_logo.svg" class="logo__image only-light pst-js-only" alt="nnsight - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../start/">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../documentation/">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../features/">
    Features
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../tutorials/">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../about/">
    About
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item"><script>
    fetch("https://ndif.dev/ping")
        .then((response) => {
            if (response.status == 200) {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#66800b', 'important');
                    });
                });
            }
            else {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#af3029', 'important');
                    });
                });
                var statusIcon = document.querySelector('.ndif .fa-circle-check');
                if (statusIcon) {
                    // not here
                    statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark'); 
                }
            }
        })
        .catch((response) => {
            Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                    spanElement.style.setProperty('color', '#af3029', 'important');
                });
            });
            var statusIcon = document.querySelector('.ndif .fa-circle-check');
            if (statusIcon) {
                statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark');
            }
        })
</script></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="/status" title="Status: Unknown" class="ndif" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-circle-check fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Status: Unknown</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ndif-team/nnsight" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.ndif.us/" title="Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://forms.gle/1Y6myaXYzSh3oHf56" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../start/">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../documentation/">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../features/">
    Features
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../tutorials/">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../../../about/">
    About
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><script>
    fetch("https://ndif.dev/ping")
        .then((response) => {
            if (response.status == 200) {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#66800b', 'important');
                    });
                });
            }
            else {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#af3029', 'important');
                    });
                });
                var statusIcon = document.querySelector('.ndif .fa-circle-check');
                if (statusIcon) {
                    // not here
                    statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark'); 
                }
            }
        })
        .catch((response) => {
            Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                    spanElement.style.setProperty('color', '#af3029', 'important');
                });
            });
            var statusIcon = document.querySelector('.ndif .fa-circle-check');
            if (statusIcon) {
                statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark');
            }
        })
</script></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="/status" title="Status: Unknown" class="ndif" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-circle-check fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Status: Unknown</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ndif-team/nnsight" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.ndif.us/" title="Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://forms.gle/1Y6myaXYzSh3oHf56" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../../../" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">A Causal Model of Simple Multiple Choice Question Answering</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="A-Causal-Model-of-Simple-Multiple-Choice-Question-Answering">
<h1>A Causal Model of Simple Multiple Choice Question Answering<a class="headerlink" href="#A-Causal-Model-of-Simple-Multiple-Choice-Question-Answering" title="Link to this heading">#</a></h1>
<p>A causal model is a directed graph of <strong>variables</strong> that each have a <strong>mechanism</strong> that determines the variables <strong>value</strong> based on the values of its parents.</p>
<p>Every causal model in this code base is required to have two particular variables:</p>
<ul class="simple">
<li><p>“raw_input” is the variable with a value that can be plugged into a neural network via Pipeline.load().</p></li>
<li><p>“raw_output” is the variable with a value that can be compared with Pipeline.dump(), the neural network output.</p></li>
</ul>
<p>The causal model we define below creates a simple multiple choice question answering (MCQA) dataset where world knowledge about the color of an object is stated and then the color of that object is asked about.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">causal.causal_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">CausalModel</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="n">OBJECT_COLORS</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;banana&quot;</span><span class="p">,</span> <span class="s2">&quot;yellow&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;grass&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;strawberry&quot;</span><span class="p">,</span> <span class="s2">&quot;red&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;coconut&quot;</span><span class="p">,</span> <span class="s2">&quot;brown&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;eggplant&quot;</span><span class="p">,</span> <span class="s2">&quot;purple&quot;</span><span class="p">),</span>
                 <span class="p">(</span><span class="s2">&quot;blueberry&quot;</span><span class="p">,</span> <span class="s2">&quot;blue&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;carrot&quot;</span><span class="p">,</span> <span class="s2">&quot;orange&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;coal&quot;</span><span class="p">,</span> <span class="s2">&quot;black&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;snow&quot;</span><span class="p">,</span> <span class="s2">&quot;white&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;ivory&quot;</span><span class="p">,</span> <span class="s2">&quot;white&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;cauliflower&quot;</span><span class="p">,</span> <span class="s2">&quot;white&quot;</span><span class="p">),</span>
                 <span class="p">(</span><span class="s2">&quot;bubblegum&quot;</span><span class="p">,</span> <span class="s2">&quot;pink&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;lemon&quot;</span><span class="p">,</span> <span class="s2">&quot;yellow&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;lime&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;ruby&quot;</span><span class="p">,</span> <span class="s2">&quot;red&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;chocolate&quot;</span><span class="p">,</span> <span class="s2">&quot;brown&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;emerald&quot;</span><span class="p">,</span> <span class="s2">&quot;green&quot;</span><span class="p">),</span>
                 <span class="p">(</span><span class="s2">&quot;sapphire&quot;</span><span class="p">,</span> <span class="s2">&quot;blue&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;pumpkin&quot;</span><span class="p">,</span> <span class="s2">&quot;orange&quot;</span><span class="p">)]</span>
<span class="n">OBJECTS</span><span class="p">,</span> <span class="n">COLORS</span><span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">OBJECT_COLORS</span><span class="p">)</span>
<span class="n">COLORS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">COLORS</span><span class="p">))</span>  <span class="c1"># Ensure unique colors</span>

<span class="n">NUM_CHOICES</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">ALPHABET</span> <span class="o">=</span> <span class="s2">&quot;ABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;</span>
<span class="n">TEMPLATES</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;The &lt;object&gt; is &lt;color&gt;. What color is the &lt;object&gt;?&quot;</span> <span class="o">+</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&lt;symbol</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="si">}</span><span class="s2">&gt;. &lt;choice</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="si">}</span><span class="s2">&gt;&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)])</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Answer:&quot;</span><span class="p">]</span>

<span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;template&quot;</span><span class="p">,</span> <span class="s2">&quot;object_color&quot;</span><span class="p">,</span> <span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">,</span> <span class="s2">&quot;answer&quot;</span><span class="p">,</span> <span class="s2">&quot;raw_output&quot;</span><span class="p">]</span>

<span class="n">values</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="n">COLORS</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)}</span>
<span class="n">values</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="n">ALPHABET</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)})</span>
<span class="n">values</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;answer_position&quot;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">),</span> <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="n">ALPHABET</span><span class="p">})</span>
<span class="n">values</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;template&quot;</span><span class="p">:</span> <span class="n">TEMPLATES</span><span class="p">})</span>
<span class="n">values</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;object_color&quot;</span><span class="p">:</span> <span class="n">OBJECT_COLORS</span><span class="p">})</span>
<span class="n">values</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;raw_input&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;raw_output&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">})</span>

<span class="n">parents</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;template&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;object_color&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;raw_input&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;template&quot;</span><span class="p">,</span> <span class="s2">&quot;object_color&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)],</span>
        <span class="s2">&quot;answer_position&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;object_color&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)],</span>
        <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)],</span>
        <span class="s2">&quot;raw_output&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">],</span>
        <span class="p">}</span>
<span class="n">parents</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)})</span>
<span class="n">parents</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)})</span>

<span class="k">def</span><span class="w"> </span><span class="nf">fill_template</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="n">template</span><span class="p">,</span> <span class="n">object_color</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">symbols</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">2</span> <span class="o">+</span> <span class="n">NUM_CHOICES</span><span class="p">]</span>
    <span class="n">choices</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span> <span class="o">+</span> <span class="n">NUM_CHOICES</span><span class="p">:</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">NUM_CHOICES</span><span class="p">]</span>

    <span class="n">object_name</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">object_color</span>
    <span class="n">filled_template</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;object&gt;&quot;</span><span class="p">,</span> <span class="n">object_name</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;color&gt;&quot;</span><span class="p">,</span> <span class="n">color</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">symbol</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">symbols</span><span class="p">):</span>
        <span class="n">filled_template</span> <span class="o">=</span> <span class="n">filled_template</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;symbol</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&gt;&quot;</span><span class="p">,</span> <span class="n">symbol</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">choice</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">choices</span><span class="p">):</span>
        <span class="n">filled_template</span> <span class="o">=</span> <span class="n">filled_template</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;choice</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&gt;&quot;</span><span class="p">,</span> <span class="n">choice</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">filled_template</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_answer_position</span><span class="p">(</span><span class="n">object_color</span><span class="p">,</span> <span class="o">*</span><span class="n">choices</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">choice</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">choices</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">choice</span> <span class="o">==</span> <span class="n">object_color</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">return</span> <span class="n">i</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_answer</span><span class="p">(</span><span class="n">answer_position</span><span class="p">,</span> <span class="o">*</span><span class="n">symbols</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">answer_position</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">symbols</span><span class="p">[</span><span class="n">answer_position</span><span class="p">]</span>

<span class="n">mechanisms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;template&quot;</span><span class="p">:</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">TEMPLATES</span><span class="p">),</span>
    <span class="s2">&quot;object_color&quot;</span><span class="p">:</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">OBJECT_COLORS</span><span class="p">),</span>
    <span class="o">**</span><span class="p">{</span><span class="sa">f</span><span class="s2">&quot;symbol</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">ALPHABET</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)},</span>
    <span class="o">**</span><span class="p">{</span><span class="sa">f</span><span class="s2">&quot;choice</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">COLORS</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)},</span>
    <span class="s2">&quot;raw_input&quot;</span><span class="p">:</span> <span class="n">fill_template</span><span class="p">,</span>
    <span class="s2">&quot;answer_position&quot;</span><span class="p">:</span> <span class="n">get_answer_position</span><span class="p">,</span>
    <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="n">get_answer</span><span class="p">,</span>
    <span class="s2">&quot;raw_output&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">x</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">MCQA_causal_model</span> <span class="o">=</span> <span class="n">CausalModel</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">parents</span><span class="p">,</span> <span class="n">mechanisms</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">NUM_CHOICES</span><span class="si">}</span><span class="s2">_answer_MCQA&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We have input variables for the answer choices and the symbol associated with each choice, an object/color pair, and a template for embedding the object, color, choices, and symbols into a well-formed multiple choice question. We have an intermediary variable with a mechanism that determines the position of the correct choice. The answer variable has a mechanism that uses the positional information to index into the symbol tokens and select the right answer.</p>
<p>The raw_input variable uses the template to form an LM query and the raw_output is simply a direct copy of the answer.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">print_structure</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_3_0.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_3_0.png" />
</div>
</div>
<p>Causal model inputs are dictionaries from variable names to values. Now we can write a sampler that generates questions that can be answered, i.e., the color of the object appears among the choices.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sample_answerable_question</span><span class="p">():</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">sample_input</span><span class="p">()</span>
    <span class="c1">#sample unique choices and symbols</span>
    <span class="n">choices</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">COLORS</span><span class="p">,</span> <span class="n">NUM_CHOICES</span><span class="p">)</span>
    <span class="n">symbols</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">ALPHABET</span><span class="p">,</span> <span class="n">NUM_CHOICES</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">):</span>
        <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="o">=</span> <span class="n">choices</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;object_color&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">input</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)]:</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">NUM_CHOICES</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;object_color&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">input</span>

<span class="n">example</span> <span class="o">=</span> <span class="n">sample_answerable_question</span><span class="p">()</span>
<span class="n">full_setting</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Example input:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">example</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Full setting determined by the causal model:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">full_setting</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">example</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Example input:
template: The &lt;object&gt; is &lt;color&gt;. What color is the &lt;object&gt;?
&lt;symbol0&gt;. &lt;choice0&gt;
&lt;symbol1&gt;. &lt;choice1&gt;
Answer:

object_color: (&#39;coal&#39;, &#39;black&#39;)

symbol0: N

symbol1: Y

choice0: red

choice1: black


Full setting determined by the causal model:
answer_position: 1

answer: Y

raw_input: The coal is black. What color is the coal?
N. red
Y. black
Answer:

raw_output:  Y

</pre></div></div>
</div>
</section>
<section id="Loading-in-the-language-model">
<h1>Loading in the language model<a class="headerlink" href="#Loading-in-the-language-model" title="Link to this heading">#</a></h1>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">neural.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">LMPipeline</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:1&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;meta-llama/Meta-Llama-3.1-8B-Instruct&quot;</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">LMPipeline</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;left&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">checker</span><span class="p">(</span><span class="n">neural_output</span><span class="p">,</span> <span class="n">causal_output</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">causal_output</span> <span class="ow">in</span> <span class="n">neural_output</span> <span class="ow">or</span> <span class="n">neural_output</span> <span class="ow">in</span> <span class="n">causal_output</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DEVICE:&quot;</span><span class="p">,</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "fdbf5dd4d31443ee9158e5267a499f2b", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
DEVICE: cuda:1
</pre></div></div>
</div>
</section>
<section id="Single-example-causal-tracing">
<h1>Single example causal tracing<a class="headerlink" href="#Single-example-causal-tracing" title="Link to this heading">#</a></h1>
<p>In this experiment, we trace how the causal effect from a crucial input token flows to the output token. Namely, we focus on how the symbol token for the correct answer effects the output. We start by writing a function that samples an input and then generates the counterfactual where that the answer is in the same position, but the symbol for the correct answer has been replaced.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">different_symbol_same_position</span><span class="p">():</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">sample_answerable_question</span><span class="p">()</span>
    <span class="n">counterfactual</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">full_setting</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

    <span class="n">current_symbols</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)]</span>
    <span class="n">complement</span> <span class="o">=</span> <span class="p">[</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ALPHABET</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">current_symbols</span><span class="p">]</span>
    <span class="n">new_symbol</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">complement</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">full_setting</span><span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">new_symbol</span>

    <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">full_setting</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">counterfactual</span><span class="p">)[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span><span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;counterfactual_inputs&quot;</span><span class="p">:[</span><span class="n">counterfactual</span><span class="p">]}</span>

<span class="n">example</span> <span class="o">=</span> <span class="n">different_symbol_same_position</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Example input:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;input: </span><span class="si">{</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;input&#39;</span><span class="p">][</span><span class="s1">&#39;raw_input&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Counterfactual example:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;input: </span><span class="si">{</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;counterfactual_inputs&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;raw_input&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Example input:
input: The lemon is yellow. What color is the lemon?
V. green
L. yellow
Answer:

Counterfactual example:
input: The lemon is yellow. What color is the lemon?
V. green
U. yellow
Answer:
</pre></div></div>
</div>
<p>Check that the language model correctly answers the original and counterfactual inputs. Resample the input if an assertion error occurs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_example</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">]</span>
<span class="n">counterfactual_example</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s2">&quot;counterfactual_inputs&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Check if the model gets both examples correct</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing model predictions:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Test original</span>
<span class="n">original_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_example</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Original prediction: </span><span class="si">{</span><span class="n">original_pred</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">causal_output</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">input_example</span><span class="p">)[</span><span class="s2">&quot;raw_output&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Causal output: </span><span class="si">{</span><span class="n">causal_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">checker</span><span class="p">(</span><span class="n">original_pred</span><span class="p">,</span> <span class="n">causal_output</span><span class="p">),</span> <span class="s2">&quot;Original prediction does not match causal output!&quot;</span>

<span class="c1"># Test counterfactual</span>
<span class="n">counterfactual_pred</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">counterfactual_example</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Counterfactual prediction: </span><span class="si">{</span><span class="n">counterfactual_pred</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">causal_output</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">counterfactual_example</span><span class="p">)[</span><span class="s2">&quot;raw_output&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Causal output: </span><span class="si">{</span><span class="n">causal_output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">checker</span><span class="p">(</span><span class="n">counterfactual_pred</span><span class="p">,</span> <span class="n">causal_output</span><span class="p">),</span> <span class="s2">&quot;Counterfactual prediction does not match causal output!&quot;</span>
<br/><br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

==================================================
Testing model predictions:
==================================================
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/atticus/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/atticus/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Original prediction:  L
Causal output:  L

Counterfactual prediction:  U
Causal output:  U
</pre></div></div>
</div>
<section id="Visualizing-the-results-interchange-interventions-for-a-single-pair-of-inputs">
<h2>Visualizing the results interchange interventions for a single pair of inputs<a class="headerlink" href="#Visualizing-the-results-interchange-interventions-for-a-single-pair-of-inputs" title="Link to this heading">#</a></h2>
<p>We perform an interchange intervention on full vectors of the residual stream, i.e., the transformer block output, in the language model for every token position and every layer. After each intervention, we record the output of the language model. When an intervention results in the output the language model would have provided for the counterfactual input, we know that the signal from the token change is contained in that vector.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the tracing experiment</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">experiments.residual_stream_experiment</span><span class="w"> </span><span class="kn">import</span> <span class="n">SameLengthResidualStreamTracing</span>

<span class="c1"># Run the tracing experiment</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running SameLengthResidualStreamTracing experiment...&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Create the tracing experiment</span>
<span class="n">tracing_exp</span> <span class="o">=</span> <span class="n">SameLengthResidualStreamTracing</span><span class="p">(</span>
    <span class="n">pipeline</span><span class="o">=</span><span class="n">pipeline</span><span class="p">,</span>
    <span class="n">causal_model</span><span class="o">=</span><span class="n">MCQA_causal_model</span><span class="p">,</span>
    <span class="n">checker</span><span class="o">=</span><span class="n">checker</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Run the experiment with our counterfactual pair</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">tracing_exp</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">base_input</span><span class="o">=</span><span class="n">input_example</span><span class="p">,</span>
    <span class="n">counterfactual_input</span><span class="o">=</span><span class="n">counterfactual_example</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Tracing completed for </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="si">}</span><span class="s2"> layer-position combinations&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
nnsight is not detected. Please install via &#39;pip install nnsight&#39; for nnsight backend.

==================================================
Running SameLengthResidualStreamTracing experiment...
==================================================
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/atticus/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/atticus/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_13_2.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_13_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_13_3.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_13_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Tracing completed for 4 layer-position combinations
</pre></div></div>
</div>
</section>
</section>
<section id="Aggregating-Interchange-Intervention-Experiments">
<h1>Aggregating Interchange Intervention Experiments<a class="headerlink" href="#Aggregating-Interchange-Intervention-Experiments" title="Link to this heading">#</a></h1>
<p>Using a single pair of examples is useful as an exploratory experiment, but rigorously supporting mechanistic interpretability hypotheses requires systematic evaluations of aggregated results from many experiments.</p>
<section id="Constructing-Counterfactual-Examples-to-Localize-the-Answer-Position-Variable">
<h2>Constructing Counterfactual Examples to Localize the Answer Position Variable<a class="headerlink" href="#Constructing-Counterfactual-Examples-to-Localize-the-Answer-Position-Variable" title="Link to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">causal.causal_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">CounterfactualDataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">CounterfactualDataset</span><span class="o">.</span><span class="n">from_sampler</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">different_symbol_same_position</span><span class="p">)</span>
<span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">can_distinguish_with_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
<span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">can_distinguish_with_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Can distinguish between [&#39;answer_position&#39;] and [&#39;answer&#39;]: 100 out of 100 examples
Proportion of distinguishable examples: 1.00
Can distinguish between [&#39;answer_position&#39;] and None: 0 out of 100 examples
Proportion of distinguishable examples: 0.00
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;proportion&#39;: 0.0, &#39;count&#39;: 0}
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">causal.causal_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">CounterfactualDataset</span>

<span class="k">def</span><span class="w"> </span><span class="nf">same_symbol_different_position</span><span class="p">():</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">sample_answerable_question</span><span class="p">()</span>
    <span class="n">counterfactual</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="n">pos</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">]</span>
    <span class="n">new_pos</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">pos</span><span class="p">])</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pos</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_pos</span><span class="p">)]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_pos</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pos</span><span class="p">)]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pos</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_pos</span><span class="p">)]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_pos</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pos</span><span class="p">)]</span>
    <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">counterfactual</span><span class="p">)[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span><span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;counterfactual_inputs&quot;</span><span class="p">:[</span><span class="n">counterfactual</span><span class="p">]}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">different_symbol_different_position</span><span class="p">():</span>
    <span class="nb">input</span> <span class="o">=</span> <span class="n">sample_answerable_question</span><span class="p">()</span>
    <span class="n">counterfactual</span> <span class="o">=</span> <span class="nb">input</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c1">#Different position</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">]</span>
    <span class="n">new_pos</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">pos</span><span class="p">])</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pos</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_pos</span><span class="p">)]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">new_pos</span><span class="p">)]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;choice&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pos</span><span class="p">)]</span>

    <span class="c1">#Different symbol</span>
    <span class="n">current_symbols</span> <span class="o">=</span> <span class="p">[</span><span class="nb">input</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">)]</span>
    <span class="n">complement</span> <span class="o">=</span> <span class="p">[</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ALPHABET</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">current_symbols</span><span class="p">]</span>
    <span class="n">new_symbols</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">complement</span><span class="p">,</span> <span class="n">NUM_CHOICES</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_CHOICES</span><span class="p">):</span>
        <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;symbol&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">new_symbols</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">counterfactual</span><span class="p">)[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span><span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;counterfactual_inputs&quot;</span><span class="p">:[</span><span class="n">counterfactual</span><span class="p">]}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">random_counterfactual</span><span class="p">():</span>
    <span class="nb">input</span><span class="p">,</span> <span class="n">counterfactual</span> <span class="o">=</span> <span class="n">sample_answerable_question</span><span class="p">(),</span> <span class="n">sample_answerable_question</span><span class="p">()</span>
    <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>
    <span class="n">counterfactual</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">counterfactual</span><span class="p">)[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;input&quot;</span><span class="p">:</span><span class="nb">input</span><span class="p">,</span> <span class="s2">&quot;counterfactual_inputs&quot;</span><span class="p">:[</span><span class="n">counterfactual</span><span class="p">]}</span>

<span class="n">counterfactual_datasets</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;same_symbol_different_position&quot;</span><span class="p">:</span> <span class="n">CounterfactualDataset</span><span class="o">.</span><span class="n">from_sampler</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">same_symbol_different_position</span><span class="p">),</span>
                            <span class="s2">&quot;different_symbol_different_position&quot;</span><span class="p">:</span> <span class="n">CounterfactualDataset</span><span class="o">.</span><span class="n">from_sampler</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">different_symbol_different_position</span><span class="p">),</span>
                            <span class="s2">&quot;different_symbol_same_position&quot;</span><span class="p">:</span> <span class="n">CounterfactualDataset</span><span class="o">.</span><span class="n">from_sampler</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">different_symbol_same_position</span><span class="p">),</span>
                            <span class="s2">&quot;random_counterfactual&quot;</span><span class="p">:</span> <span class="n">CounterfactualDataset</span><span class="o">.</span><span class="n">from_sampler</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_counterfactual</span><span class="p">)</span> <span class="p">}</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">can_distinguish_with_dataset</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="p">[</span><span class="s2">&quot;same_symbol_different_position&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
<span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">can_distinguish_with_dataset</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="p">[</span><span class="s2">&quot;same_symbol_different_position&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">can_distinguish_with_dataset</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="p">[</span><span class="s2">&quot;random_counterfactual&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
<span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">can_distinguish_with_dataset</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="p">[</span><span class="s2">&quot;random_counterfactual&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="kc">None</span><span class="p">)</span>

<span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">can_distinguish_with_dataset</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="p">[</span><span class="s2">&quot;different_symbol_different_position&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
<span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">can_distinguish_with_dataset</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="p">[</span><span class="s2">&quot;different_symbol_different_position&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Can distinguish between [&#39;answer_position&#39;] and [&#39;answer&#39;]: 100 out of 100 examples
Proportion of distinguishable examples: 1.00
Can distinguish between [&#39;answer_position&#39;] and None: 100 out of 100 examples
Proportion of distinguishable examples: 1.00
Can distinguish between [&#39;answer_position&#39;] and [&#39;answer&#39;]: 96 out of 100 examples
Proportion of distinguishable examples: 0.96
Can distinguish between [&#39;answer_position&#39;] and None: 46 out of 100 examples
Proportion of distinguishable examples: 0.46
Can distinguish between [&#39;answer_position&#39;] and [&#39;answer&#39;]: 100 out of 100 examples
Proportion of distinguishable examples: 1.00
Can distinguish between [&#39;answer_position&#39;] and None: 100 out of 100 examples
Proportion of distinguishable examples: 1.00
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;proportion&#39;: 1.0, &#39;count&#39;: 100}
</pre></div></div>
</div>
</section>
<section id="Filtering-Out-Examples-the-Language-Model-Answers-Incorrectly">
<h2>Filtering Out Examples the Language Model Answers Incorrectly<a class="headerlink" href="#Filtering-Out-Examples-the-Language-Model-Answers-Incorrectly" title="Link to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get a sample input and check model&#39;s prediction</span>
<span class="n">sampled_example</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="o">.</span><span class="n">values</span><span class="p">()))[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;INPUT:&quot;</span><span class="p">,</span> <span class="n">sampled_example</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;EXPECTED OUTPUT:&quot;</span><span class="p">,</span> <span class="n">MCQA_causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="n">sampled_example</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">])[</span><span class="s2">&quot;raw_output&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MODEL PREDICTION:&quot;</span><span class="p">,</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">sampled_example</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
INPUT: {&#39;choice0&#39;: &#39;pink&#39;, &#39;choice1&#39;: &#39;green&#39;, &#39;object_color&#39;: [&#39;grass&#39;, &#39;green&#39;], &#39;raw_input&#39;: &#39;The grass is green. What color is the grass?\nF. pink\nR. green\nAnswer:&#39;, &#39;symbol0&#39;: &#39;F&#39;, &#39;symbol1&#39;: &#39;R&#39;, &#39;template&#39;: &#39;The &lt;object&gt; is &lt;color&gt;. What color is the &lt;object&gt;?\n&lt;symbol0&gt;. &lt;choice0&gt;\n&lt;symbol1&gt;. &lt;choice1&gt;\nAnswer:&#39;}
EXPECTED OUTPUT:  R
MODEL PREDICTION:  R
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/atticus/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/atticus/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">experiments.filter_experiment</span><span class="w"> </span><span class="kn">import</span> <span class="n">FilterExperiment</span>
<span class="c1"># Filter the datasets based on model performance</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Filtering datasets based on model performance...&quot;</span><span class="p">)</span>
<span class="n">exp</span> <span class="o">=</span> <span class="n">FilterExperiment</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">MCQA_causal_model</span><span class="p">,</span> <span class="n">checker</span><span class="p">)</span>
<span class="n">filtered_datasets</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Filtering datasets based on model performance...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Filtering same_symbol_different_position: 100%|██████████| 1/1 [00:01&lt;00:00,  1.58s/it]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Dataset &#39;same_symbol_different_position&#39;: kept 100/100 examples (100.0%)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Filtering different_symbol_different_position: 100%|██████████| 1/1 [00:01&lt;00:00,  1.57s/it]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Dataset &#39;different_symbol_different_position&#39;: kept 100/100 examples (100.0%)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Filtering different_symbol_same_position: 100%|██████████| 1/1 [00:01&lt;00:00,  1.66s/it]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Dataset &#39;different_symbol_same_position&#39;: kept 99/100 examples (99.0%)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Filtering random_counterfactual: 100%|██████████| 1/1 [00:01&lt;00:00,  1.58s/it]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Dataset &#39;random_counterfactual&#39;: kept 100/100 examples (100.0%)

Total filtering results:
Original examples: 400
Kept examples: 399
Overall keep rate: 99.8%
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
</section>
<section id="Define-token-positions-of-interest">
<h2>Define token positions of interest<a class="headerlink" href="#Define-token-positions-of-interest" title="Link to this heading">#</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">neural.LM_units</span><span class="w"> </span><span class="kn">import</span> <span class="n">TokenPosition</span><span class="p">,</span> <span class="n">get_last_token_index</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_correct_symbol_index</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">causal_model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Find the index of the correct answer symbol in the prompt.</span>

<span class="sd">    Args:</span>
<span class="sd">        input (Dict): The input dictionary to a causal model</span>
<span class="sd">        pipeline: The tokenizer pipeline</span>

<span class="sd">    Returns:</span>
<span class="sd">        list[int]: List containing the index of the correct answer symbol token</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Run the model to get the answer position</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">causal_model</span><span class="o">.</span><span class="n">run_forward</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">]</span>
    <span class="n">correct_symbol</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;symbol</span><span class="si">{</span><span class="n">pos</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="s2">&quot;raw_input&quot;</span><span class="p">]</span>

    <span class="c1"># Find all single uppercase letters in the prompt</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">re</span><span class="o">.</span><span class="n">finditer</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\b[A-Z]\b&quot;</span><span class="p">,</span> <span class="n">prompt</span><span class="p">))</span>

    <span class="c1"># Find the match corresponding to our correct symbol</span>
    <span class="n">symbol_match</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matches</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">prompt</span><span class="p">[</span><span class="n">match</span><span class="o">.</span><span class="n">start</span><span class="p">():</span><span class="n">match</span><span class="o">.</span><span class="n">end</span><span class="p">()]</span> <span class="o">==</span> <span class="n">correct_symbol</span><span class="p">:</span>
            <span class="n">symbol_match</span> <span class="o">=</span> <span class="n">match</span>
            <span class="k">break</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">symbol_match</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Could not find correct symbol </span><span class="si">{</span><span class="n">correct_symbol</span><span class="si">}</span><span class="s2"> in prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Get the substring up to the symbol match end</span>
    <span class="n">substring</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">[:</span><span class="n">symbol_match</span><span class="o">.</span><span class="n">end</span><span class="p">()]</span>
    <span class="n">tokenized_substring</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">substring</span><span class="p">)[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># The symbol token will be at the end of the substring</span>
    <span class="k">return</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenized_substring</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># Create TokenPosition object</span>
<span class="n">token_positions</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">TokenPosition</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">get_correct_symbol_index</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">MCQA_causal_model</span><span class="p">),</span> <span class="n">pipeline</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;correct_symbol&quot;</span><span class="p">),</span>
    <span class="n">TokenPosition</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span><span class="n">get_correct_symbol_index</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">,</span> <span class="n">MCQA_causal_model</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">pipeline</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;correct_symbol_period&quot;</span><span class="p">),</span>
    <span class="n">TokenPosition</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">get_last_token_index</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pipeline</span><span class="p">),</span> <span class="n">pipeline</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="s2">&quot;last_token&quot;</span><span class="p">)</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<p>We can use a method from the TokenPosition class to print out the token position selected for an example:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">token_position</span> <span class="ow">in</span> <span class="n">token_positions</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Token position: </span><span class="si">{</span><span class="n">token_position</span><span class="o">.</span><span class="n">id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">example</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">counterfactual_datasets</span><span class="o">.</span><span class="n">values</span><span class="p">()))[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Selected token: </span><span class="si">{</span><span class="n">token_position</span><span class="o">.</span><span class="n">highlight_selected_token</span><span class="p">(</span><span class="n">example</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Token position: correct_symbol
Selected token: &lt;|begin_of_text|&gt;The grass is green. What color is the grass?
F. pink
**R**. green
Answer:

Token position: correct_symbol_period
Selected token: &lt;|begin_of_text|&gt;The grass is green. What color is the grass?
F. pink
R**.** green
Answer:

Token position: last_token
Selected token: &lt;|begin_of_text|&gt;The grass is green. What color is the grass?
F. pink
R. green
Answer**:**
</pre></div></div>
</div>
</section>
<section id="Performing-Interchange-Interventions-on-the-Residual-Stream">
<h2>Performing Interchange Interventions on the Residual Stream<a class="headerlink" href="#Performing-Interchange-Interventions-on-the-Residual-Stream" title="Link to this heading">#</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">experiments.residual_stream_experiment</span><span class="w"> </span><span class="kn">import</span> <span class="n">PatchResidualStream</span>

<span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">get_num_layers</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;batch_size&quot;</span><span class="p">:</span><span class="mi">128</span><span class="p">}</span>
<span class="n">target_variables_list</span>  <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;answer&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">]]</span>
<span class="n">results_dir</span> <span class="o">=</span> <span class="s2">&quot;MCQA_demo_results&quot;</span>
<br/><br/></pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">PatchResidualStream</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">MCQA_causal_model</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)),</span> <span class="n">token_positions</span><span class="p">,</span> <span class="n">checker</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">raw_results</span> <span class="o">=</span> <span class="n">experiment</span><span class="o">.</span><span class="n">perform_interventions</span><span class="p">(</span><span class="n">filtered_datasets</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">target_variables_list</span><span class="o">=</span><span class="n">target_variables_list</span><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><span class="n">results_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Heatmaps for &#39;answer&#39; variable:&quot;</span><span class="p">)</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">plot_heatmaps</span><span class="p">(</span><span class="n">raw_results</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Heatmaps for &#39;answer_position&#39; variable:&quot;</span><span class="p">)</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">plot_heatmaps</span><span class="p">(</span><span class="n">raw_results</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Heatmaps for &#39;answer&#39; variable:
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_1.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_2.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_3.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_4.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_4.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Heatmaps for &#39;answer_position&#39; variable:
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_6.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_6.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_7.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_7.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_8.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_8.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_9.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_29_9.png" />
</div>
</div>
</section>
</section>
<section id="Train-Featurizers-with-DAS">
<h1>Train Featurizers with DAS<a class="headerlink" href="#Train-Featurizers-with-DAS" title="Link to this heading">#</a></h1>
<p>For each token position and model layer we train a set of 16 orthogonal linear features to realize the answer_position variable in the causal model. We again perform interchange interventions on the causal model and the language model, but we will now use the output of the causal model under intervention as a source of supervision to learn where to intervene in the language model. Instead of intervening on the full residual stream vector of the language model, we intervene on a linear subspace
that is parameterized using 16 orthogonal vectors. Then we update these orthogonal vectors such that the output of the LM under interchange intervention is the same as the output of the causal model under interchange intervention.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
    <span class="s2">&quot;evaluation_batch_size&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s2">&quot;training_epoch&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s2">&quot;n_features&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">experiment</span> <span class="o">=</span> <span class="n">PatchResidualStream</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">MCQA_causal_model</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)),</span> <span class="n">token_positions</span><span class="p">,</span> <span class="n">checker</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">train_interventions</span><span class="p">(</span><span class="n">filtered_datasets</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;DAS&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">raw_results</span> <span class="o">=</span> <span class="n">experiment</span><span class="o">.</span><span class="n">perform_interventions</span><span class="p">(</span><span class="n">filtered_datasets</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">target_variables_list</span><span class="o">=</span><span class="n">target_variables_list</span><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><span class="n">results_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.83it/s, loss=3.75, accuracy=0.2, token_accuracy=0.2]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.78it/s, loss=3.57, accuracy=0.2, token_accuracy=0.2]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=3.45, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.81it/s, loss=3.39, accuracy=0.2, token_accuracy=0.2]
Epoch: 4: 100%|██████████| 25/25 [00:09&lt;00:00,  2.71it/s, loss=3.38, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.81it/s, loss=3.34, accuracy=0.33, token_accuracy=0.33]
Epoch: 6: 100%|██████████| 25/25 [00:09&lt;00:00,  2.69it/s, loss=3.39, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.81it/s, loss=3.26, accuracy=0.33, token_accuracy=0.33]
Epoch: 100%|██████████| 8/8 [01:11&lt;00:00,  8.99s/it]
Epoch: 0: 100%|██████████| 25/25 [00:09&lt;00:00,  2.70it/s, loss=3.54, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=3.36, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=3.28, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.81it/s, loss=3.2, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.80it/s, loss=3.15, accuracy=0.4, token_accuracy=0.4]
Epoch: 5: 100%|██████████| 25/25 [00:09&lt;00:00,  2.74it/s, loss=3.11, accuracy=0.6, token_accuracy=0.6]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.81it/s, loss=3.04, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:09&lt;00:00,  2.77it/s, loss=3.11, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [01:11&lt;00:00,  8.98s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.83it/s, loss=3.8, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=3.79, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=3.78, accuracy=0.67, token_accuracy=0.67]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.81it/s, loss=3.79, accuracy=0.13, token_accuracy=0.13]
Epoch: 4: 100%|██████████| 25/25 [00:09&lt;00:00,  2.76it/s, loss=3.78, accuracy=0.33, token_accuracy=0.33]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.83it/s, loss=3.78, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=3.78, accuracy=0.4, token_accuracy=0.4]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=3.78, accuracy=0.33, token_accuracy=0.33]
Epoch: 100%|██████████| 8/8 [01:11&lt;00:00,  8.89s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=3.55, accuracy=0.2, token_accuracy=0.2]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.86it/s, loss=3.23, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=3.01, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.80it/s, loss=2.82, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.86it/s, loss=2.78, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.83it/s, loss=2.64, accuracy=0.2, token_accuracy=0.2]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=2.53, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=2.66, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [01:10&lt;00:00,  8.80s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=3.29, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=2.62, accuracy=0.53, token_accuracy=0.53]
Epoch: 2: 100%|██████████| 25/25 [00:09&lt;00:00,  2.77it/s, loss=2.39, accuracy=0.8, token_accuracy=0.8]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.85it/s, loss=2.17, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.85it/s, loss=2, accuracy=0.6, token_accuracy=0.6]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.86it/s, loss=2.03, accuracy=0.67, token_accuracy=0.67]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.85it/s, loss=1.88, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:09&lt;00:00,  2.77it/s, loss=1.99, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [01:10&lt;00:00,  8.85s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=3.78, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=3.76, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=3.75, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=3.74, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.80it/s, loss=3.74, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=3.73, accuracy=0.27, token_accuracy=0.27]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=3.73, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=3.73, accuracy=0.2, token_accuracy=0.2]
Epoch: 100%|██████████| 8/8 [01:10&lt;00:00,  8.79s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=3.26, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.85it/s, loss=2.69, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.86it/s, loss=2.31, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.81it/s, loss=2.05, accuracy=0.73, token_accuracy=0.73]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=1.99, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=1.92, accuracy=0.6, token_accuracy=0.6]
Epoch: 6: 100%|██████████| 25/25 [00:09&lt;00:00,  2.73it/s, loss=1.72, accuracy=0.33, token_accuracy=0.33]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=1.8, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [01:10&lt;00:00,  8.78s/it]
Epoch: 0: 100%|██████████| 25/25 [00:09&lt;00:00,  2.71it/s, loss=3.14, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=2.22, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=2.03, accuracy=0.47, token_accuracy=0.47]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=1.88, accuracy=0.6, token_accuracy=0.6]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=1.83, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:09&lt;00:00,  2.77it/s, loss=1.77, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=1.77, accuracy=0.73, token_accuracy=0.73]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=1.79, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [01:10&lt;00:00,  8.80s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=3.75, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=3.67, accuracy=0.13, token_accuracy=0.13]
Epoch: 2: 100%|██████████| 25/25 [00:09&lt;00:00,  2.78it/s, loss=3.63, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=3.6, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=3.59, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=3.57, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=3.54, accuracy=0.33, token_accuracy=0.33]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=3.53, accuracy=0.27, token_accuracy=0.27]
Epoch: 100%|██████████| 8/8 [01:09&lt;00:00,  8.71s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=3.21, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=2.31, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=2.19, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=1.94, accuracy=0.67, token_accuracy=0.67]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=1.9, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=1.76, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=1.72, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.84it/s, loss=1.72, accuracy=0.73, token_accuracy=0.73]
Epoch: 100%|██████████| 8/8 [01:09&lt;00:00,  8.67s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.93it/s, loss=2.82, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=2.09, accuracy=0.67, token_accuracy=0.67]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=1.84, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=1.5, accuracy=0.67, token_accuracy=0.67]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.82it/s, loss=1.79, accuracy=0.6, token_accuracy=0.6]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=1.4, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=1.39, accuracy=0.8, token_accuracy=0.8]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=1.19, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [01:09&lt;00:00,  8.64s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=3.71, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.79it/s, loss=3.61, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=3.59, accuracy=0.6, token_accuracy=0.6]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=3.55, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=3.55, accuracy=0.33, token_accuracy=0.33]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=3.53, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=3.53, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.90it/s, loss=3.51, accuracy=0.2, token_accuracy=0.2]
Epoch: 100%|██████████| 8/8 [01:09&lt;00:00,  8.67s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=2.78, accuracy=0.53, token_accuracy=0.53]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.83it/s, loss=2.21, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.95it/s, loss=1.83, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=1.58, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.94it/s, loss=1.46, accuracy=0.6, token_accuracy=0.6]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.93it/s, loss=1.33, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=1.07, accuracy=0.67, token_accuracy=0.67]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.94it/s, loss=0.87, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [01:08&lt;00:00,  8.57s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=2.58, accuracy=0.8, token_accuracy=0.8]
Epoch: 1: 100%|██████████| 25/25 [00:09&lt;00:00,  2.75it/s, loss=1.94, accuracy=0.67, token_accuracy=0.67]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.94it/s, loss=1.76, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.93it/s, loss=1.25, accuracy=0.73, token_accuracy=0.73]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.93it/s, loss=1.07, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=0.85, accuracy=0.73, token_accuracy=0.73]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.95it/s, loss=0.65, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.94it/s, loss=0.57, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [01:08&lt;00:00,  8.58s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.95it/s, loss=3.66, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.87it/s, loss=3.52, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=3.51, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=3.46, accuracy=0.27, token_accuracy=0.27]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=3.44, accuracy=0.07, token_accuracy=0.07]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=3.45, accuracy=0.27, token_accuracy=0.27]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=3.41, accuracy=0.2, token_accuracy=0.2]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.95it/s, loss=3.37, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [01:08&lt;00:00,  8.57s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=2.77, accuracy=0.53, token_accuracy=0.53]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=2, accuracy=0.67, token_accuracy=0.67]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.95it/s, loss=1.52, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=0.86, accuracy=0.93, token_accuracy=0.93]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=0.71, accuracy=0.73, token_accuracy=0.73]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=0.61, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=0.59, accuracy=0.93, token_accuracy=0.93]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.86it/s, loss=0.5, accuracy=0.73, token_accuracy=0.73]
Epoch: 100%|██████████| 8/8 [01:08&lt;00:00,  8.52s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.99it/s, loss=2.44, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=1.36, accuracy=0.87, token_accuracy=0.87]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=0.75, accuracy=1, token_accuracy=1]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.94it/s, loss=0.76, accuracy=1, token_accuracy=1]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=0.71, accuracy=0.73, token_accuracy=0.73]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=0.53, accuracy=0.8, token_accuracy=0.8]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.95it/s, loss=0.39, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=0.31, accuracy=1, token_accuracy=1]
Epoch: 100%|██████████| 8/8 [01:07&lt;00:00,  8.47s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=3.62, accuracy=0.2, token_accuracy=0.2]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.99it/s, loss=3.45, accuracy=0.13, token_accuracy=0.13]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=3.46, accuracy=0.47, token_accuracy=0.47]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.94it/s, loss=3.39, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.95it/s, loss=3.35, accuracy=0.4, token_accuracy=0.4]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=3.36, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=3.29, accuracy=0, token_accuracy=0]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=3.24, accuracy=0.33, token_accuracy=0.33]
Epoch: 100%|██████████| 8/8 [01:07&lt;00:00,  8.47s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=2.54, accuracy=0.73, token_accuracy=0.73]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.99it/s, loss=1.92, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=1.15, accuracy=0.87, token_accuracy=0.87]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.99it/s, loss=1.03, accuracy=0.8, token_accuracy=0.8]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.99it/s, loss=0.74, accuracy=0.87, token_accuracy=0.87]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=0.61, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=0.78, accuracy=0.67, token_accuracy=0.67]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=0.94, accuracy=0.87, token_accuracy=0.87]
Epoch: 100%|██████████| 8/8 [01:06&lt;00:00,  8.36s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=1.99, accuracy=0.53, token_accuracy=0.53]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=1.32, accuracy=0.8, token_accuracy=0.8]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=1.01, accuracy=0.8, token_accuracy=0.8]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=0.77, accuracy=0.93, token_accuracy=0.93]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=0.53, accuracy=0.8, token_accuracy=0.8]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=0.51, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.91it/s, loss=0.55, accuracy=0.93, token_accuracy=0.93]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=0.41, accuracy=0.93, token_accuracy=0.93]
Epoch: 100%|██████████| 8/8 [01:07&lt;00:00,  8.48s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=3.59, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=3.42, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=3.38, accuracy=0.27, token_accuracy=0.27]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.99it/s, loss=3.34, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=3.28, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=3.25, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=3.25, accuracy=0.27, token_accuracy=0.27]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=3.18, accuracy=0.47, token_accuracy=0.47]
Epoch: 100%|██████████| 8/8 [01:07&lt;00:00,  8.39s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=2.14, accuracy=0.8, token_accuracy=0.8]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=1.27, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.02it/s, loss=0.79, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=0.71, accuracy=0.87, token_accuracy=0.87]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.99it/s, loss=0.54, accuracy=1, token_accuracy=1]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=0.36, accuracy=0.8, token_accuracy=0.8]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.02it/s, loss=0.35, accuracy=1, token_accuracy=1]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=0.28, accuracy=0.87, token_accuracy=0.87]
Epoch: 100%|██████████| 8/8 [01:06&lt;00:00,  8.31s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=2.02, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=1.09, accuracy=0.67, token_accuracy=0.67]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=0.8, accuracy=0.87, token_accuracy=0.87]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=0.56, accuracy=0.6, token_accuracy=0.6]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=0.76, accuracy=0.8, token_accuracy=0.8]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=0.46, accuracy=0.8, token_accuracy=0.8]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.02it/s, loss=0.43, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=0.58, accuracy=0.8, token_accuracy=0.8]
Epoch: 100%|██████████| 8/8 [01:06&lt;00:00,  8.28s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=3.55, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.99it/s, loss=3.44, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=3.27, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.02it/s, loss=3.2, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=3.15, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.02it/s, loss=3.14, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=3.05, accuracy=0.67, token_accuracy=0.67]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  2.92it/s, loss=3.06, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [01:06&lt;00:00,  8.34s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=1.81, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=0.62, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.05it/s, loss=0.53, accuracy=0.87, token_accuracy=0.87]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.04it/s, loss=0.49, accuracy=0.87, token_accuracy=0.87]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.05it/s, loss=0.33, accuracy=1, token_accuracy=1]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=0.21, accuracy=0.93, token_accuracy=0.93]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=0.22, accuracy=0.8, token_accuracy=0.8]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=0.19, accuracy=1, token_accuracy=1]
Epoch: 100%|██████████| 8/8 [01:06&lt;00:00,  8.26s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  2.96it/s, loss=2.12, accuracy=0.53, token_accuracy=0.53]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.08it/s, loss=1.08, accuracy=0.93, token_accuracy=0.93]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=0.74, accuracy=0.8, token_accuracy=0.8]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=0.57, accuracy=0.87, token_accuracy=0.87]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.05it/s, loss=0.53, accuracy=0.93, token_accuracy=0.93]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=0.35, accuracy=1, token_accuracy=1]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  2.94it/s, loss=0.42, accuracy=0.93, token_accuracy=0.93]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.04it/s, loss=0.42, accuracy=0.87, token_accuracy=0.87]
Epoch: 100%|██████████| 8/8 [01:06&lt;00:00,  8.30s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=3.48, accuracy=0.73, token_accuracy=0.73]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.98it/s, loss=3.17, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.04it/s, loss=3.03, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=2.96, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.89it/s, loss=2.97, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.05it/s, loss=2.8, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.02it/s, loss=2.75, accuracy=0.27, token_accuracy=0.27]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=2.71, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [01:06&lt;00:00,  8.30s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=1.68, accuracy=0.87, token_accuracy=0.87]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=0.55, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=0.37, accuracy=0.93, token_accuracy=0.93]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.07it/s, loss=0.28, accuracy=1, token_accuracy=1]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.07it/s, loss=0.2, accuracy=0.93, token_accuracy=0.93]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.08it/s, loss=0.14, accuracy=1, token_accuracy=1]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.08it/s, loss=0.05, accuracy=1, token_accuracy=1]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=0.04, accuracy=1, token_accuracy=1]
Epoch: 100%|██████████| 8/8 [01:05&lt;00:00,  8.16s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=2.12, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.07it/s, loss=1.09, accuracy=0.87, token_accuracy=0.87]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=0.75, accuracy=1, token_accuracy=1]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.04it/s, loss=0.51, accuracy=0.8, token_accuracy=0.8]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.95it/s, loss=0.51, accuracy=0.87, token_accuracy=0.87]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=0.42, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.07it/s, loss=0.27, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.02it/s, loss=0.29, accuracy=0.93, token_accuracy=0.93]
Epoch: 100%|██████████| 8/8 [01:05&lt;00:00,  8.22s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.08it/s, loss=3.37, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.07it/s, loss=2.99, accuracy=0.27, token_accuracy=0.27]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.00it/s, loss=2.89, accuracy=0.47, token_accuracy=0.47]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.05it/s, loss=2.73, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.05it/s, loss=2.69, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=2.59, accuracy=0.33, token_accuracy=0.33]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=2.48, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.07it/s, loss=2.53, accuracy=0.13, token_accuracy=0.13]
Epoch: 100%|██████████| 8/8 [01:05&lt;00:00,  8.20s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.08it/s, loss=1.63, accuracy=0.87, token_accuracy=0.87]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=0.47, accuracy=0.93, token_accuracy=0.93]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.08it/s, loss=0.3, accuracy=0.87, token_accuracy=0.87]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.11it/s, loss=0.16, accuracy=1, token_accuracy=1]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  2.97it/s, loss=0.21, accuracy=0.8, token_accuracy=0.8]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=0.27, accuracy=0.93, token_accuracy=0.93]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=0.25, accuracy=0.93, token_accuracy=0.93]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=0.1, accuracy=1, token_accuracy=1]
Epoch: 100%|██████████| 8/8 [01:05&lt;00:00,  8.16s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=2.08, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=1.24, accuracy=0.93, token_accuracy=0.93]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=0.91, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=0.65, accuracy=0.8, token_accuracy=0.8]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=0.8, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=0.46, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.05it/s, loss=0.46, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.11it/s, loss=0.45, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [01:04&lt;00:00,  8.08s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.11it/s, loss=3.19, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=2.9, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=2.81, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.11it/s, loss=2.67, accuracy=0.2, token_accuracy=0.2]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=2.49, accuracy=0.6, token_accuracy=0.6]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=2.6, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=2.53, accuracy=0.6, token_accuracy=0.6]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=2.41, accuracy=0.33, token_accuracy=0.33]
Epoch: 100%|██████████| 8/8 [01:04&lt;00:00,  8.07s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.06it/s, loss=1.97, accuracy=0.73, token_accuracy=0.73]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=0.9, accuracy=0.8, token_accuracy=0.8]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.15it/s, loss=1.01, accuracy=0.87, token_accuracy=0.87]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.14it/s, loss=0.53, accuracy=0.87, token_accuracy=0.87]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=0.42, accuracy=0.93, token_accuracy=0.93]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=0.3, accuracy=1, token_accuracy=1]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.12it/s, loss=0.35, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=0.41, accuracy=0.93, token_accuracy=0.93]
Epoch: 100%|██████████| 8/8 [01:04&lt;00:00,  8.04s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.14it/s, loss=2.32, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=1.5, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.07it/s, loss=1.16, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.12it/s, loss=1.07, accuracy=0.73, token_accuracy=0.73]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.11it/s, loss=0.9, accuracy=0.8, token_accuracy=0.8]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.12it/s, loss=0.81, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=0.82, accuracy=0.73, token_accuracy=0.73]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=0.83, accuracy=0.8, token_accuracy=0.8]
Epoch: 100%|██████████| 8/8 [01:04&lt;00:00,  8.07s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.16it/s, loss=3.23, accuracy=0.13, token_accuracy=0.13]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  2.88it/s, loss=2.76, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=2.56, accuracy=0.27, token_accuracy=0.27]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.11it/s, loss=2.61, accuracy=0.27, token_accuracy=0.27]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.12it/s, loss=2.51, accuracy=0.4, token_accuracy=0.4]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.12it/s, loss=2.32, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=2.27, accuracy=0.27, token_accuracy=0.27]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.12it/s, loss=2.19, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [01:04&lt;00:00,  8.08s/it]
Epoch: 0: 100%|██████████| 25/25 [00:08&lt;00:00,  3.05it/s, loss=1.86, accuracy=0.87, token_accuracy=0.87]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.15it/s, loss=0.56, accuracy=0.93, token_accuracy=0.93]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.16it/s, loss=0.38, accuracy=0.87, token_accuracy=0.87]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=0.29, accuracy=0.93, token_accuracy=0.93]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=0.17, accuracy=0.93, token_accuracy=0.93]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.17it/s, loss=0.21, accuracy=1, token_accuracy=1]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=0.27, accuracy=1, token_accuracy=1]
Epoch: 7: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=0.28, accuracy=0.87, token_accuracy=0.87]
Epoch: 100%|██████████| 8/8 [01:03&lt;00:00,  7.98s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=2.04, accuracy=0.73, token_accuracy=0.73]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.17it/s, loss=0.96, accuracy=0.8, token_accuracy=0.8]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.16it/s, loss=0.78, accuracy=0.6, token_accuracy=0.6]
Epoch: 3: 100%|██████████| 25/25 [00:08&lt;00:00,  3.09it/s, loss=0.58, accuracy=0.67, token_accuracy=0.67]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=0.77, accuracy=0.73, token_accuracy=0.73]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.15it/s, loss=0.6, accuracy=0.93, token_accuracy=0.93]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=0.5, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.14it/s, loss=0.4, accuracy=0.87, token_accuracy=0.87]
Epoch: 100%|██████████| 8/8 [01:03&lt;00:00,  7.94s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.16it/s, loss=2.98, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.17it/s, loss=2.45, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:08&lt;00:00,  3.01it/s, loss=2.34, accuracy=0.47, token_accuracy=0.47]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.21it/s, loss=2.34, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=2.21, accuracy=0.8, token_accuracy=0.8]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.17it/s, loss=2.11, accuracy=0.2, token_accuracy=0.2]
Epoch: 6: 100%|██████████| 25/25 [00:08&lt;00:00,  3.03it/s, loss=2.01, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.15it/s, loss=1.97, accuracy=0.27, token_accuracy=0.27]
Epoch: 100%|██████████| 8/8 [01:03&lt;00:00,  7.98s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.23it/s, loss=2.04, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=1.09, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.21it/s, loss=0.69, accuracy=0.8, token_accuracy=0.8]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.19it/s, loss=0.56, accuracy=0.93, token_accuracy=0.93]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.20it/s, loss=0.62, accuracy=0.93, token_accuracy=0.93]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.12it/s, loss=0.43, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.20it/s, loss=0.32, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.19it/s, loss=0.25, accuracy=1, token_accuracy=1]
Epoch: 100%|██████████| 8/8 [01:02&lt;00:00,  7.86s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.22it/s, loss=2.35, accuracy=0.8, token_accuracy=0.8]
Epoch: 1: 100%|██████████| 25/25 [00:08&lt;00:00,  3.08it/s, loss=1.25, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.19it/s, loss=1.07, accuracy=0.6, token_accuracy=0.6]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.21it/s, loss=0.82, accuracy=0.8, token_accuracy=0.8]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=0.57, accuracy=0.87, token_accuracy=0.87]
Epoch: 5: 100%|██████████| 25/25 [00:08&lt;00:00,  3.10it/s, loss=0.52, accuracy=0.93, token_accuracy=0.93]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.17it/s, loss=0.39, accuracy=0.67, token_accuracy=0.67]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.20it/s, loss=0.49, accuracy=0.8, token_accuracy=0.8]
Epoch: 100%|██████████| 8/8 [01:03&lt;00:00,  7.89s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.20it/s, loss=2.51, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=2.06, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.20it/s, loss=1.68, accuracy=0.6, token_accuracy=0.6]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=1.55, accuracy=0.6, token_accuracy=0.6]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=1.7, accuracy=0.6, token_accuracy=0.6]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=1.45, accuracy=0.6, token_accuracy=0.6]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.17it/s, loss=1.34, accuracy=0.4, token_accuracy=0.4]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.17it/s, loss=1.27, accuracy=0.27, token_accuracy=0.27]
Epoch: 100%|██████████| 8/8 [01:02&lt;00:00,  7.86s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.15it/s, loss=2.24, accuracy=0.8, token_accuracy=0.8]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.24it/s, loss=1.6, accuracy=0.67, token_accuracy=0.67]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.22it/s, loss=1.28, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.21it/s, loss=1.01, accuracy=0.73, token_accuracy=0.73]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.19it/s, loss=0.64, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.24it/s, loss=0.52, accuracy=0.73, token_accuracy=0.73]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.24it/s, loss=0.42, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.22it/s, loss=0.39, accuracy=0.93, token_accuracy=0.93]
Epoch: 100%|██████████| 8/8 [01:02&lt;00:00,  7.79s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=2.18, accuracy=0.73, token_accuracy=0.73]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.23it/s, loss=1.38, accuracy=0.67, token_accuracy=0.67]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.20it/s, loss=1.2, accuracy=0.87, token_accuracy=0.87]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.22it/s, loss=0.99, accuracy=0.67, token_accuracy=0.67]
Epoch: 4: 100%|██████████| 25/25 [00:08&lt;00:00,  3.12it/s, loss=0.86, accuracy=0.8, token_accuracy=0.8]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.21it/s, loss=0.64, accuracy=0.8, token_accuracy=0.8]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.23it/s, loss=0.65, accuracy=0.73, token_accuracy=0.73]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.24it/s, loss=0.54, accuracy=0.93, token_accuracy=0.93]
Epoch: 100%|██████████| 8/8 [01:02&lt;00:00,  7.81s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=1.64, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.23it/s, loss=0.97, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.23it/s, loss=0.63, accuracy=0.8, token_accuracy=0.8]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.24it/s, loss=0.5, accuracy=0.8, token_accuracy=0.8]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.13it/s, loss=0.36, accuracy=0.87, token_accuracy=0.87]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.19it/s, loss=0.3, accuracy=0.93, token_accuracy=0.93]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.25it/s, loss=0.28, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.25it/s, loss=0.3, accuracy=0.8, token_accuracy=0.8]
Epoch: 100%|██████████| 8/8 [01:02&lt;00:00,  7.80s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.19it/s, loss=2.31, accuracy=0.53, token_accuracy=0.53]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=1.83, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=1.58, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.27it/s, loss=1.68, accuracy=0.67, token_accuracy=0.67]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=1.32, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.15it/s, loss=1.22, accuracy=0.8, token_accuracy=0.8]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=0.96, accuracy=0.6, token_accuracy=0.6]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=1.09, accuracy=0.8, token_accuracy=0.8]
Epoch: 100%|██████████| 8/8 [01:01&lt;00:00,  7.72s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.29it/s, loss=2.52, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.20it/s, loss=1.64, accuracy=0.67, token_accuracy=0.67]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.24it/s, loss=1.43, accuracy=0.8, token_accuracy=0.8]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.27it/s, loss=1.36, accuracy=0.8, token_accuracy=0.8]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.27it/s, loss=1.07, accuracy=1, token_accuracy=1]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.18it/s, loss=1.02, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=1.01, accuracy=0.93, token_accuracy=0.93]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.27it/s, loss=0.9, accuracy=0.73, token_accuracy=0.73]
Epoch: 100%|██████████| 8/8 [01:01&lt;00:00,  7.70s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.30it/s, loss=1.48, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.16it/s, loss=0.87, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=0.72, accuracy=0.93, token_accuracy=0.93]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.28it/s, loss=0.71, accuracy=0.73, token_accuracy=0.73]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=0.71, accuracy=0.6, token_accuracy=0.6]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=0.61, accuracy=0.67, token_accuracy=0.67]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.15it/s, loss=0.51, accuracy=0.73, token_accuracy=0.73]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=0.53, accuracy=0.8, token_accuracy=0.8]
Epoch: 100%|██████████| 8/8 [01:01&lt;00:00,  7.72s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=2.57, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.30it/s, loss=2.04, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.20it/s, loss=1.97, accuracy=0.67, token_accuracy=0.67]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.28it/s, loss=1.8, accuracy=0.6, token_accuracy=0.6]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.29it/s, loss=1.68, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.30it/s, loss=1.66, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.31it/s, loss=1.7, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=1.65, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [01:00&lt;00:00,  7.62s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.31it/s, loss=2.59, accuracy=0.53, token_accuracy=0.53]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.29it/s, loss=1.6, accuracy=0.67, token_accuracy=0.67]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.29it/s, loss=1.44, accuracy=0.8, token_accuracy=0.8]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.19it/s, loss=1.32, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.30it/s, loss=1.17, accuracy=0.73, token_accuracy=0.73]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.28it/s, loss=1.15, accuracy=0.6, token_accuracy=0.6]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.27it/s, loss=1.02, accuracy=0.73, token_accuracy=0.73]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.29it/s, loss=0.98, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [01:01&lt;00:00,  7.63s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.32it/s, loss=1.5, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.30it/s, loss=1.05, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.30it/s, loss=0.87, accuracy=0.67, token_accuracy=0.67]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.31it/s, loss=0.75, accuracy=0.8, token_accuracy=0.8]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.26it/s, loss=0.63, accuracy=0.8, token_accuracy=0.8]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.31it/s, loss=0.55, accuracy=0.87, token_accuracy=0.87]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.28it/s, loss=0.58, accuracy=0.87, token_accuracy=0.87]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.27it/s, loss=0.55, accuracy=0.8, token_accuracy=0.8]
Epoch: 100%|██████████| 8/8 [01:00&lt;00:00,  7.59s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.19it/s, loss=2.96, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.35it/s, loss=2.28, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=2.15, accuracy=0.6, token_accuracy=0.6]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=2.05, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=2.01, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.21it/s, loss=2.01, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.32it/s, loss=1.93, accuracy=0.4, token_accuracy=0.4]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.34it/s, loss=1.9, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [01:00&lt;00:00,  7.58s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.36it/s, loss=2.79, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.31it/s, loss=2.25, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.23it/s, loss=2.07, accuracy=0.67, token_accuracy=0.67]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.34it/s, loss=2.02, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.35it/s, loss=1.77, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.31it/s, loss=1.43, accuracy=0.73, token_accuracy=0.73]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.31it/s, loss=1.32, accuracy=0.73, token_accuracy=0.73]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.21it/s, loss=1.26, accuracy=0.73, token_accuracy=0.73]
Epoch: 100%|██████████| 8/8 [01:00&lt;00:00,  7.58s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.36it/s, loss=1.95, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.32it/s, loss=1.29, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=1.1, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.21it/s, loss=1.04, accuracy=0.67, token_accuracy=0.67]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=0.94, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=0.83, accuracy=0.6, token_accuracy=0.6]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.32it/s, loss=0.87, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.34it/s, loss=0.85, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [01:00&lt;00:00,  7.54s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.24it/s, loss=2.79, accuracy=0.53, token_accuracy=0.53]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=2.31, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.38it/s, loss=2.11, accuracy=0.2, token_accuracy=0.2]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.35it/s, loss=2.06, accuracy=0.73, token_accuracy=0.73]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=2.05, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.23it/s, loss=2.04, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.35it/s, loss=1.96, accuracy=0.67, token_accuracy=0.67]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.35it/s, loss=1.87, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [01:00&lt;00:00,  7.51s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=2.83, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=2.18, accuracy=0.53, token_accuracy=0.53]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.23it/s, loss=1.81, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.36it/s, loss=1.48, accuracy=0.73, token_accuracy=0.73]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=1.43, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.35it/s, loss=1.34, accuracy=0.73, token_accuracy=0.73]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.34it/s, loss=1.18, accuracy=0.6, token_accuracy=0.6]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.14it/s, loss=1.15, accuracy=0.8, token_accuracy=0.8]
Epoch: 100%|██████████| 8/8 [01:00&lt;00:00,  7.55s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.38it/s, loss=1.7, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.39it/s, loss=1.4, accuracy=0.73, token_accuracy=0.73]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.40it/s, loss=1.21, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.29it/s, loss=1.14, accuracy=0.27, token_accuracy=0.27]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.32it/s, loss=1.07, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.38it/s, loss=1.02, accuracy=0.67, token_accuracy=0.67]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.38it/s, loss=0.99, accuracy=0.6, token_accuracy=0.6]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=0.95, accuracy=0.87, token_accuracy=0.87]
Epoch: 100%|██████████| 8/8 [00:59&lt;00:00,  7.44s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.39it/s, loss=3.07, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.38it/s, loss=2.51, accuracy=0.2, token_accuracy=0.2]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.40it/s, loss=2.35, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.41it/s, loss=2.22, accuracy=0.27, token_accuracy=0.27]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.40it/s, loss=2.16, accuracy=0.4, token_accuracy=0.4]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.39it/s, loss=2.15, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.39it/s, loss=2.1, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.36it/s, loss=1.95, accuracy=0.47, token_accuracy=0.47]
Epoch: 100%|██████████| 8/8 [00:59&lt;00:00,  7.38s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=2.69, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.40it/s, loss=2.26, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=2.2, accuracy=0.47, token_accuracy=0.47]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=2.12, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.31it/s, loss=2.04, accuracy=0.4, token_accuracy=0.4]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.41it/s, loss=1.95, accuracy=0.73, token_accuracy=0.73]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.40it/s, loss=1.95, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.38it/s, loss=1.85, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [00:59&lt;00:00,  7.38s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.41it/s, loss=1.84, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.36it/s, loss=1.42, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=1.24, accuracy=0.47, token_accuracy=0.47]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.40it/s, loss=1.16, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=1.05, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.40it/s, loss=0.99, accuracy=0.6, token_accuracy=0.6]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.40it/s, loss=0.96, accuracy=0.6, token_accuracy=0.6]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=0.91, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [00:59&lt;00:00,  7.39s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=3.39, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.44it/s, loss=3.02, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.43it/s, loss=2.95, accuracy=0.27, token_accuracy=0.27]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.44it/s, loss=2.73, accuracy=0.13, token_accuracy=0.13]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.45it/s, loss=2.65, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=2.59, accuracy=0.27, token_accuracy=0.27]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=2.52, accuracy=0.67, token_accuracy=0.67]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.43it/s, loss=2.48, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [00:58&lt;00:00,  7.29s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.45it/s, loss=2.91, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=2.55, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.33it/s, loss=2.41, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.43it/s, loss=2.46, accuracy=0.6, token_accuracy=0.6]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=2.33, accuracy=0.73, token_accuracy=0.73]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.46it/s, loss=2.06, accuracy=0.33, token_accuracy=0.33]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.04, accuracy=0.8, token_accuracy=0.8]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=1.99, accuracy=0.47, token_accuracy=0.47]
Epoch: 100%|██████████| 8/8 [00:58&lt;00:00,  7.31s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.27it/s, loss=2.05, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=1.51, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.42it/s, loss=1.34, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.46it/s, loss=1.27, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.43it/s, loss=1.17, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.44it/s, loss=1.14, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.43it/s, loss=1.12, accuracy=0.4, token_accuracy=0.4]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.43it/s, loss=1.01, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [00:58&lt;00:00,  7.33s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.48it/s, loss=3.37, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.92, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.49it/s, loss=2.73, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.45it/s, loss=2.71, accuracy=0.2, token_accuracy=0.2]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.45it/s, loss=2.63, accuracy=0.33, token_accuracy=0.33]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.49it/s, loss=2.6, accuracy=0.13, token_accuracy=0.13]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.46it/s, loss=2.56, accuracy=0.2, token_accuracy=0.2]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.48it/s, loss=2.48, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [00:57&lt;00:00,  7.21s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.52it/s, loss=3.27, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.49it/s, loss=2.69, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=2.37, accuracy=0.2, token_accuracy=0.2]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.32, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.48it/s, loss=2.28, accuracy=0.33, token_accuracy=0.33]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.46it/s, loss=2.22, accuracy=0.33, token_accuracy=0.33]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.15, accuracy=0.6, token_accuracy=0.6]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.11, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [00:57&lt;00:00,  7.22s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.52it/s, loss=2.23, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.37it/s, loss=1.61, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.48it/s, loss=1.39, accuracy=0.6, token_accuracy=0.6]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.48it/s, loss=1.36, accuracy=0.6, token_accuracy=0.6]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.46it/s, loss=1.29, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.48it/s, loss=1.26, accuracy=0.67, token_accuracy=0.67]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.49it/s, loss=1.22, accuracy=0.8, token_accuracy=0.8]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.34it/s, loss=1.17, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [00:57&lt;00:00,  7.25s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.53it/s, loss=3.49, accuracy=0.13, token_accuracy=0.13]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.51it/s, loss=3.05, accuracy=0.53, token_accuracy=0.53]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.51it/s, loss=2.98, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.51it/s, loss=2.83, accuracy=0.27, token_accuracy=0.27]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.53it/s, loss=2.76, accuracy=0.4, token_accuracy=0.4]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.53it/s, loss=2.76, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.45it/s, loss=2.72, accuracy=0.07, token_accuracy=0.07]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.50it/s, loss=2.64, accuracy=0.33, token_accuracy=0.33]
Epoch: 100%|██████████| 8/8 [00:57&lt;00:00,  7.13s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.56it/s, loss=3.17, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.53it/s, loss=2.7, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.52it/s, loss=2.52, accuracy=0.27, token_accuracy=0.27]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.53it/s, loss=2.39, accuracy=0.53, token_accuracy=0.53]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.51it/s, loss=2.26, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.13, accuracy=0.27, token_accuracy=0.27]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.49it/s, loss=2.11, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.51it/s, loss=2.09, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:56&lt;00:00,  7.11s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.55it/s, loss=2.29, accuracy=0.13, token_accuracy=0.13]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.52it/s, loss=1.83, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.52it/s, loss=1.6, accuracy=0.73, token_accuracy=0.73]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.54it/s, loss=1.49, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=1.56, accuracy=0.4, token_accuracy=0.4]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.52it/s, loss=1.39, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.51it/s, loss=1.39, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.53it/s, loss=1.31, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [00:56&lt;00:00,  7.10s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.59it/s, loss=3.34, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.57it/s, loss=2.99, accuracy=0.27, token_accuracy=0.27]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.55it/s, loss=2.86, accuracy=0.27, token_accuracy=0.27]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.78, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.55it/s, loss=2.75, accuracy=0.6, token_accuracy=0.6]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.54it/s, loss=2.72, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.56it/s, loss=2.68, accuracy=0.27, token_accuracy=0.27]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.57it/s, loss=2.63, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [00:56&lt;00:00,  7.05s/it]
Epoch: 0: 100%|██████████| 25/25 [00:07&lt;00:00,  3.56it/s, loss=3.3, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.54it/s, loss=2.7, accuracy=0.53, token_accuracy=0.53]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.56it/s, loss=2.64, accuracy=0.6, token_accuracy=0.6]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.55it/s, loss=2.49, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.53it/s, loss=2.35, accuracy=0.73, token_accuracy=0.73]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.57it/s, loss=2.67, accuracy=0.53, token_accuracy=0.53]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.55it/s, loss=2.45, accuracy=0.73, token_accuracy=0.73]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.54it/s, loss=2.27, accuracy=0.73, token_accuracy=0.73]
Epoch: 100%|██████████| 8/8 [00:56&lt;00:00,  7.05s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.59it/s, loss=2.55, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.56it/s, loss=2.1, accuracy=0.8, token_accuracy=0.8]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.55it/s, loss=1.92, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.44it/s, loss=1.91, accuracy=0.27, token_accuracy=0.27]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.57it/s, loss=1.8, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.54it/s, loss=1.71, accuracy=0.73, token_accuracy=0.73]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.57it/s, loss=1.6, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.57it/s, loss=1.53, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:56&lt;00:00,  7.05s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.63it/s, loss=3.38, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.60it/s, loss=3.07, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:07&lt;00:00,  3.52it/s, loss=2.93, accuracy=0.27, token_accuracy=0.27]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.43it/s, loss=2.86, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.59it/s, loss=2.79, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.59it/s, loss=2.74, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.60it/s, loss=2.71, accuracy=0.2, token_accuracy=0.2]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.61it/s, loss=2.63, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [00:56&lt;00:00,  7.01s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.61it/s, loss=3.16, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.62it/s, loss=2.78, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.61it/s, loss=2.64, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.57it/s, loss=2.49, accuracy=0.53, token_accuracy=0.53]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.63it/s, loss=2.34, accuracy=0.73, token_accuracy=0.73]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.63it/s, loss=2.19, accuracy=0.6, token_accuracy=0.6]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.56it/s, loss=2.13, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.62it/s, loss=2.05, accuracy=0.33, token_accuracy=0.33]
Epoch: 100%|██████████| 8/8 [00:55&lt;00:00,  6.93s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.62it/s, loss=2.98, accuracy=0.6, token_accuracy=0.6]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.60it/s, loss=2.59, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.62it/s, loss=2.37, accuracy=0.67, token_accuracy=0.67]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.59it/s, loss=2.27, accuracy=0.07, token_accuracy=0.07]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.25, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.57it/s, loss=2.12, accuracy=0.33, token_accuracy=0.33]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.60it/s, loss=2.03, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.57it/s, loss=1.93, accuracy=0.47, token_accuracy=0.47]
Epoch: 100%|██████████| 8/8 [00:55&lt;00:00,  6.98s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.64it/s, loss=3.27, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.63it/s, loss=2.97, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.66it/s, loss=2.82, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.65it/s, loss=2.73, accuracy=0.67, token_accuracy=0.67]
Epoch: 4: 100%|██████████| 25/25 [00:07&lt;00:00,  3.55it/s, loss=2.67, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.44it/s, loss=2.67, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.63it/s, loss=2.55, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.63it/s, loss=2.55, accuracy=0.33, token_accuracy=0.33]
Epoch: 100%|██████████| 8/8 [00:55&lt;00:00,  6.94s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.66it/s, loss=3.06, accuracy=0.8, token_accuracy=0.8]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.65it/s, loss=2.78, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.62it/s, loss=2.44, accuracy=0.6, token_accuracy=0.6]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.63it/s, loss=2.28, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.63it/s, loss=2.14, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:07&lt;00:00,  3.57it/s, loss=2.04, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:07&lt;00:00,  3.43it/s, loss=1.96, accuracy=0.6, token_accuracy=0.6]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.66it/s, loss=1.93, accuracy=0.27, token_accuracy=0.27]
Epoch: 100%|██████████| 8/8 [00:55&lt;00:00,  6.94s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.68it/s, loss=3.06, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.67it/s, loss=2.64, accuracy=0.2, token_accuracy=0.2]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.61it/s, loss=2.37, accuracy=0.2, token_accuracy=0.2]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.67it/s, loss=2.32, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.64it/s, loss=2.15, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.64it/s, loss=2.1, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.61it/s, loss=2.06, accuracy=0.33, token_accuracy=0.33]
Epoch: 7: 100%|██████████| 25/25 [00:07&lt;00:00,  3.47it/s, loss=2.04, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:55&lt;00:00,  6.90s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.73it/s, loss=3.5, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.71it/s, loss=2.96, accuracy=0.2, token_accuracy=0.2]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.70it/s, loss=2.82, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.67it/s, loss=2.72, accuracy=0.53, token_accuracy=0.53]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.70it/s, loss=2.67, accuracy=0.33, token_accuracy=0.33]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.69it/s, loss=2.61, accuracy=0.27, token_accuracy=0.27]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.68it/s, loss=2.57, accuracy=0.27, token_accuracy=0.27]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.67it/s, loss=2.55, accuracy=0.47, token_accuracy=0.47]
Epoch: 100%|██████████| 8/8 [00:54&lt;00:00,  6.77s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.62it/s, loss=3.21, accuracy=0.2, token_accuracy=0.2]
Epoch: 1: 100%|██████████| 25/25 [00:07&lt;00:00,  3.54it/s, loss=2.46, accuracy=0.27, token_accuracy=0.27]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.70it/s, loss=2.24, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.65it/s, loss=2.14, accuracy=0.53, token_accuracy=0.53]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.69it/s, loss=2.13, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.69it/s, loss=1.94, accuracy=0.33, token_accuracy=0.33]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.67it/s, loss=1.97, accuracy=0.4, token_accuracy=0.4]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.67it/s, loss=1.86, accuracy=0.6, token_accuracy=0.6]
Epoch: 100%|██████████| 8/8 [00:54&lt;00:00,  6.84s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.73it/s, loss=3.02, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.68it/s, loss=2.53, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.68it/s, loss=2.28, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:07&lt;00:00,  3.53it/s, loss=2.27, accuracy=0.67, token_accuracy=0.67]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.60it/s, loss=2.14, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.68it/s, loss=2.22, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.68it/s, loss=2.12, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.68it/s, loss=2.03, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:54&lt;00:00,  6.84s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.75it/s, loss=3.33, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.74it/s, loss=2.91, accuracy=0.53, token_accuracy=0.53]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.73it/s, loss=2.8, accuracy=0.27, token_accuracy=0.27]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.73it/s, loss=2.72, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.72it/s, loss=2.65, accuracy=0.33, token_accuracy=0.33]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.75it/s, loss=2.64, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.72it/s, loss=2.56, accuracy=0.33, token_accuracy=0.33]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.60it/s, loss=2.52, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:53&lt;00:00,  6.73s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.78it/s, loss=3.22, accuracy=0.2, token_accuracy=0.2]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.74it/s, loss=2.87, accuracy=0.2, token_accuracy=0.2]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.73it/s, loss=2.76, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.75it/s, loss=2.69, accuracy=0.53, token_accuracy=0.53]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.75it/s, loss=2.63, accuracy=0.67, token_accuracy=0.67]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.72it/s, loss=2.55, accuracy=0.6, token_accuracy=0.6]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.73it/s, loss=2.5, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.77it/s, loss=2.45, accuracy=0.67, token_accuracy=0.67]
Epoch: 100%|██████████| 8/8 [00:53&lt;00:00,  6.68s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.74it/s, loss=2.95, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.76it/s, loss=2.56, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.72it/s, loss=2.35, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.76it/s, loss=2.26, accuracy=0.27, token_accuracy=0.27]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.60it/s, loss=2.19, accuracy=0.4, token_accuracy=0.4]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.60it/s, loss=2.12, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.71it/s, loss=2.02, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.73it/s, loss=1.92, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:54&lt;00:00,  6.75s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.80it/s, loss=3.41, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.78it/s, loss=3.01, accuracy=0.2, token_accuracy=0.2]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.78it/s, loss=2.75, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.79it/s, loss=2.68, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.79it/s, loss=2.63, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.76it/s, loss=2.6, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.77it/s, loss=2.53, accuracy=0.73, token_accuracy=0.73]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.78it/s, loss=2.52, accuracy=0.47, token_accuracy=0.47]
Epoch: 100%|██████████| 8/8 [00:52&lt;00:00,  6.61s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.76it/s, loss=3.14, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.61it/s, loss=2.54, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.65it/s, loss=2.35, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.78it/s, loss=2.34, accuracy=0.53, token_accuracy=0.53]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.77it/s, loss=2.13, accuracy=0.6, token_accuracy=0.6]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.76it/s, loss=2.25, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.76it/s, loss=2.13, accuracy=0.2, token_accuracy=0.2]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.79it/s, loss=1.96, accuracy=0.27, token_accuracy=0.27]
Epoch: 100%|██████████| 8/8 [00:53&lt;00:00,  6.70s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.79it/s, loss=2.94, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.77it/s, loss=2.48, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.77it/s, loss=2.4, accuracy=0.2, token_accuracy=0.2]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.76it/s, loss=2.29, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.79it/s, loss=2.17, accuracy=0.33, token_accuracy=0.33]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.78it/s, loss=2.06, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.75it/s, loss=2.01, accuracy=0.47, token_accuracy=0.47]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.73it/s, loss=1.97, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:53&lt;00:00,  6.64s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.58it/s, loss=3.34, accuracy=0.47, token_accuracy=0.47]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.82it/s, loss=2.97, accuracy=0.4, token_accuracy=0.4]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.80it/s, loss=2.92, accuracy=0.33, token_accuracy=0.33]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.88, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.85, accuracy=0.33, token_accuracy=0.33]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.83it/s, loss=2.82, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.82it/s, loss=2.73, accuracy=0.4, token_accuracy=0.4]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.80it/s, loss=2.63, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:52&lt;00:00,  6.61s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.83it/s, loss=3.3, accuracy=0.67, token_accuracy=0.67]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.68, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.53, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.48, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.80it/s, loss=2.45, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.82it/s, loss=2.41, accuracy=0.33, token_accuracy=0.33]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.82it/s, loss=2.29, accuracy=0.33, token_accuracy=0.33]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.27, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:52&lt;00:00,  6.56s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.70it/s, loss=2.97, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.53, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.64it/s, loss=2.18, accuracy=0.2, token_accuracy=0.2]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.80it/s, loss=2.07, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.14, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=2.05, accuracy=0.27, token_accuracy=0.27]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.81it/s, loss=1.99, accuracy=0.2, token_accuracy=0.2]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.82it/s, loss=1.92, accuracy=0.47, token_accuracy=0.47]
Epoch: 100%|██████████| 8/8 [00:53&lt;00:00,  6.63s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.91it/s, loss=3.29, accuracy=0.33, token_accuracy=0.33]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.84it/s, loss=3.06, accuracy=0.6, token_accuracy=0.6]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.88it/s, loss=3.05, accuracy=0.13, token_accuracy=0.13]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.89it/s, loss=2.98, accuracy=0.4, token_accuracy=0.4]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.87it/s, loss=2.96, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.90it/s, loss=2.92, accuracy=0.27, token_accuracy=0.27]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.86it/s, loss=2.92, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.85it/s, loss=2.91, accuracy=0.47, token_accuracy=0.47]
Epoch: 100%|██████████| 8/8 [00:51&lt;00:00,  6.46s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.86it/s, loss=3.28, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.87it/s, loss=3.1, accuracy=0.27, token_accuracy=0.27]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.89it/s, loss=3.05, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.85it/s, loss=3.03, accuracy=0.33, token_accuracy=0.33]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.86it/s, loss=2.99, accuracy=0.47, token_accuracy=0.47]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.86it/s, loss=2.94, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.87it/s, loss=2.87, accuracy=0.27, token_accuracy=0.27]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.86it/s, loss=2.56, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [00:51&lt;00:00,  6.47s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.71it/s, loss=3.77, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.87it/s, loss=3.42, accuracy=0.2, token_accuracy=0.2]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.86it/s, loss=3.19, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.86it/s, loss=2.96, accuracy=0.6, token_accuracy=0.6]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.88it/s, loss=2.85, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.88it/s, loss=2.76, accuracy=0.4, token_accuracy=0.4]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.85it/s, loss=2.63, accuracy=0.4, token_accuracy=0.4]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.90it/s, loss=2.61, accuracy=0.4, token_accuracy=0.4]
Epoch: 100%|██████████| 8/8 [00:51&lt;00:00,  6.50s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.94it/s, loss=3.8, accuracy=0.4, token_accuracy=0.4]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.93it/s, loss=3.8, accuracy=0.33, token_accuracy=0.33]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.90it/s, loss=3.79, accuracy=0.53, token_accuracy=0.53]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.93it/s, loss=3.79, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.94it/s, loss=3.8, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.93it/s, loss=3.8, accuracy=0.33, token_accuracy=0.33]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.95it/s, loss=3.79, accuracy=0.33, token_accuracy=0.33]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.89it/s, loss=3.79, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [00:50&lt;00:00,  6.37s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.96it/s, loss=3.8, accuracy=0.13, token_accuracy=0.13]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.91it/s, loss=3.79, accuracy=0.53, token_accuracy=0.53]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.95it/s, loss=3.8, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.90it/s, loss=3.79, accuracy=0.47, token_accuracy=0.47]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.93it/s, loss=3.79, accuracy=0.53, token_accuracy=0.53]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.93it/s, loss=3.79, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.96it/s, loss=3.8, accuracy=0.53, token_accuracy=0.53]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.94it/s, loss=3.79, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [00:50&lt;00:00,  6.36s/it]
Epoch: 0: 100%|██████████| 25/25 [00:06&lt;00:00,  3.95it/s, loss=3.68, accuracy=0.27, token_accuracy=0.27]
Epoch: 1: 100%|██████████| 25/25 [00:06&lt;00:00,  3.92it/s, loss=3.13, accuracy=0.47, token_accuracy=0.47]
Epoch: 2: 100%|██████████| 25/25 [00:06&lt;00:00,  3.93it/s, loss=2.86, accuracy=0.4, token_accuracy=0.4]
Epoch: 3: 100%|██████████| 25/25 [00:06&lt;00:00,  3.91it/s, loss=2.8, accuracy=0.27, token_accuracy=0.27]
Epoch: 4: 100%|██████████| 25/25 [00:06&lt;00:00,  3.91it/s, loss=2.77, accuracy=0.27, token_accuracy=0.27]
Epoch: 5: 100%|██████████| 25/25 [00:06&lt;00:00,  3.91it/s, loss=2.72, accuracy=0.47, token_accuracy=0.47]
Epoch: 6: 100%|██████████| 25/25 [00:06&lt;00:00,  3.92it/s, loss=2.72, accuracy=0.33, token_accuracy=0.33]
Epoch: 7: 100%|██████████| 25/25 [00:06&lt;00:00,  3.93it/s, loss=2.58, accuracy=0.53, token_accuracy=0.53]
Epoch: 100%|██████████| 8/8 [00:51&lt;00:00,  6.38s/it]
/home/atticus/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/atticus/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Heatmaps for &#39;answer_position&#39; variable:&quot;</span><span class="p">)</span>
<span class="n">experiment</span><span class="o">.</span><span class="n">plot_heatmaps</span><span class="p">(</span><span class="n">raw_results</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;answer_position&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Heatmaps for &#39;answer_position&#39; variable:
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_32_1.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_32_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_32_2.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_32_2.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_32_3.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_32_3.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_32_4.png" src="../../../../../../_images/notebooks_tutorials_causal_mediation_analysis_CausalAbstraction_demos_MCQA_tutorial_32_4.png" />
</div>
</div>
</section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">A Causal Model of Simple Multiple Choice Question Answering</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Loading-in-the-language-model">Loading in the language model</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Single-example-causal-tracing">Single example causal tracing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Visualizing-the-results-interchange-interventions-for-a-single-pair-of-inputs">Visualizing the results interchange interventions for a single pair of inputs</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Aggregating-Interchange-Intervention-Experiments">Aggregating Interchange Intervention Experiments</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Constructing-Counterfactual-Examples-to-Localize-the-Answer-Position-Variable">Constructing Counterfactual Examples to Localize the Answer Position Variable</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Filtering-Out-Examples-the-Language-Model-Answers-Incorrectly">Filtering Out Examples the Language Model Answers Incorrectly</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-token-positions-of-interest">Define token positions of interest</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Performing-Interchange-Interventions-on-the-Residual-Stream">Performing Interchange Interventions on the Residual Stream</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Train-Featurizers-with-DAS">Train Featurizers with DAS</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025 NDIF.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
   
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>