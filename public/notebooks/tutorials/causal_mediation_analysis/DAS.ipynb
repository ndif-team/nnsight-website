{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eef0b7f",
   "metadata": {
    "id": "9eef0b7f"
   },
   "source": [
    "# Distributed Alignment Search (DAS): Searching for Linearly Encoded Concepts in Model Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2711bb6",
   "metadata": {
    "id": "a2711bb6"
   },
   "source": [
    "Imagine we want to edit a model to think that Paris is in the country of Brazil, without changing whatever else the model knows about Paris (e.g., its language, continent, ...). Which representations in the model encode this fact about Paris?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715718af",
   "metadata": {
    "id": "715718af"
   },
   "source": [
    "In this tutorial, we'll go over **Distributed Alignment Search**, or <a href=\"https://arxiv.org/abs/2303.02536\">DAS</a>, which helps us automatically identify a set of linear subspaces in a model's representations that encode a particular concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b622e",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "We encourage using \"light mode\" to view this tutorial, since the color blocks are harder to read in \"dark mode\". You can also follow along on [this Colab notebook](https://colab.research.google.com/drive/18rSVAQsy8fEud-iEHRyyhsEF8hoVBgPJ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde356e1",
   "metadata": {
    "id": "fde356e1"
   },
   "source": [
    "<div style=\"background-color:#FF9999;padding:10px 10px;border-radius:20px\">\n",
    "<b>Before we begin!</b>\n",
    "\n",
    "These are good things to know before we begin the tutorial\n",
    "<ul>\n",
    "<li>Activation patching - check out the activation patching tutorial <a href=\"https://nnsight.net/notebooks/tutorials/activation_patching/\">here</a>!</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8719e",
   "metadata": {
    "id": "8da8719e"
   },
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Things we'll talk about</b>\n",
    "\n",
    "In case you want to tell people what you learned today!\n",
    "<ul>\n",
    "<li><a href=\"https://arxiv.org/abs/2303.02536\">DAS</a> - method for finding linear subspaces of model representations that store a particular concept.</li>\n",
    "<li><a href=\"https://arxiv.org/abs/2402.17700\">RAVEL</a> - evaluation framework for localizing concepts in model activations.</li>\n",
    "</ul>\n",
    "\n",
    "Let's do this!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6c581b",
   "metadata": {
    "id": "8f6c581b"
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  is_colab = True\n",
    "except ImportError:\n",
    "  is_colab = False\n",
    "\n",
    "if is_colab:\n",
    "  pio.renderers.default = \"colab\"\n",
    "  !pip install nnsight==0.5.0.dev\n",
    "else:\n",
    "  pio.renderers.default = \"plotly_mimetype+notebook_connected+notebook\"\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ect5F87GaedN",
   "metadata": {
    "id": "ect5F87GaedN"
   },
   "source": [
    "**Note**\n",
    "\n",
    "In this tutorial, we use the Llama-3.2 1B model. Before starting the tutorial, please go to the model's [huggingface page](https://huggingface.co/meta-llama/Llama-3.2-1B) and request permission to use the model. Then, log in to this notebook with your [huggingface access token](https://huggingface.co/docs/hub/en/security-tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29WhFQRUafsb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330,
     "referenced_widgets": [
      "279676108a6b45ddadf4a6f339db525d",
      "84886001cc56464c911e13d7ca3c4079",
      "a214db6a65be41759f003df761cb1695",
      "05ebc2fa7cac45d29b31ce40f1c2c05b",
      "a0465c6d154f4a41a8d8b1c15b5d101f",
      "4c3d869e951b4500ac7c3f91506b13b1",
      "1a551dd797f54d89a55553b8c7e39aae",
      "2e10fdcde4aa45fcadd0e7d3bd0b436e",
      "560e58a2b749410caa129b7931925227",
      "6df04578201e41789af274172bd9d482",
      "abbd26fc7f5d47cdbcd056bc7b9288ba",
      "bdb356ea59a84823a1b3832453063521",
      "76f8e7c2d8ea43cbb27a0c66a3f64e40",
      "ae2a6c8958ee48d09529466257be347f",
      "8f0091d9696e48f2a91dcb4444848c21",
      "95fdd4654d904472977677e170a3cce4",
      "4a54d3800755482cadea63930f1fa9d4"
     ]
    },
    "id": "29WhFQRUafsb",
    "outputId": "dd6b3cd1-f95d-47ef-f9d2-bcd273707634"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279676108a6b45ddadf4a6f339db525d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "JKpDPg97gsDL",
   "metadata": {
    "id": "JKpDPg97gsDL"
   },
   "outputs": [],
   "source": [
    "# (try to) set seeds for reproducibility\n",
    "import random\n",
    "import torch\n",
    "\n",
    "random.seed(12)\n",
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000a395",
   "metadata": {
    "id": "d000a395"
   },
   "source": [
    "## Making surgical edits - residual streams capture too much information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fdea36",
   "metadata": {
    "id": "47fdea36"
   },
   "source": [
    "When we ask a language model questions about the city of Paris, it seems to know the city's country, its continent, and its language. Yet where are these properties of Paris stored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nIrfsRRY7vy",
   "metadata": {
    "id": "0nIrfsRRY7vy"
   },
   "source": [
    "One way to start investigating this is activation patching. When we patch the residual stream of the 8th layer's activation for the Paris token, we change its country from France to Brazil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59534ebb",
   "metadata": {
    "id": "59534ebb"
   },
   "source": [
    "![two forward runs of a model, with an arrow between the residual stream activations of Rio and Paris. After the intervention is applied, the model outputs Brazil](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/patching_visualization.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdce6ad1",
   "metadata": {
    "id": "fdce6ad1"
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "import nnsight\n",
    "from IPython.display import clear_output\n",
    "model = nnsight.LanguageModel(\"meta-llama/Llama-3.2-1B\", device_map=\"auto\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01133425",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01133425",
    "outputId": "839d558a-d7d4-4083-c3fa-caea8413a791"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France (0.65)\n",
      " the (0.05)\n",
      " love (0.01)\n"
     ]
    }
   ],
   "source": [
    "# base run - does our model know where Paris is?\n",
    "import torch\n",
    "\n",
    "base_prompt = \"Paris is in the country of\"\n",
    "\n",
    "# get logits from the model's output\n",
    "with torch.no_grad():\n",
    "  with model.trace(base_prompt) as tracer:\n",
    "    base_logits = model.output.logits[:, -1, :].save()\n",
    "\n",
    "# apply softmax to convert logits to probability distribution over tokens\n",
    "base_probs = torch.softmax(base_logits, dim=-1)\n",
    "\n",
    "top_completions = torch.topk(base_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93aaa92",
   "metadata": {
    "id": "e93aaa92"
   },
   "outputs": [],
   "source": [
    "# source run - collect representations for a city from a different country\n",
    "source_prompt = \"Rio is in the country of\"\n",
    "source_country = model.tokenizer(\" Brazil\")[\"input_ids\"][1] # includes a space\n",
    "\n",
    "source_hidden_states = []\n",
    "with torch.no_grad():\n",
    "  with model.trace(source_prompt) as tracer:\n",
    "    # get hidden states of all layers in the network.\n",
    "    # we index the output at 0 because it's a tuple where the first index is the hidden state.\n",
    "    for layer in model.model.layers:\n",
    "      source_hidden_states.append(layer.output[0].save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49d11d07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49d11d07",
    "outputId": "796d667a-00c6-4855-f5aa-a64666e81e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Brazil (0.61)\n",
      " the (0.05)\n",
      " Portugal (0.01)\n"
     ]
    }
   ],
   "source": [
    "# patched run - by patching at layer 8 over Paris, we change its country from France to Brazil!\n",
    "TOKEN_INDEX = 1\n",
    "LAYER_INDEX = 8\n",
    "\n",
    "with model.trace(base_prompt) as tracer:\n",
    "  # apply the same patch we did before\n",
    "  model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :] = source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "\n",
    "  patched_logits = model.output.logits[:, -1, :].save()\n",
    "\n",
    "patched_probs = torch.softmax(patched_logits, dim=-1)\n",
    "\n",
    "top_completions = torch.topk(patched_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf57e12",
   "metadata": {
    "id": "3bf57e12"
   },
   "source": [
    "However, we **also accidentally edit other facts about Paris**, such as its continent and language!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33978988",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33978988",
    "outputId": "c85887a3-2822-4f61-ac47-ca7fae8f0e00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " South (0.55)\n",
      " America (0.11)\n",
      " North (0.10)\n"
     ]
    }
   ],
   "source": [
    "# by changing Paris's country, we also changed its continent!\n",
    "TOKEN_INDEX = 1\n",
    "LAYER_INDEX = 8\n",
    "\n",
    "new_base_prompt = \"Paris is in the continent of\"\n",
    "\n",
    "with model.trace(new_base_prompt) as tracer:\n",
    "  # apply the same patch we did before\n",
    "  model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :] = \\\n",
    "    source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "\n",
    "  patched_logits = model.output.logits[:, -1, :].save()\n",
    "\n",
    "patched_probs = torch.softmax(patched_logits, dim=-1)\n",
    "\n",
    "top_completions = torch.topk(patched_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38c0eab0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38c0eab0",
    "outputId": "60f9da9e-e67d-456b-aef2-b074d30de062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Portuguese (0.57)\n",
      " Spanish (0.12)\n",
      " English (0.10)\n"
     ]
    }
   ],
   "source": [
    "# as well as its language!\n",
    "new_base_prompt = \"Paris is a city whose main language is\"\n",
    "\n",
    "with model.trace(new_base_prompt) as tracer:\n",
    "  # apply the same patch we did before\n",
    "  model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :] = \\\n",
    "    source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "\n",
    "  patched_logits = model.output.logits[:, -1, :].save()\n",
    "\n",
    "patched_probs = torch.softmax(patched_logits, dim=-1)\n",
    "\n",
    "top_completions = torch.topk(patched_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a930cc4e",
   "metadata": {
    "id": "a930cc4e"
   },
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Takeaway</b>\n",
    "\n",
    "We need to find a way to make our patching **more precise**. One way to do this is to patch a unit of computation that's smaller than the whole residual stream component. There are many reasonable options, such as patching sets of neurons. In this tutorial, we'll look at how we can patch **linear subspaces** of a model's representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vEFz-xB0ZSlq",
   "metadata": {
    "id": "vEFz-xB0ZSlq"
   },
   "source": [
    "<div style=\"background-color:#F2CFEE;padding:10px 10px;border-radius:20px\">\n",
    "<b>Want to know more?</b>\n",
    "\n",
    "This example came from <a href=\"https://arxiv.org/abs/2402.17700\">RAVEL</a>, a benchmark that measures whether interpretability methods can localize specific concepts (e.g., country vs. language) in a model's internal activations. Check out the paper and dataset for a full analysis of current interpretability methods & areas for future work!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49541273",
   "metadata": {
    "id": "49541273"
   },
   "source": [
    "## Choosing the right unit of computation - how do models represent concepts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4b64e",
   "metadata": {
    "id": "f6e4b64e"
   },
   "source": [
    "What are we patching to begin with? Let's take a look at the source activations we collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f58841",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21f58841",
    "outputId": "12248fcc-2a21-43fa-8d7f-0e1e8005119a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0111, -0.0206, -0.2613,  ..., -0.0281, -0.1300,  0.0346]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_activations = source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "source_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ce518c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49ce518c",
    "outputId": "db68c148-f540-49e9-ec45-f538a50c8167"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_activations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f4c7a",
   "metadata": {
    "id": "336f4c7a"
   },
   "source": [
    "Can we break down the residual stream activation into smaller, meaningful units of computation?\n",
    "\n",
    "One idea is to look at single neurons - that is, single indices within the large 2048-dimensional vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34538880",
   "metadata": {
    "id": "34538880"
   },
   "source": [
    "Another idea, motivated by the Linear Representation Hypothesis, is that transformer-based neural networks tend to use **linear subspaces** as units of computation. Thinking about a model's activation as one giant vector, perhaps concepts are each encoded in a separate linear dimension within the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763dcc73",
   "metadata": {
    "id": "763dcc73"
   },
   "source": [
    "![Activation represented as a linear vector, with subspaces encoding concepts such as the country & language of Paris](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/activation_vector.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a347d0e",
   "metadata": {
    "id": "7a347d0e"
   },
   "source": [
    "To patch a set of neurons, we could simply index into the ones we think encode important concepts in the model. However, enumerating all subsets of neurons is computationally infeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd1f5c",
   "metadata": {
    "id": "6cfd1f5c"
   },
   "source": [
    "![patching the first 3 neurons of the activations of Rio and Paris](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/patching_neurons_visualization.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe5a7db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfe5a7db",
    "outputId": "a0b6bb5e-8821-4ee9-8545-da84f1ad868d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France (0.64)\n",
      " the (0.05)\n",
      " love (0.01)\n"
     ]
    }
   ],
   "source": [
    "# change the list of indices to try a set of neurons to patch!\n",
    "NEURON_INDICES = [0, 1, 2, 4]\n",
    "\n",
    "base_prompt = \"Paris is in the country of\"\n",
    "\n",
    "with model.trace(base_prompt) as tracer:\n",
    "  # Apply the patch from the source hidden states to the base hidden states\n",
    "  model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, NEURON_INDICES] = \\\n",
    "    source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, NEURON_INDICES]\n",
    "\n",
    "  patched_logits = model.output.logits[:, -1, :]\n",
    "\n",
    "  patched_probs = torch.softmax(patched_logits, dim=-1).save()\n",
    "\n",
    "top_completions = torch.topk(patched_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec24c4e",
   "metadata": {
    "id": "4ec24c4e"
   },
   "source": [
    "To patch a set of **linear subspaces**, we can follow a similar procedure, with a slight twist...\n",
    "\n",
    "First, we **rotate** our base and source vectors. This creates two new vectors, whose neurons are linear combinations of the original vector. Next, we **patch linear subspaces** just as we would in the regular set-up. Lastly, we **rotate back** the patched vector, so that it's in the same basis as the original run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9fba6",
   "metadata": {
    "id": "04d9fba6"
   },
   "source": [
    "![patch between a source and base vector, where the source & base vector are first rotated. the resulting patch is then un-rotated back to the original basis](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/das_visualization.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3f99b59",
   "metadata": {
    "id": "f3f99b59"
   },
   "outputs": [],
   "source": [
    "# construct a rotation matrix (model_dim x model_dim)\n",
    "MODEL_HIDDEN_DIM = 2048\n",
    "\n",
    "rotator = torch.nn.Linear(MODEL_HIDDEN_DIM, MODEL_HIDDEN_DIM, bias=False)\n",
    "torch.nn.init.orthogonal_(rotator.weight)\n",
    "\n",
    "rotator = torch.nn.utils.parametrizations.orthogonal(rotator).to(model.device)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c077243e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c077243e",
    "outputId": "6ce2a740-d159-4c72-9cb2-ac7d925b9e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France (0.24)\n",
      " the (0.06)\n",
      " Belgium (0.02)\n"
     ]
    }
   ],
   "source": [
    "# play around with how many linear dimensions we patch!\n",
    "N_PATCHING_DIMS = 1\n",
    "\n",
    "base_prompt = \"Paris is in the country of\"\n",
    "\n",
    "def patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=False):\n",
    "  grad_env = torch.enable_grad if with_grad else torch.no_grad\n",
    "  with grad_env():\n",
    "    with model.trace(base_prompt) as tracer:\n",
    "      # rotate the base representation\n",
    "      base = model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :].clone()\n",
    "      rotated_base = rotator(base)\n",
    "\n",
    "      # rotate the source representation\n",
    "      source = source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "      rotated_source = rotator(source)\n",
    "\n",
    "      # patch the first n dimensions in the rotated space\n",
    "      # (NOTE: same thing as `rotated_base[:, 0] = rotated_source[:, 0]` but we want the gradient to flow)\n",
    "      rotated_patch = torch.cat([\n",
    "        rotated_source[:, :N_PATCHING_DIMS],\n",
    "        rotated_base[:, N_PATCHING_DIMS:]\n",
    "      ], dim=1)\n",
    "\n",
    "      # unrotate patched vector back to the original space\n",
    "      patch = torch.matmul(rotated_patch, rotator.weight.T)\n",
    "\n",
    "      # replace base with patch\n",
    "      model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :] = patch\n",
    "\n",
    "      patched_logits = model.output.logits[:, -1, :].save()\n",
    "  return patched_logits\n",
    "\n",
    "patched_logits = patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=False)\n",
    "patched_probs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9322d8ab",
   "metadata": {
    "id": "9322d8ab"
   },
   "source": [
    "<div style=\"background-color:#F2CFEE;padding:10px 10px;border-radius:20px\">\n",
    "<b>Want to know more?</b>\n",
    "\n",
    "You may have suspected this, but there's nothing particularly special about a linear rotation! Maybe the model uses the magnitude of a vector, instead of its direction, to do meaningful computation. We can think about different intermediate transformations that might expose interesting units of computation.  Here are some key properties that we need these transformations to have:\n",
    "<ul>\n",
    "<li><b>invertible</b> - we need to be able to \"undo\" the transformation to return to the original representation space from the transformed space</li>\n",
    "<li><b>separable</b> - we don't want concepts to interfere with each other during the transformation</li>\n",
    "</ul>\n",
    "\n",
    "To learn about more of their properties and their theoretical grounding, check out the <a href=\"https://arxiv.org/abs/2301.04709\">causal abstraction theory paper</a>!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94a752",
   "metadata": {
    "id": "6b94a752"
   },
   "source": [
    "Hm, changing our unit of computation from neurons to linear subspaces didn't seem to help us out much... Patching the first few linear subspaces of our rotation matrix didn't successfully edit the model's representation of Paris's country.\n",
    "\n",
    "How do we automatically search for the linear subspaces we care about?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b524a7",
   "metadata": {
    "id": "83b524a7"
   },
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Takeaway</b>\n",
    "\n",
    "There are different potentially meaningful units of computations in a model's representation. Thinking about the model representation as one giant multi-dimensional vector, we can try to patch **linear subspaces** of the model's representation by first rotating it to a different space.\n",
    "\n",
    "How do we know which linear subspaces to patch? This is where DAS comes in!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f9f4f",
   "metadata": {
    "id": "5b8f9f4f"
   },
   "source": [
    "## Enter DAS - automatically finding relevant linear subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e0640",
   "metadata": {
    "id": "c37e0640"
   },
   "source": [
    "By rotating the hidden representations of our model, we can patch different linear subspaces. But how can we find the right linear subspace to patch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9c038",
   "metadata": {
    "id": "16d9c038"
   },
   "source": [
    "Turns out, we can directly optimize our rotation vector to do this! Let's try to train our rotation matrix to maximize the likelihood of \"Brazil\" the country of Paris instead of \"France\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5949fbdd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5949fbdd",
    "outputId": "ff3c8541-cf27-461d-9444-ad0b4986fa49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 1/10 [02:41<22:09, 147.70s/it, loss=0.273]"
     ]
    }
   ],
   "source": [
    "# let's train our rotation matrix so that the patch output is Brazil instead of France\n",
    "from tqdm import trange\n",
    "\n",
    "# optimize only the rotation parameters (the LLM stays frozen)\n",
    "optimizer = torch.optim.Adam(rotator.parameters())\n",
    "\n",
    "# use language modeling loss - increase likelihood of outputing Brazil\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "counterfactual_answer = torch.tensor([model.tokenizer(\" Brazil\")[\"input_ids\"][1]]).to(model.device)\n",
    "\n",
    "with trange(10) as progress_bar: # train for 10 epochs\n",
    "  for epoch in progress_bar:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get patched logits using our rotation vector\n",
    "    patched_logits = patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=True)\n",
    "\n",
    "    # cross entropy loss - make last token be Brazil instead of France\n",
    "    loss = loss_fn(patched_logits, counterfactual_answer)\n",
    "    progress_bar.set_postfix({'loss': loss.item()})\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5172fa",
   "metadata": {
    "id": "bf5172fa"
   },
   "source": [
    "Looks like training our rotation matrix did the job! Now, patching from Rio to Paris changes Paris's country from France to Brazil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9f49b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fe9f49b",
    "outputId": "c789dd7a-deac-4013-9948-c90981c50ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Brazil (0.21)\n",
      " France (0.08)\n",
      " the (0.07)\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"Paris is in the country of\"\n",
    "\n",
    "patched_logits = patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=False)\n",
    "patched_probs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42375d01",
   "metadata": {
    "id": "42375d01"
   },
   "source": [
    "But did it interfere with other facts about Paris, such as its continent or language? Doesn't look like it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b047bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09b047bb",
    "outputId": "95106fb8-235f-43ce-a460-e7a10fa7600e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Europe (0.43)\n",
      " Africa (0.19)\n",
      " North (0.13)\n"
     ]
    }
   ],
   "source": [
    "new_base_prompt = \"Paris is in the continent of\"\n",
    "\n",
    "patched_logits = patch_linear_subspaces(rotator, new_base_prompt, source_hidden_states, with_grad=False)\n",
    "patched_probs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b4c7d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95b4c7d8",
    "outputId": "6ad03a31-e81a-4cb6-8871-a26b734a96e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " French (0.40)\n",
      " English (0.15)\n",
      " Italian (0.14)\n"
     ]
    }
   ],
   "source": [
    "new_base_prompt = \"Paris is a city whose main language is\"\n",
    "\n",
    "patched_logits = patch_linear_subspaces(rotator, new_base_prompt, source_hidden_states, with_grad=False)\n",
    "patched_probs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_probs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "  print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e967f",
   "metadata": {
    "id": "587e967f"
   },
   "source": [
    "<div style=\"background-color:#F2CFEE;padding:10px 10px;border-radius:20px\">\n",
    "<b>Want to know more?</b>\n",
    "\n",
    "If there are concepts that we know we want to keep the same, we can train DAS with a multi-task objective (i.e., \"edit this property\" + \"keep this other property the same\"). See the <a href=\"https://arxiv.org/abs/2402.17700\">RAVEL</a> paper for more details!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e24912",
   "metadata": {
    "id": "44e24912"
   },
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Takeaway</b>\n",
    "\n",
    "How can we patch certain concepts in a model's representation, such as the country of Paris, without messing with other concepts stored in the model, such as Paris's continent or language?\n",
    "\n",
    "DAS to the rescue! By searching over sets of linear subspaces, DAS finds a linear subspace in the model that, when patched, edits the model's concept. The resulting patch is more precise - by patching individual linear subspaces, we have a better chance at making sure that only the specific concept we're looking for gets edited.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZJtG8LQNQGXR",
   "metadata": {
    "id": "ZJtG8LQNQGXR"
   },
   "source": [
    "### Multi-Task DAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g3XtaqZVQINI",
   "metadata": {
    "id": "g3XtaqZVQINI"
   },
   "outputs": [],
   "source": [
    "# let's train our rotation matrix so that the patch output is Brazil instead of France\n",
    "from tqdm import trange\n",
    "\n",
    "# optimize only the rotation parameters (the LLM stays frozen)\n",
    "optimizer = torch.optim.Adam(rotator.parameters())\n",
    "\n",
    "# use language modeling loss - increase likelihood of outputing Brazil\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "counterfactual_answer = torch.tensor([model.tokenizer(\" Brazil\")[\"input_ids\"][1]]).to(model.device)\n",
    "\n",
    "# we can directly specify things we want to stay the same!\n",
    "new_base_prompt = \"Paris is in the continent of\"\n",
    "new_base_answer = torch.tensor([model.tokenizer(\" Europe\")[\"input_ids\"][1]]).to(model.device)\n",
    "\n",
    "with trange(10) as progress_bar: # train for 10 epochs\n",
    "  for epoch in progress_bar:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get loss for counterfactual behavior (what we want to CHANGE)\n",
    "    patched_logits = patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=True)\n",
    "    counterfactual_loss = loss_fn(patched_logits, counterfactual_answer)\n",
    "\n",
    "    # get loss for base behavior (what we want to STAY THE SAME)\n",
    "    patched_logits = patch_linear_subspaces(rotator, new_base_prompt, source_hidden_states, with_grad=True)\n",
    "    new_base_loss = loss_fn(patched_logits, new_base_answer)\n",
    "\n",
    "    # can add more examples of base behavior to keep the same if we want!\n",
    "    # ...\n",
    "\n",
    "    # add up all losses together\n",
    "    loss = counterfactual_loss + new_base_loss\n",
    "\n",
    "    progress_bar.set_postfix({'loss': loss.item()})\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ellipse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05ebc2fa7cac45d29b31ce40f1c2c05b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_bdb356ea59a84823a1b3832453063521",
      "style": "IPY_MODEL_76f8e7c2d8ea43cbb27a0c66a3f64e40",
      "value": true
     }
    },
    "1a551dd797f54d89a55553b8c7e39aae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "279676108a6b45ddadf4a6f339db525d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_84886001cc56464c911e13d7ca3c4079",
       "IPY_MODEL_a214db6a65be41759f003df761cb1695",
       "IPY_MODEL_05ebc2fa7cac45d29b31ce40f1c2c05b",
       "IPY_MODEL_a0465c6d154f4a41a8d8b1c15b5d101f",
       "IPY_MODEL_4c3d869e951b4500ac7c3f91506b13b1"
      ],
      "layout": "IPY_MODEL_1a551dd797f54d89a55553b8c7e39aae"
     }
    },
    "2e10fdcde4aa45fcadd0e7d3bd0b436e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a54d3800755482cadea63930f1fa9d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c3d869e951b4500ac7c3f91506b13b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95fdd4654d904472977677e170a3cce4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4a54d3800755482cadea63930f1fa9d4",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "560e58a2b749410caa129b7931925227": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6df04578201e41789af274172bd9d482": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76f8e7c2d8ea43cbb27a0c66a3f64e40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84886001cc56464c911e13d7ca3c4079": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e10fdcde4aa45fcadd0e7d3bd0b436e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_560e58a2b749410caa129b7931925227",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "8f0091d9696e48f2a91dcb4444848c21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "95fdd4654d904472977677e170a3cce4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0465c6d154f4a41a8d8b1c15b5d101f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_ae2a6c8958ee48d09529466257be347f",
      "style": "IPY_MODEL_8f0091d9696e48f2a91dcb4444848c21",
      "tooltip": ""
     }
    },
    "a214db6a65be41759f003df761cb1695": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_6df04578201e41789af274172bd9d482",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_abbd26fc7f5d47cdbcd056bc7b9288ba",
      "value": ""
     }
    },
    "abbd26fc7f5d47cdbcd056bc7b9288ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae2a6c8958ee48d09529466257be347f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdb356ea59a84823a1b3832453063521": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
