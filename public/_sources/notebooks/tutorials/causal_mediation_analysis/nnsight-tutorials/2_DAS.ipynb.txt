{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eef0b7f",
   "metadata": {},
   "source": [
    "# Distributed Alignment Search (DAS): Searching for Linearly Encoded Concepts in Model Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2711bb6",
   "metadata": {},
   "source": [
    "In the last tutorial, we looked at <a href=\"https://arxiv.org/abs/2402.17700\">RAVEL</a>, which helps us evaluate where a high-level concept might be encoded in a model's internal representations.\n",
    "\n",
    "In particular, imagine we want to edit a model to think that Paris is in the country of Brazil, without changing whatever else the model knows about Paris (e.g., its language, continent, ...). Which representations in the model encode this fact about Paris?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715718af",
   "metadata": {},
   "source": [
    "In this tutorial, we'll go over **Distributed Alignment Search**, or <a href=\"https://arxiv.org/abs/2303.02536\">DAS</a>, which helps us automatically identify a set of linear subspaces in a model's representations that encode a particular concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde356e1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#FF9999;padding:10px 10px;border-radius:20px\">\n",
    "<b>Before we begin!</b>\n",
    "\n",
    "These are good things to know before we begin the tutorial\n",
    "<ul>\n",
    "<li>Activation patching - check out the activation patching tutorial <a href=\"https://nnsight.net/notebooks/tutorials/activation_patching/\">here</a>!</li>\n",
    "<li>RAVEL - make sure to check out the first part of the tutorial before trying out this one!</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da8719e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Things we'll talk about</b>\n",
    "\n",
    "In case you want to tell people what you learned today!\n",
    "<ul>\n",
    "<li><a href=\"https://arxiv.org/abs/2303.02536\">DAS</a> - method for finding linear subspaces of model representations that store a particular concept.</li>\n",
    "</ul>\n",
    "\n",
    "Let's do this!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    is_colab = True\n",
    "except ImportError:\n",
    "    is_colab = False\n",
    "\n",
    "if is_colab:\n",
    "    !pip install -U nnsight\n",
    "    !git clone https://github.com/AmirZur/nnsight-tutorials.git\n",
    "    %cd nnsight-tutorials/\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000a395",
   "metadata": {},
   "source": [
    "## Making surgical edits - residual streams capture too much information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fdea36",
   "metadata": {},
   "source": [
    "Last tutorial, we saw that by patching the 8th layer of the \"Paris\" token, we were able to change its country from France to Brazil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59534ebb",
   "metadata": {},
   "source": [
    "![two forward runs of a model, with an arrow between the residual stream activations of Rio and Paris. After the intervention is applied, the model outputs Brazil](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/patching_visualization.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdce6ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "import nnsight\n",
    "from IPython.display import clear_output\n",
    "\n",
    "model = nnsight.LanguageModel(\"meta-llama/Llama-3.2-1B\", device_map=\"auto\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01133425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France (0.65)\n",
      " the (0.05)\n",
      " love (0.01)\n"
     ]
    }
   ],
   "source": [
    "# does our model know where Paris is?\n",
    "import torch\n",
    "\n",
    "base_prompt = \"Paris is in the country of\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    with model.trace(base_prompt) as tracer:\n",
    "        base_tokens = tracer.invoker.inputs[0][0]['input_ids'][0]\n",
    "        # Get logits from the lm_head\n",
    "        base_logits = model.lm_head.output[:, -1, :].save()\n",
    "\n",
    "base_logprobs = torch.softmax(base_logits, dim=-1)\n",
    "\n",
    "top_completions = torch.topk(base_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e93aaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect representations for a city from a different country\n",
    "source_prompt = \"Rio is in the country of\"\n",
    "source_country = model.tokenizer(\" Brazil\")[\"input_ids\"][1] # includes a space\n",
    "\n",
    "with torch.no_grad():\n",
    "    with model.trace(source_prompt) as tracer:\n",
    "        source_tokens = tracer.invoker.inputs[0][0]['input_ids'][0]\n",
    "        # Get hidden states of all layers in the network.\n",
    "        # We index the output at 0 because it's a tuple where the first index is the hidden state.\n",
    "        source_hidden_states = [\n",
    "            layer.output[0].save()\n",
    "            for layer in model.model.layers\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d11d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Brazil (0.61)\n",
      " the (0.05)\n",
      " Portugal (0.01)\n"
     ]
    }
   ],
   "source": [
    "# by patching at layer 8 over Paris, we change its country from France to Brazil!\n",
    "TOKEN_INDEX = 1\n",
    "LAYER_INDEX = 8\n",
    "\n",
    "with model.trace(base_prompt) as tracer:\n",
    "    # apply the same patch we did before\n",
    "    model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :] = \\\n",
    "        source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "\n",
    "    patched_logits = model.lm_head.output[:, -1, :]\n",
    "\n",
    "    patched_logprobs = torch.softmax(patched_logits, dim=-1).save()\n",
    "\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf57e12",
   "metadata": {},
   "source": [
    "However, we **also accidentally edit other facts about Paris**, such as its continent and language!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33978988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " South (0.55)\n",
      " America (0.11)\n",
      " North (0.10)\n"
     ]
    }
   ],
   "source": [
    "# by changing Paris's country, we also changed its continent!\n",
    "TOKEN_INDEX = 1\n",
    "LAYER_INDEX = 8\n",
    "\n",
    "new_base_prompt = \"Paris is in the continent of\"\n",
    "\n",
    "with model.trace(new_base_prompt) as tracer:\n",
    "    # apply the same patch we did before\n",
    "    model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :] = \\\n",
    "        source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "\n",
    "    patched_logits = model.lm_head.output[:, -1, :]\n",
    "\n",
    "    patched_logprobs = torch.softmax(patched_logits, dim=-1).save()\n",
    "\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c0eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Portuguese (0.57)\n",
      " Spanish (0.12)\n",
      " English (0.10)\n"
     ]
    }
   ],
   "source": [
    "# as well as its language!\n",
    "new_base_prompt = \"Paris is a city whose main language is\"\n",
    "\n",
    "with model.trace(new_base_prompt) as tracer:\n",
    "    # apply the same patch we did before\n",
    "    model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :] = \\\n",
    "        source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "\n",
    "    patched_logits = model.lm_head.output[:, -1, :]\n",
    "\n",
    "    patched_logprobs = torch.softmax(patched_logits, dim=-1).save()\n",
    "\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a930cc4e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Takeaway</b>\n",
    "\n",
    "We need to find a way to make our patching **more precise**. One way to do this is to patch a unit of computation that's smaller than the whole residual stream component. There are many reasonable options, such as patching sets of neurons. In this tutorial, we'll look at how we can patch **linear subspaces** of a model's representation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49541273",
   "metadata": {},
   "source": [
    "## Choosing the right unit of computation - how do models represent concepts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e4b64e",
   "metadata": {},
   "source": [
    "What are we patching to begin with? Let's take a look at the source activations we collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f58841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0111, -0.0206, -0.2613,  ..., -0.0281, -0.1300,  0.0346]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_activations = source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "source_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ce518c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_activations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f4c7a",
   "metadata": {},
   "source": [
    "Can we break down the residual stream activation into smaller, meaningful units of computation?\n",
    "\n",
    "One idea is to look at single neurons - that is, single indices within the large 2048-dimensional vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34538880",
   "metadata": {},
   "source": [
    "Another idea, motivated by the Linear Representation Hypothesis, is that transformer-based neural networks tend to use **linear subspaces** as units of computation. Thinking about a model's activation as one giant vector, perhaps concepts are each encoded in a separate linear dimension within the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763dcc73",
   "metadata": {},
   "source": [
    "![Activation represented as a linear vector, with subspaces encoding concepts such as the country & language of Paris](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/activation_vector.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a347d0e",
   "metadata": {},
   "source": [
    "To patch a set of neurons, we could simply index into the ones we think encode important concepts in the model. However, enumerating all subsets of neurons is computationally infeasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfd1f5c",
   "metadata": {},
   "source": [
    "![patching the first 3 neurons of the activations of Rio and Paris](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/patching_neurons_visualization.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe5a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France (0.64)\n",
      " the (0.05)\n",
      " love (0.01)\n"
     ]
    }
   ],
   "source": [
    "# change the list of indices to try a set of neurons to patch!\n",
    "NEURON_INDICES = [0, 1, 2, 4]\n",
    "\n",
    "base_prompt = \"Paris is in the country of\"\n",
    "\n",
    "with model.trace(base_prompt) as tracer:\n",
    "    # Apply the patch from the source hidden states to the base hidden states\n",
    "    model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, NEURON_INDICES] = \\\n",
    "        source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, NEURON_INDICES]\n",
    "\n",
    "    patched_logits = model.lm_head.output[:, -1, :]\n",
    "\n",
    "    patched_logprobs = torch.softmax(patched_logits, dim=-1).save()\n",
    "\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec24c4e",
   "metadata": {},
   "source": [
    "To patch a set of **linear subspaces**, we can follow a similar procedure, with a slight twist...\n",
    "\n",
    "First, we **rotate** our base and source vectors. This creates two new vectors, whose neurons are linear combinations of the original vector. Next, we **patch linear subspaces** just as we would in the regular set-up. Lastly, we **rotate back** the patched vector, so that it's in the same basis as the original run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9fba6",
   "metadata": {},
   "source": [
    "![patch between a source and base vector, where the source & base vector are first rotated. the resulting patch is then un-rotated back to the original basis](https://github.com/AmirZur/nnsight-tutorials/blob/main/figures/das_visualization.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3f99b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a rotation matrix (model_dim x model_dim)\n",
    "MODEL_HIDDEN_DIM = 2048\n",
    "\n",
    "rotator = torch.nn.Linear(MODEL_HIDDEN_DIM, MODEL_HIDDEN_DIM, bias=False)\n",
    "torch.nn.init.orthogonal_(rotator.weight)\n",
    "\n",
    "rotator = torch.nn.utils.parametrizations.orthogonal(rotator)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c077243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " France (0.12)\n",
      " the (0.09)\n",
      " Italy (0.02)\n"
     ]
    }
   ],
   "source": [
    "# play around with how many linear dimensions we patch!\n",
    "N_PATCHING_DIMS = 1\n",
    "\n",
    "base_prompt = \"Paris is in the country of\"\n",
    "\n",
    "def patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=False):\n",
    "    grad_env = torch.enable_grad if with_grad else torch.no_grad\n",
    "    with grad_env():\n",
    "        with model.trace(base_prompt) as tracer:\n",
    "            # rotate the base representation\n",
    "            base = model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :].clone()\n",
    "            rotated_base = rotator(base)\n",
    "\n",
    "            # rotate the source representation\n",
    "            source = source_hidden_states[LAYER_INDEX][:, TOKEN_INDEX, :]\n",
    "            rotated_source = rotator(source)\n",
    "\n",
    "            # patch the first n dimensions in the rotated space\n",
    "            # (NOTE: same thing as `rotated_base[:, 0] = rotated_source[:, 0]` but we want the gradient to flow)\n",
    "            rotated_patch = torch.cat([\n",
    "                rotated_source[:, :N_PATCHING_DIMS],\n",
    "                rotated_base[:, N_PATCHING_DIMS:]\n",
    "            ], dim=1)\n",
    "\n",
    "            # unrotate patched vector back to the original space\n",
    "            patch = torch.matmul(rotated_patch, rotator.weight.T)\n",
    "\n",
    "            # replace base with patch\n",
    "            model.model.layers[LAYER_INDEX].output[0][:, TOKEN_INDEX, :] = patch\n",
    "\n",
    "            patched_logits = model.lm_head.output[:, -1, :].save()\n",
    "    return patched_logits\n",
    "\n",
    "patched_logits = patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=False)\n",
    "patched_logprobs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9322d8ab",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#F2CFEE;padding:10px 10px;border-radius:20px\">\n",
    "<b>Want to know more?</b>\n",
    "\n",
    "You may have suspected this, but there's nothing particularly special about a linear rotation! Maybe the model uses the magnitude of a vector, instead of its direction, to do meaningful computation. We can think about different intermediate transformations that might expose interesting units of computation.  Here are some key properties that we need these transformations to have:\n",
    "<ul>\n",
    "<li><b>invertible</b> - we need to be able to \"undo\" the transformation to return to the original representation space from the transformed space</li>\n",
    "<li><b>separable</b> - we don't want concepts to interfere with each other during the transformation</li>\n",
    "</ul>\n",
    "\n",
    "To learn about more of their properties and their theoretical grounding, check out the <a href=\"https://arxiv.org/abs/2301.04709\">causal abstraction theory paper</a>!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b94a752",
   "metadata": {},
   "source": [
    "Hm, changing our unit of computation from neurons to linear subspaces didn't seem to help us out much... Patching the first few linear subspaces of our rotation matrix didn't successfully edit the model's representation of Paris's country. \n",
    "\n",
    "How do we automatically search for the linear subspaces we care about?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b524a7",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Takeaway</b>\n",
    "\n",
    "There are different potentially meaningful units of computations in a model's representation. Thinking about the model representation as one giant multi-dimensional vector, we can try to patch **linear subspaces** of the model's representation by first rotating it to a different space. \n",
    "\n",
    "How do we know which linear subspaces to patch? This is where DAS comes in!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f9f4f",
   "metadata": {},
   "source": [
    "## Enter DAS - automatically finding relevant linear subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e0640",
   "metadata": {},
   "source": [
    "By rotating the hidden representations of our model, we can patch different linear subspaces. But how can we find the right linear subspace to patch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9c038",
   "metadata": {},
   "source": [
    "Turns out, we can directly optimize our rotation vector to do this! Let's try to train our rotation matrix to maximize the likelihood of \"Brazil\" the country of Paris instead of \"France\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5949fbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:44<00:00, 22.44s/it, loss=1.94]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Brazil (0.14)\n",
      " Portugal (0.08)\n",
      " the (0.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# let's train our rotation matrix so that the patch output is Brazil instead of France\n",
    "from tqdm import trange\n",
    "\n",
    "optimizer = torch.optim.Adam(rotator.parameters())\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "counterfactual_answer = torch.tensor([model.tokenizer(\" Brazil\")[\"input_ids\"][1]])\n",
    "\n",
    "with trange(10) as progress_bar:\n",
    "    for epoch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get patched logits using our rotation vector\n",
    "        patched_logits = patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=True)\n",
    "\n",
    "        # cross entropy loss - make last token be Brazil instead of France\n",
    "        loss = loss_fn(patched_logits, counterfactual_answer)\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "patched_logprobs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5172fa",
   "metadata": {},
   "source": [
    "Looks like training our rotation matrix did the job! Now, patching from Rio to Paris changes Paris's country from France to Brazil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fe9f49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Brazil (0.64)\n",
      " Portugal (0.07)\n",
      ", (0.06)\n"
     ]
    }
   ],
   "source": [
    "base_prompt = \"Paris is in the country of\"\n",
    "\n",
    "patched_logits = patch_linear_subspaces(rotator, base_prompt, source_hidden_states, with_grad=False)\n",
    "patched_logprobs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42375d01",
   "metadata": {},
   "source": [
    "But did it interfere with other facts about Paris, such as its continent or language? Doesn't look like it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b047bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Europe (0.70)\n",
      " America (0.07)\n",
      ", (0.04)\n"
     ]
    }
   ],
   "source": [
    "new_base_prompt = \"Paris is in the continent of\"\n",
    "\n",
    "patched_logits = patch_linear_subspaces(rotator, new_base_prompt, source_hidden_states, with_grad=False)\n",
    "patched_logprobs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95b4c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " spoken (0.32)\n",
      " English (0.12)\n",
      ", (0.08)\n"
     ]
    }
   ],
   "source": [
    "new_base_prompt = \"Paris is a city whose main language is\"\n",
    "\n",
    "patched_logits = patch_linear_subspaces(rotator, new_base_prompt, source_hidden_states, with_grad=False)\n",
    "patched_logprobs = torch.softmax(patched_logits, dim=-1)\n",
    "top_completions = torch.topk(patched_logprobs, 3, sorted=True)\n",
    "for v, i in zip(top_completions.values[0], top_completions.indices[0]):\n",
    "    print(f'{model.tokenizer.decode(i.item())} ({v.item():.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587e967f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#F2CFEE;padding:10px 10px;border-radius:20px\">\n",
    "<b>Want to know more?</b>\n",
    "\n",
    "If there are concepts that we know we want to keep the same, we can train DAS with a multi-task objective (i.e., \"edit this property\" + \"keep this other property the same\"). See the <a href=\"https://arxiv.org/abs/2402.17700\">RAVEL</a> paper for more detail.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e24912",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C1E5F5;padding:10px 10px;border-radius:20px\">\n",
    "<b>Takeaway</b>\n",
    "\n",
    "How can we patch certain concepts in a model's representation, such as the country of Paris, without messing with other concepts stored in the model, such as Paris's continent or language?\n",
    "\n",
    "DAS to the rescue! By searching over sets of linear subspaces, DAS finds a linear subspace in the model that, when patched, edits the model's concept. The resulting patch is more precise - by patching individual linear subspaces, we have a better chance at making sure that only the specific concept we're looking for gets edited.  \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
