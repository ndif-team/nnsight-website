
<!DOCTYPE html>


<html lang="en" data-content_root="../../" data-theme="dark">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>NNsight 0.5: Official Walkthrough &#8212; nnsight</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "dark";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "dark";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=187304be"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/NNsight_0_5_Changes';</script>
    <script src="../../_static/js/custom.js?v=f64c75aa"></script>
    <script src="../../_static/js/code.js?v=34343d0c"></script>
    <link rel="icon" href="../../_static/icon.ico"/>
    <link rel="author" title="About these documents" href="../../about/" />
    <link rel="index" title="Index" href="../../genindex/" />
    <link rel="search" title="Search" href="../../search/" />

  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
<link href="../../_static/css/custom.css?v=1758727866" rel="stylesheet" type="text/css" />
<link href="../../_static/css/home.css?v=1758727866" rel="stylesheet" type="text/css" />

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="dark">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../">
  
  
  
  
  
    
    
    
    <img src="../../_static/nnsight_logo.svg" class="logo__image only-dark" alt="nnsight - Home"/>
    <img src="../../_static/nnsight_logo.svg" class="logo__image only-light pst-js-only" alt="nnsight - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../start/">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../documentation/">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../features/">
    Features
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../tutorials/">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../about/">
    About
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item"><script>
    fetch("https://ndif.dev/ping")
        .then((response) => {
            if (response.status == 200) {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#66800b', 'important');
                    });
                });
            }
            else {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#af3029', 'important');
                    });
                });
                var statusIcon = document.querySelector('.ndif .fa-circle-check');
                if (statusIcon) {
                    // not here
                    statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark'); 
                }
            }
        })
        .catch((response) => {
            Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                    spanElement.style.setProperty('color', '#af3029', 'important');
                });
            });
            var statusIcon = document.querySelector('.ndif .fa-circle-check');
            if (statusIcon) {
                statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark');
            }
        })
</script></div>
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="/status" title="Status: Unknown" class="ndif" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-circle-check fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Status: Unknown</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ndif-team/nnsight" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.ndif.us/" title="Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://forms.gle/1Y6myaXYzSh3oHf56" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../start/">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../documentation/">
    Documentation
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../features/">
    Features
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../tutorials/">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../about/">
    About
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><script>
    fetch("https://ndif.dev/ping")
        .then((response) => {
            if (response.status == 200) {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#66800b', 'important');
                    });
                });
            }
            else {
                Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                    Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                        spanElement.style.setProperty('color', '#af3029', 'important');
                    });
                });
                var statusIcon = document.querySelector('.ndif .fa-circle-check');
                if (statusIcon) {
                    // not here
                    statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark'); 
                }
            }
        })
        .catch((response) => {
            Array.from(document.getElementsByClassName("ndif")).forEach((ndifElement) => {
                Array.from(ndifElement.getElementsByTagName('span')).forEach((spanElement) => {
                    spanElement.style.setProperty('color', '#af3029', 'important');
                });
            });
            var statusIcon = document.querySelector('.ndif .fa-circle-check');
            if (statusIcon) {
                statusIcon.classList.replace('fa-circle-check', 'fa-circle-xmark');
            }
        })
</script></div>
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
            
          
          
          
          
          
          
          
          
          
          <a href="/status" title="Status: Unknown" class="ndif" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-solid fa-circle-check fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Status: Unknown</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ndif-team/nnsight" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://discuss.ndif.us/" title="Forum" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discourse fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Forum</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://forms.gle/1Y6myaXYzSh3oHf56" title="Discord" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-discord fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Discord</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">NNsight 0.5: Official Walkthrough</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="NNsight-0.5:-Official-Walkthrough">
<h1>NNsight 0.5: Official Walkthrough<a class="headerlink" href="#NNsight-0.5:-Official-Walkthrough" title="Link to this heading">#</a></h1>
<p><strong>We have many exciting new features in this update!</strong></p>
<p><code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code> represents a complete redesign from the ground up focused on addressing user concerns related to debugging and performing fine-grained interventions. Now, we have direct execution of user code and no longer need to work with the complexity of proxies.</p>
<p>The following walkthrough guides you through how to access <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code> and use all of its individual features. As this update changes how <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> works, we will structure this walkthrough in three sections:</p>
<ol class="arabic simple">
<li><p>Core behavior</p></li>
<li><p>Breaking changes</p></li>
<li><p>New features</p></li>
</ol>
<p>Thought and opinions and the direction of NNsight are invaluable to our organization: Please report any bugs or feedback on our forum: <a class="reference external" href="https://discuss.ndif.us">https://discuss.ndif.us</a></p>
<p><strong>Now, let’s get started by installing ``NNsight 0.5`` and initializing the GPT-2 model.</strong></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">clear_output</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>nnsight
<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">nnsight</span>

<span class="n">nnsight</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/opt/anaconda3/envs/nnsight/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;0.5.0&#39;
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># save packages using pip freeze</span>
<span class="o">!</span>pip<span class="w"> </span>freeze
<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import nnsight packages</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">nnsight</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">nnsight</span><span class="w"> </span><span class="kn">import</span> <span class="n">LanguageModel</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "6b96cec6a55d423692e106d3ff4f96ac", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "b797914fef1e4774953e8592c9f26baa", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e2bca1ef8c444edfa573242257e54aee", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "2b95db51686948f08ad143beaa271ed8", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "808e5a53556d4ef9a46fabbf62f89081", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
GPT2LMHeadModel(
  (transformer): GPT2Model(
    (wte): Embedding(50257, 768)
    (wpe): Embedding(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): ModuleList(
      (0-11): 12 x GPT2Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        )
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (act): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        )
      )
    )
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (lm_head): Linear(in_features=768, out_features=50257, bias=False)
  (generator): Generator(
    (streamer): Streamer()
  )
)
</pre></div></div>
</div>
</section>
<section id="Core-Behavior">
<h1>Core Behavior<a class="headerlink" href="#Core-Behavior" title="Link to this heading">#</a></h1>
<p>Now that we have <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code> installed and GPT-2 instantiated, let’s dig deeper into the core changes we’ve implemented with this update.</p>
<section id="No-More-Proxies!">
<h2>No More Proxies!<a class="headerlink" href="#No-More-Proxies!" title="Link to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">NNsight</span></code> previously used proxies to help trace and intervene on model internals. This meant anything that didn’t fit into the proxy graph had to be manually supported. With <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, there are no more proxies. Now, user code is executed directly inside the trace context, which enables use of breakpoints, print statements, libraries and custom functions, etc.</p>
<p>For example, we can now directly print model values within the tracing context without using NNsight’s log function.</p>
<p>&lt;before, if soemthing wasnt supported by nnsight to fit into the proxing intervention graph design, it had to be manually supported, now because use code is directly executed, you can do anythin &gt;</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>
  <span class="c1"># print statement within trace context</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Intervention&quot;</span><span class="p">)</span>

  <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">l1</span><span class="p">)</span>

  <span class="n">l2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

  <span class="n">l3</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">l3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "02c688c465134409b37562cebae830bb", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a62afae87a624d5d9f2e45f2972e2956", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Starting Intervention
l1 (tensor([[[ 0.6784, -1.4596,  0.8340,  ..., -0.8639,  0.0798, -1.6176],
         [-1.6008,  0.3668,  0.7506,  ..., -1.1595, -0.5517,  0.3558]]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;),)
(tensor([[[ 1.1259, -2.1527,  0.9124,  ..., -0.9309, -0.3252, -1.0321],
         [ 0.1096,  0.2835,  0.9886,  ..., -1.1560, -0.5406,  0.7856]]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;),)
</pre></div></div>
</div>
<p>Let’s try using a breakpoint to inspect an activation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

  <span class="nb">breakpoint</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&gt; <span class="ansi-green-fg">&lt;nnsight 138764089777696&gt;</span>(10)<span class="ansi-cyan-fg">__nnsight_tracer_138764089715760__</span><span class="ansi-blue-fg">()</span>

ipdb&gt; l1
(tensor([[[ 0.6784, -1.4596,  0.8340,  ..., -0.8639,  0.0798, -1.6176],
         [-1.6008,  0.3668,  0.7506,  ..., -1.1595, -0.5517,  0.3558]]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;),)
ipdb&gt;
(tensor([[[ 0.6784, -1.4596,  0.8340,  ..., -0.8639,  0.0798, -1.6176],
         [-1.6008,  0.3668,  0.7506,  ..., -1.1595, -0.5517,  0.3558]]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;),)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ExitTracingException</span>                      Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-22733912.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg">   </span>l1 <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">.</span>transformer<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>output
<span class="ansi-green-intense-fg ansi-bold">      4</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/tracing/base.py</span> in <span class="ansi-cyan-fg">skip</span><span class="ansi-blue-fg">(new_frame, event, arg)</span>
<span class="ansi-green-intense-fg ansi-bold">    385</span>                 self<span class="ansi-blue-fg">.</span>info<span class="ansi-blue-fg">.</span>frame<span class="ansi-blue-fg">.</span>f_trace <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-fg">--&gt; 386</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">raise</span> ExitTracingException<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    387</span>

<span class="ansi-red-fg">ExitTracingException</span>:

During handling of the above exception, another exception occurred:

<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-22733912.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">with</span> model<span class="ansi-blue-fg">.</span>trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Hello World&#34;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>   l1 <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">.</span>transformer<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>output
<span class="ansi-green-intense-fg ansi-bold">      4</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>   breakpoint<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/tracing/base.py</span> in <span class="ansi-cyan-fg">__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">    414</span>
<span class="ansi-green-intense-fg ansi-bold">    415</span>             <span class="ansi-red-fg"># Execute the traced code using the configured backend</span>
<span class="ansi-green-fg">--&gt; 416</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>backend<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    417</span>
<span class="ansi-green-intense-fg ansi-bold">    418</span>             <span class="ansi-green-fg">return</span> <span class="ansi-green-fg">True</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/backends/execution.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, tracer)</span>
<span class="ansi-green-intense-fg ansi-bold">     19</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     20</span>             Globals<span class="ansi-blue-fg">.</span>enter<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 21</span><span class="ansi-red-fg">             </span>tracer<span class="ansi-blue-fg">.</span>execute<span class="ansi-blue-fg">(</span>fn<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     22</span>         <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     23</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/tracing/tracer.py</span> in <span class="ansi-cyan-fg">execute</span><span class="ansi-blue-fg">(self, fn)</span>
<span class="ansi-green-intense-fg ansi-bold">    383</span>         interleaver<span class="ansi-blue-fg">.</span>initialize<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>mediators<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">,</span> batcher<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>batcher<span class="ansi-blue-fg">,</span> user_cache<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>user_cache<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    384</span>
<span class="ansi-green-fg">--&gt; 385</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">.</span>interleave<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>fn<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    386</span>
<span class="ansi-green-intense-fg ansi-bold">    387</span>         self<span class="ansi-blue-fg">.</span>push<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_frame<span class="ansi-blue-fg">.</span>f_locals<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/modeling/mixins/meta.py</span> in <span class="ansi-cyan-fg">interleave</span><span class="ansi-blue-fg">(self, fn, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     74</span>                 fn <span class="ansi-blue-fg">=</span> fn<span class="ansi-blue-fg">.</span>__func__<span class="ansi-blue-fg">.</span>__get__<span class="ansi-blue-fg">(</span>new_self<span class="ansi-blue-fg">,</span> type<span class="ansi-blue-fg">(</span>new_self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     75</span>
<span class="ansi-green-fg">---&gt; 76</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> super<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>interleave<span class="ansi-blue-fg">(</span>fn<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/envoy.py</span> in <span class="ansi-cyan-fg">interleave</span><span class="ansi-blue-fg">(self, fn, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    731</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    732</span>             <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>_interleaver<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 733</span><span class="ansi-red-fg">                 </span>fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    734</span>
<span class="ansi-green-intense-fg ansi-bold">    735</span>             self<span class="ansi-blue-fg">.</span>_interleaver<span class="ansi-blue-fg">.</span>check_cache_full<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/envoy.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, hook, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    382</span>             self<span class="ansi-blue-fg">.</span>_module<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    383</span>             <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>interleaving <span class="ansi-green-fg">and</span> <span class="ansi-green-fg">not</span> hook
<span class="ansi-green-fg">--&gt; 384</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">else</span> self<span class="ansi-blue-fg">.</span>_module<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    385</span>         )
<span class="ansi-green-intense-fg ansi-bold">    386</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1771</span>             <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_compiled_call_impl<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1772</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1773</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_call_impl<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1774</span>
<span class="ansi-green-intense-fg ansi-bold">   1775</span>     <span class="ansi-red-fg"># torchrec tests the code consistency with the following code</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1877</span>
<span class="ansi-green-intense-fg ansi-bold">   1878</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1879</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> inner<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1880</span>         <span class="ansi-green-fg">except</span> Exception<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1881</span>             <span class="ansi-red-fg"># run always called hooks if they have not already been run</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">inner</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">   1825</span>                 args <span class="ansi-blue-fg">=</span> bw_hook<span class="ansi-blue-fg">.</span>setup_input_hook<span class="ansi-blue-fg">(</span>args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1826</span>
<span class="ansi-green-fg">-&gt; 1827</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> forward_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1828</span>             <span class="ansi-green-fg">if</span> _global_forward_hooks <span class="ansi-green-fg">or</span> self<span class="ansi-blue-fg">.</span>_forward_hooks<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1829</span>                 for hook_id, hook in (

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py</span> in <span class="ansi-cyan-fg">skippable_forward</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    131</span>             <span class="ansi-green-fg">if</span> skip <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span> <span class="ansi-green-fg">or</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>interleaving<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    132</span>                 <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 133</span><span class="ansi-red-fg">                     </span><span class="ansi-green-fg">return</span> forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    134</span>                 <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>                     skip <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1074</span>         return_dict <span class="ansi-blue-fg">=</span> return_dict <span class="ansi-green-fg">if</span> return_dict <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span> <span class="ansi-green-fg">else</span> self<span class="ansi-blue-fg">.</span>config<span class="ansi-blue-fg">.</span>use_return_dict
<span class="ansi-green-intense-fg ansi-bold">   1075</span>
<span class="ansi-green-fg">-&gt; 1076</span><span class="ansi-red-fg">         transformer_outputs = self.transformer(
</span><span class="ansi-green-intense-fg ansi-bold">   1077</span>             input_ids<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1078</span>             past_key_values<span class="ansi-blue-fg">=</span>past_key_values<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1771</span>             <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_compiled_call_impl<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1772</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1773</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_call_impl<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1774</span>
<span class="ansi-green-intense-fg ansi-bold">   1775</span>     <span class="ansi-red-fg"># torchrec tests the code consistency with the following code</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1877</span>
<span class="ansi-green-intense-fg ansi-bold">   1878</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1879</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> inner<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1880</span>         <span class="ansi-green-fg">except</span> Exception<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1881</span>             <span class="ansi-red-fg"># run always called hooks if they have not already been run</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">inner</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">   1825</span>                 args <span class="ansi-blue-fg">=</span> bw_hook<span class="ansi-blue-fg">.</span>setup_input_hook<span class="ansi-blue-fg">(</span>args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1826</span>
<span class="ansi-green-fg">-&gt; 1827</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> forward_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1828</span>             <span class="ansi-green-fg">if</span> _global_forward_hooks <span class="ansi-green-fg">or</span> self<span class="ansi-blue-fg">.</span>_forward_hooks<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1829</span>                 for hook_id, hook in (

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py</span> in <span class="ansi-cyan-fg">skippable_forward</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    131</span>             <span class="ansi-green-fg">if</span> skip <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span> <span class="ansi-green-fg">or</span> <span class="ansi-green-fg">not</span> self<span class="ansi-blue-fg">.</span>interleaving<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    132</span>                 <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 133</span><span class="ansi-red-fg">                     </span><span class="ansi-green-fg">return</span> forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    134</span>                 <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>                     skip <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/transformers/models/gpt2/modeling_gpt2.py</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    925</span>                 all_hidden_states <span class="ansi-blue-fg">=</span> all_hidden_states <span class="ansi-blue-fg">+</span> <span class="ansi-blue-fg">(</span>hidden_states<span class="ansi-blue-fg">,</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    926</span>
<span class="ansi-green-fg">--&gt; 927</span><span class="ansi-red-fg">             outputs = block(
</span><span class="ansi-green-intense-fg ansi-bold">    928</span>                 hidden_states<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    929</span>                 past_key_values <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> <span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>gradient_checkpointing <span class="ansi-green-fg">and</span> self<span class="ansi-blue-fg">.</span>training<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">else</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     92</span>
<span class="ansi-green-intense-fg ansi-bold">     93</span>             <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_gradient_checkpointing_func<span class="ansi-blue-fg">(</span>partial<span class="ansi-blue-fg">(</span>super<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>__call__<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 94</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> super<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>__call__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     95</span>
<span class="ansi-green-intense-fg ansi-bold">     96</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1771</span>             <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_compiled_call_impl<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1772</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1773</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_call_impl<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1774</span>
<span class="ansi-green-intense-fg ansi-bold">   1775</span>     <span class="ansi-red-fg"># torchrec tests the code consistency with the following code</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1877</span>
<span class="ansi-green-intense-fg ansi-bold">   1878</span>         <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1879</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> inner<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1880</span>         <span class="ansi-green-fg">except</span> Exception<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1881</span>             <span class="ansi-red-fg"># run always called hooks if they have not already been run</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">inner</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">   1838</span>                         hook_result <span class="ansi-blue-fg">=</span> hook<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">,</span> kwargs<span class="ansi-blue-fg">,</span> result<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1839</span>                     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1840</span><span class="ansi-red-fg">                         </span>hook_result <span class="ansi-blue-fg">=</span> hook<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> args<span class="ansi-blue-fg">,</span> result<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1841</span>
<span class="ansi-green-intense-fg ansi-bold">   1842</span>                     <span class="ansi-green-fg">if</span> hook_result <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py</span> in <span class="ansi-cyan-fg">_fn</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    927</span>                 _maybe_set_eval_frame<span class="ansi-blue-fg">(</span>_callback_from_stance<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>callback<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    928</span>                 <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 929</span><span class="ansi-red-fg">                     </span><span class="ansi-green-fg">return</span> fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    930</span>                 <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    931</span>                     set_eval_frame<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py</span> in <span class="ansi-cyan-fg">output_hook</span><span class="ansi-blue-fg">(module, _, output)</span>
<span class="ansi-green-intense-fg ansi-bold">    176</span>                 skip <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    177</span>
<span class="ansi-green-fg">--&gt; 178</span><span class="ansi-red-fg">             </span>output <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>handle<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#34;{provider}.output&#34;</span><span class="ansi-blue-fg">,</span> output<span class="ansi-blue-fg">,</span> iterate<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    179</span>
<span class="ansi-green-intense-fg ansi-bold">    180</span>             <span class="ansi-green-fg">return</span> output

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py</span> in <span class="ansi-cyan-fg">handle</span><span class="ansi-blue-fg">(self, provider, value, iterate)</span>
<span class="ansi-green-intense-fg ansi-bold">    338</span>
<span class="ansi-green-intense-fg ansi-bold">    339</span>             <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 340</span><span class="ansi-red-fg">                 </span>mediator<span class="ansi-blue-fg">.</span>handle<span class="ansi-blue-fg">(</span>provider<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    341</span>             <span class="ansi-green-fg">except</span> SkipException <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    342</span>                 skip_count <span class="ansi-blue-fg">+=</span> <span class="ansi-cyan-fg">1</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py</span> in <span class="ansi-cyan-fg">handle</span><span class="ansi-blue-fg">(self, provider)</span>
<span class="ansi-green-intense-fg ansi-bold">    514</span>
<span class="ansi-green-intense-fg ansi-bold">    515</span>             <span class="ansi-green-fg">if</span> event <span class="ansi-blue-fg">==</span> Events<span class="ansi-blue-fg">.</span>VALUE<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 516</span><span class="ansi-red-fg">                 </span>process <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>handle_value_event<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">,</span> provider<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    517</span>             <span class="ansi-green-fg">elif</span> event <span class="ansi-blue-fg">==</span> Events<span class="ansi-blue-fg">.</span>SWAP<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    518</span>                 process <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>handle_swap_event<span class="ansi-blue-fg">(</span>provider<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>data<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py</span> in <span class="ansi-cyan-fg">handle_value_event</span><span class="ansi-blue-fg">(self, requester, provider, value)</span>
<span class="ansi-green-intense-fg ansi-bold">    602</span>             value <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>interleaver<span class="ansi-blue-fg">.</span>batcher<span class="ansi-blue-fg">.</span>narrow<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>batch_group<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    603</span>
<span class="ansi-green-fg">--&gt; 604</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>respond<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    605</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    606</span>             <span class="ansi-green-fg">if</span> requester <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>history<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py</span> in <span class="ansi-cyan-fg">respond</span><span class="ansi-blue-fg">(self, value)</span>
<span class="ansi-green-intense-fg ansi-bold">    709</span>         self<span class="ansi-blue-fg">.</span>response_queue<span class="ansi-blue-fg">.</span>put<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    710</span>
<span class="ansi-green-fg">--&gt; 711</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>wait<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    712</span>
<span class="ansi-green-intense-fg ansi-bold">    713</span>     <span class="ansi-red-fg">### Requester Methods ###</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py</span> in <span class="ansi-cyan-fg">wait</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    467</span>         <span class="ansi-green-fg">while</span> self<span class="ansi-blue-fg">.</span>event_queue<span class="ansi-blue-fg">.</span>empty<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">and</span> self<span class="ansi-blue-fg">.</span>alive<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    468</span>             <span class="ansi-red-fg"># Keep checking until there&#39;s an event in the queue</span>
<span class="ansi-green-fg">--&gt; 469</span><span class="ansi-red-fg">             </span>time<span class="ansi-blue-fg">.</span>sleep<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0.001</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># Small sleep to prevent CPU spinning</span>
<span class="ansi-green-intense-fg ansi-bold">    470</span>
<span class="ansi-green-intense-fg ansi-bold">    471</span>     <span class="ansi-green-fg">def</span> cancel<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>:
</pre></div></div>
</div>
<p>Please note that <code class="docutils literal notranslate"><span class="pre">.save()</span></code> is still required for values that you plan to use outside of the tracing context.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

  <span class="n">l4</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

<span class="nb">print</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">l4</span><span class="p">)</span> <span class="c1"># will cause error as it is not saved so not defined outside of the tracing context.</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(tensor([[[ 0.6784, -1.4596,  0.8340,  ..., -0.8639,  0.0798, -1.6176],
         [-1.6008,  0.3668,  0.7506,  ..., -1.1595, -0.5517,  0.3558]]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;),)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-2062034499.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      6</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> print<span class="ansi-blue-fg">(</span>l1<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 8</span><span class="ansi-red-fg"> </span>print<span class="ansi-blue-fg">(</span>l4<span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># will cause error as it is not saved so not defined outside of the tracing context.</span>

<span class="ansi-red-fg">NameError</span>: name &#39;l4&#39; is not defined
</pre></div></div>
</div>
</section>
<section id="Stack-Traces">
<h2>Stack Traces<a class="headerlink" href="#Stack-Traces" title="Link to this heading">#</a></h2>
<p>With <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, exceptions are now significantly easier to understand and debug. We’ve rebuilt how tracebacks are handled at runtime, so when an error occurs during a trace, the exception now points directly to the line in your original code where it happened.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Intervention&quot;</span><span class="p">)</span>

  <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

  <span class="nb">print</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span>

  <span class="n">l2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

  <span class="n">l3</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

  <span class="c1"># this line will throw a NameError</span>
  <span class="n">l3</span> <span class="o">+</span> <span class="n">y</span>

<span class="nb">print</span><span class="p">(</span><span class="n">l3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Starting Intervention
(tensor([[[ 0.6784, -1.4596,  0.8340,  ..., -0.8639,  0.0798, -1.6176],
         [-1.6008,  0.3668,  0.7506,  ..., -1.1595, -0.5517,  0.3558]]],
       device=&#39;cuda:0&#39;, grad_fn=&lt;AddBackward0&gt;),)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NNsightException</span>                          Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-1522161483.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">with</span> model<span class="ansi-blue-fg">.</span>trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Hello World&#34;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>   print<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Starting Intervention&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>   l1 <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">.</span>transformer<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>output

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/tracing/base.py</span> in <span class="ansi-cyan-fg">__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">    414</span>
<span class="ansi-green-intense-fg ansi-bold">    415</span>             <span class="ansi-red-fg"># Execute the traced code using the configured backend</span>
<span class="ansi-green-fg">--&gt; 416</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>backend<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    417</span>
<span class="ansi-green-intense-fg ansi-bold">    418</span>             <span class="ansi-green-fg">return</span> <span class="ansi-green-fg">True</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/backends/execution.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, tracer)</span>
<span class="ansi-green-intense-fg ansi-bold">     22</span>         <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     23</span>
<span class="ansi-green-fg">---&gt; 24</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> wrap_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> tracer<span class="ansi-blue-fg">.</span>info<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">from</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>             Globals<span class="ansi-blue-fg">.</span>exit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NNsightException</span>:

Traceback (most recent call last):
  File &#34;/tmp/ipython-input-1522161483.py&#34;, line 14, in &lt;cell line: 0&gt;
    l3 + y

NameError: name &#39;y&#39; is not defined
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Wrong shape</span>
<span class="k">def</span><span class="w"> </span><span class="nf">add_noise</span><span class="p">(</span><span class="n">activation</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">activation</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">256</span><span class="p">))</span>


<span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">output</span>

  <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">add_noise</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NNsightException</span>                          Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-1804513616.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>
<span class="ansi-green-fg">----&gt; 6</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">with</span> model<span class="ansi-blue-fg">.</span>trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Hello World&#34;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span>   l1 <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">.</span>transformer<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>mlp<span class="ansi-blue-fg">.</span>output

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/tracing/base.py</span> in <span class="ansi-cyan-fg">__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">    414</span>
<span class="ansi-green-intense-fg ansi-bold">    415</span>             <span class="ansi-red-fg"># Execute the traced code using the configured backend</span>
<span class="ansi-green-fg">--&gt; 416</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>backend<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    417</span>
<span class="ansi-green-intense-fg ansi-bold">    418</span>             <span class="ansi-green-fg">return</span> <span class="ansi-green-fg">True</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/backends/execution.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, tracer)</span>
<span class="ansi-green-intense-fg ansi-bold">     22</span>         <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     23</span>
<span class="ansi-green-fg">---&gt; 24</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> wrap_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> tracer<span class="ansi-blue-fg">.</span>info<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">from</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>             Globals<span class="ansi-blue-fg">.</span>exit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NNsightException</span>:

Traceback (most recent call last):
  File &#34;/tmp/ipython-input-1804513616.py&#34;, line 15, in &lt;cell line: 0&gt;
    model.transformer.h[0].mlp.output = add_noise(l1)
  File &#34;/tmp/ipython-input-1804513616.py&#34;, line 3, in add_noise
    return activation + torch.rand((1,2,256))

RuntimeError: The size of tensor a (768) must match the size of tensor b (256) at non-singleton dimension 2
</pre></div></div>
</div>
</section>
<section id="Vestigial-NNsight-0.4-Artifacts">
<h2>Vestigial NNsight 0.4 Artifacts<a class="headerlink" href="#Vestigial-NNsight-0.4-Artifacts" title="Link to this heading">#</a></h2>
<p>The changes made within <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code> remove the need for prior NNsight-supported functions such as <code class="docutils literal notranslate"><span class="pre">nnsight.iter()</span></code> and <code class="docutils literal notranslate"><span class="pre">nnsight.cond()</span></code>.</p>
<p>With <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code> there is no need for the following:</p>
<ul class="simple">
<li><p>Instead of <code class="docutils literal notranslate"><span class="pre">nnsight.apply()</span></code>, directly use any function of your choosing.</p></li>
<li><p>Instead of <code class="docutils literal notranslate"><span class="pre">nnsight.cond()</span></code>, use <code class="docutils literal notranslate"><span class="pre">if</span></code>/<code class="docutils literal notranslate"><span class="pre">else</span></code> statements.</p></li>
<li><p>Instead of <code class="docutils literal notranslate"><span class="pre">nnsight.iter()</span></code>, use <code class="docutils literal notranslate"><span class="pre">for</span></code> loops (inline loops also work now!)</p></li>
<li><p>Instead of <code class="docutils literal notranslate"><span class="pre">nnsight.local()</span></code>, custom functions will work remotely (?) and stream to</p></li>
<li><p>Instead of <code class="docutils literal notranslate"><span class="pre">nnsight.log()</span></code>, use <code class="docutils literal notranslate"><span class="pre">print()</span></code>.</p></li>
<li><p>Instead of <code class="docutils literal notranslate"><span class="pre">nnsight.stop()</span></code>, use <code class="docutils literal notranslate"><span class="pre">breakpoint()</span></code>.</p></li>
</ul>
<p>Additionally, prior versions of NNsight used NNsight-traceable lists or dicts for iterating, which were created using <code class="docutils literal notranslate"><span class="pre">nnsight.list()</span></code> or <code class="docutils literal notranslate"><span class="pre">nnsight.dict()</span></code>. There is no need for the following, as the code is directly traceable:</p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.bool()</span></code> with <code class="docutils literal notranslate"><span class="pre">bool()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.bytearray()</span></code> with <code class="docutils literal notranslate"><span class="pre">bytearray()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.bytes()</span></code> with <code class="docutils literal notranslate"><span class="pre">bytes()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.complex()</span></code> with <code class="docutils literal notranslate"><span class="pre">complex()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.dict()</span></code> with <code class="docutils literal notranslate"><span class="pre">dict()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.float()</span></code> with <code class="docutils literal notranslate"><span class="pre">float()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.int()</span></code> with <code class="docutils literal notranslate"><span class="pre">int()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.list()</span></code> with <code class="docutils literal notranslate"><span class="pre">list()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.set()</span></code> with <code class="docutils literal notranslate"><span class="pre">set()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.str()</span></code> with <code class="docutils literal notranslate"><span class="pre">str()</span></code>.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">nnsight.tuple()</span></code> with <code class="docutils literal notranslate"><span class="pre">tuple()</span></code>.</p></li>
</ul>
<p>While we will still support these functions in <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, they will eventually be deprecated, so we recommend switching over to traditional Python syntax. For example, for conditional statements, use Python <code class="docutils literal notranslate"><span class="pre">if</span></code> blocks, and for iterations, use Python <code class="docutils literal notranslate"><span class="pre">for</span></code> loops.</p>
</section>
<section id="Memory-Management">
<h2>Memory Management<a class="headerlink" href="#Memory-Management" title="Link to this heading">#</a></h2>
<p>Previous versions of<code class="docutils literal notranslate"><span class="pre">NNsight</span></code> would automatically clean up intermediate variables once they were no longer used in your interventions. With <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, users are now in full control of memory management, as with standard Python.</p>
<p>When you reach the end of the tracing context, items that aren’t explicitly saved are deleted, so many of you will not need to worry about these changes. However, freeing up memory may be required during memory-intensive experiments, so these changes are important to be aware of, in case you run into memory issues.</p>
<p>Let’s explore how to remove an object from the memory within the tracing context:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">):</span>

  <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>

  <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">][:]</span> <span class="o">=</span> <span class="n">l1</span>

  <span class="c1"># done with l1, free the memory</span>
  <span class="k">del</span> <span class="n">l1</span>

  <span class="c1"># now grab layer two,</span>
  <span class="n">l2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>

<span class="c1"># Items that aren&#39;t explicitly saved during tracing context are deleted upon exit</span>
<span class="nb">print</span><span class="p">(</span><span class="n">l2</span><span class="p">)</span> <span class="c1"># should throw an error</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-3242155008.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     12</span>
<span class="ansi-green-intense-fg ansi-bold">     13</span> <span class="ansi-red-fg"># Items that aren&#39;t explicitly saved during tracing context are deleted upon exit</span>
<span class="ansi-green-fg">---&gt; 14</span><span class="ansi-red-fg"> </span>print<span class="ansi-blue-fg">(</span>l2<span class="ansi-blue-fg">)</span> <span class="ansi-red-fg"># should throw an error</span>

<span class="ansi-red-fg">NameError</span>: name &#39;l2&#39; is not defined
</pre></div></div>
</div>
</section>
</section>
<section id="Breaking-Changes">
<h1>Breaking Changes<a class="headerlink" href="#Breaking-Changes" title="Link to this heading">#</a></h1>
<p>Code written with previous versions of <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> will largely run using <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code> without any changes. However, there are a few breaking changes introduced in <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, including module execution order, cross-invoker behavior, and new syntax for backward passes.</p>
<section id="Enforcing-Order-with-Modules">
<h2>Enforcing Order with Modules<a class="headerlink" href="#Enforcing-Order-with-Modules" title="Link to this heading">#</a></h2>
<p>With <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, the exact order in which you interact with modules matters. Model layers must be accessed in the same order they are executed by the model.</p>
<p>This update helps make NNsight execution more understandable, removing prior ambiguity that could occur when modules were accessed out of order within the forward pass. Previously, modules accessed out of order resulted in a “silent error” where defined interventions could go unexecuted. Now, access of out-of-order modules within the tracing context will throw an explicit error.</p>
<!-- < better examples >

< reasoning why this is good "more understandable", "explicit error when trying to apply interventions that would effect the forward pass on modules that have already been excecuted" > --><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>
  <span class="c1"># Works</span>
  <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
  <span class="n">l2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="c1"># will throw an error because these module interactions are out of order</span>
  <span class="n">l2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
  <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

  <span class="c1"># in NNsight 0.4, no error would be thrown and you would be able to access l2 and l1</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NNsightException</span>                          Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-3053322419.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">with</span> model<span class="ansi-blue-fg">.</span>trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Hello World&#34;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>   <span class="ansi-red-fg"># will throw an error because these module interactions are out of order</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span>   l2 <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">.</span>transformer<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>output
<span class="ansi-green-intense-fg ansi-bold">      5</span>   l1 <span class="ansi-blue-fg">=</span> model<span class="ansi-blue-fg">.</span>transformer<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>output

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/tracing/base.py</span> in <span class="ansi-cyan-fg">__exit__</span><span class="ansi-blue-fg">(self, exc_type, exc_val, exc_tb)</span>
<span class="ansi-green-intense-fg ansi-bold">    414</span>
<span class="ansi-green-intense-fg ansi-bold">    415</span>             <span class="ansi-red-fg"># Execute the traced code using the configured backend</span>
<span class="ansi-green-fg">--&gt; 416</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>backend<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    417</span>
<span class="ansi-green-intense-fg ansi-bold">    418</span>             <span class="ansi-green-fg">return</span> <span class="ansi-green-fg">True</span>

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/backends/execution.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, tracer)</span>
<span class="ansi-green-intense-fg ansi-bold">     22</span>         <span class="ansi-green-fg">except</span> Exception <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     23</span>
<span class="ansi-green-fg">---&gt; 24</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> wrap_exception<span class="ansi-blue-fg">(</span>e<span class="ansi-blue-fg">,</span> tracer<span class="ansi-blue-fg">.</span>info<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">from</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>         <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>             Globals<span class="ansi-blue-fg">.</span>exit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NNsightException</span>:

Traceback (most recent call last):
  File &#34;/tmp/ipython-input-3053322419.py&#34;, line 6, in &lt;cell line: 0&gt;
    l1 = model.transformer.h[0].output
  File &#34;/usr/local/lib/python3.12/dist-packages/nnsight/intervention/envoy.py&#34;, line 152, in output
    return self._interleaver.current.request(
  File &#34;/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py&#34;, line 783, in request
    value = self.send(Events.VALUE, requester)
  File &#34;/usr/local/lib/python3.12/dist-packages/nnsight/intervention/interleaver.py&#34;, line 768, in send
    raise response

OutOfOrderError: Value was missed for model.transformer.h.0.output.i0. Did you call an Envoy out of order?
</pre></div></div>
</div>
</section>
<section id="New-Cross-Invoker-Behaviour">
<h2>New Cross Invoker Behaviour<a class="headerlink" href="#New-Cross-Invoker-Behaviour" title="Link to this heading">#</a></h2>
<p>With the redesign of <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, invokers are now run in parallel but Python code is still executed left to right. <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> no longer knows when operations can and cannot be executed, so when invokes reference variables from each other, the second invoke needs to run at a point when the variable is ready.</p>
<p>With 0.5, the invoker context, which defines the values of the <code class="docutils literal notranslate"><span class="pre">.input</span></code> and <code class="docutils literal notranslate"><span class="pre">.output</span></code> proxies is being updated. Now, we use <code class="docutils literal notranslate"><span class="pre">barrier()</span></code> to tell <code class="docutils literal notranslate"><span class="pre">NNsight</span></code> to wait for the variable to update them in both batches.</p>
<p>This breaking change will impact experiments that use techniques with multiple invokes, such as patching.</p>
<details><summary><p>Cross-invoke interventions prior to 0.5</p>
</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
  <span class="n">barrier</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

    <span class="c1"># captures the output</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">output</span>

  <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;.....&quot;</span><span class="p">):</span>

    <span class="c1"># save the captured output within the invoker context</span>
    <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span>
</pre></div>
</div>
</details><p>Cross-invoke interventions using <code class="docutils literal notranslate"><span class="pre">barrier</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
  <span class="c1"># define barrier</span>
  <span class="n">barrier</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">barrier</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

    <span class="c1"># capture output</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">output</span>

    <span class="c1">#call barrier after defining variable to be used across invokes</span>
    <span class="n">barrier</span><span class="p">()</span>
  <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;.....&quot;</span><span class="p">):</span>

    <span class="c1"># call barrier again before setting to the barrier variable in next invoke</span>
    <span class="n">barrier</span><span class="p">()</span>

    <span class="c1"># save the captured output within the invoker context</span>
    <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</section>
<section id="Syntax-Update:-.backward()">
<h2>Syntax Update: <code class="docutils literal notranslate"><span class="pre">.backward()</span></code><a class="headerlink" href="#Syntax-Update:-.backward()" title="Link to this heading">#</a></h2>
<p>As the the order of module interactions is enforced in <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, the use of <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> has also been updated. Now, you need to interact with the gradients in the opposite order that they were defined in the forward pass, reducing ambiguity.</p>
<p>Now, you can create a <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> context, within which you can access gradients. The old method of accessing gradients where you access grad then call <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> is deprecated in <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>.</p>
<!-- <cleanedup examples>
<must define your tensors from .input and .output before the backwards, then use .grad to interact within .backward>
<becuase ordcer is enforced, you need to interact with the .grads in the opposite order they were defined in the forward pass > --><details><summary><p>Backwards pass prior to 0.5</p>
</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Before:</span>
<span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span>

  <span class="c1"># access grad, then call .backward()</span>
  <span class="n">grad</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">grad</span>

  <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</details><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now in NNsight 0.5</span>
<span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="n">l1_mlp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">output</span>

  <span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span>

  <span class="c1"># new: .backward() syntax</span>
  <span class="k">with</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">():</span>
    <span class="c1"># access .grad within backward context</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">l1_mlp</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[[  9480.3643,   3383.6172, -10529.2354,  ..., -11482.9043,
            -515.9424,  -6655.7808],
         [  5285.5352, -13269.0781,   4607.1997,  ...,  31736.3555,
           24232.9277,  12392.3770]]], device=&#39;cuda:0&#39;)
</pre></div></div>
</div>
</section>
</section>
<section id="New-Features">
<h1>New Features<a class="headerlink" href="#New-Features" title="Link to this heading">#</a></h1>
<section id="Accessing-Intermediate-Values">
<h2>Accessing Intermediate Values<a class="headerlink" href="#Accessing-Intermediate-Values" title="Link to this heading">#</a></h2>
<p>Now we can access the intermediate vales of a forward pass! We print the <code class="docutils literal notranslate"><span class="pre">.source</span></code> of a module to see its forward pass and associated names of each operation. This allows for much easier access to attention within the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># .source to print the first transformer</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                                       * def forward(
                                       0     self,
                                       1     hidden_states: Optional[tuple[torch.FloatTensor]],
                                       2     past_key_value: Optional[Cache] = None,
                                       3     cache_position: Optional[torch.LongTensor] = None,
                                       4     attention_mask: Optional[torch.FloatTensor] = None,
                                       5     head_mask: Optional[torch.FloatTensor] = None,
                                       6     encoder_hidden_states: Optional[torch.Tensor] = None,
                                       7     encoder_attention_mask: Optional[torch.FloatTensor] = None,
                                       8     output_attentions: Optional[bool] = False,
                                       9     **kwargs,
                                      10 ) -&gt; tuple[Union[torch.Tensor, tuple[torch.Tensor]], ...]:
                                      11     is_cross_attention = encoder_hidden_states is not None
                                      12     if past_key_value is not None:
 isinstance_0                      -&gt; 13         if isinstance(past_key_value, EncoderDecoderCache):
 past_key_value_is_updated_get_0   -&gt; 14             is_updated = past_key_value.is_updated.get(self.layer_idx)
                                      15             if is_cross_attention:
                                      16                 # after the first generated id, we can subsequently re-use all key/value_layer from cache
                                      17                 curr_past_key_value = past_key_value.cross_attention_cache
                                      18             else:
                                      19                 curr_past_key_value = past_key_value.self_attention_cache
                                      20         else:
                                      21             curr_past_key_value = past_key_value
                                      22
                                      23     if is_cross_attention:
 hasattr_0                         -&gt; 24         if not hasattr(self, &#34;q_attn&#34;):
 ValueError_0                      -&gt; 25             raise ValueError(
                                      26                 &#34;If class is used as cross attention, the weights `q_attn` have to be defined. &#34;
                                      27                 &#34;Please make sure to instantiate class with `GPT2Attention(..., is_cross_attention=True)`.&#34;
                                      28             )
 self_q_attn_0                     -&gt; 29         query_states = self.q_attn(hidden_states)
                                      30         attention_mask = encoder_attention_mask
                                      31
                                      32         # Try to get key/value states from cache if possible
                                      33         if past_key_value is not None and is_updated:
                                      34             key_states = curr_past_key_value.layers[self.layer_idx].keys
                                      35             value_states = curr_past_key_value.layers[self.layer_idx].values
                                      36         else:
 self_c_attn_0                     -&gt; 37             key_states, value_states = self.c_attn(encoder_hidden_states).split(self.split_size, dim=2)
 split_0                           -&gt;  +             ...
                                      38             shape_kv = (*key_states.shape[:-1], -1, self.head_dim)
 key_states_view_0                 -&gt; 39             key_states = key_states.view(shape_kv).transpose(1, 2)
 transpose_0                       -&gt;  +             ...
 value_states_view_0               -&gt; 40             value_states = value_states.view(shape_kv).transpose(1, 2)
 transpose_1                       -&gt;  +             ...
                                      41     else:
 self_c_attn_1                     -&gt; 42         query_states, key_states, value_states = self.c_attn(hidden_states).split(self.split_size, dim=2)
 split_1                           -&gt;  +         ...
                                      43         shape_kv = (*key_states.shape[:-1], -1, self.head_dim)
 key_states_view_1                 -&gt; 44         key_states = key_states.view(shape_kv).transpose(1, 2)
 transpose_2                       -&gt;  +         ...
 value_states_view_1               -&gt; 45         value_states = value_states.view(shape_kv).transpose(1, 2)
 transpose_3                       -&gt;  +         ...
                                      46
                                      47     shape_q = (*query_states.shape[:-1], -1, self.head_dim)
 query_states_view_0               -&gt; 48     query_states = query_states.view(shape_q).transpose(1, 2)
 transpose_4                       -&gt;  +     ...
                                      49
                                      50     if (past_key_value is not None and not is_cross_attention) or (
                                      51         past_key_value is not None and is_cross_attention and not is_updated
                                      52     ):
                                      53         # save all key/value_layer to cache to be re-used for fast auto-regressive generation
                                      54         cache_position = cache_position if not is_cross_attention else None
 curr_past_key_value_update_0      -&gt; 55         key_states, value_states = curr_past_key_value.update(
                                      56             key_states, value_states, self.layer_idx, {&#34;cache_position&#34;: cache_position}
                                      57         )
                                      58         # set flag that curr layer for cross-attn is already updated so we can re-use in subsequent calls
                                      59         if is_cross_attention:
                                      60             past_key_value.is_updated[self.layer_idx] = True
                                      61
                                      62     is_causal = attention_mask is None and query_states.shape[-2] &gt; 1 and not is_cross_attention
                                      63
                                      64     using_eager = self.config._attn_implementation == &#34;eager&#34;
                                      65     attention_interface: Callable = eager_attention_forward
                                      66     if self.config._attn_implementation != &#34;eager&#34;:
                                      67         attention_interface = ALL_ATTENTION_FUNCTIONS[self.config._attn_implementation]
                                      68
                                      69     if using_eager and self.reorder_and_upcast_attn:
 self__upcast_and_reordered_attn_0 -&gt; 70         attn_output, attn_weights = self._upcast_and_reordered_attn(
                                      71             query_states, key_states, value_states, attention_mask, head_mask
                                      72         )
                                      73     else:
 attention_interface_0             -&gt; 74         attn_output, attn_weights = attention_interface(
                                      75             self,
                                      76             query_states,
                                      77             key_states,
                                      78             value_states,
                                      79             attention_mask,
                                      80             head_mask=head_mask,
                                      81             dropout=self.attn_dropout.p if self.training else 0.0,
                                      82             is_causal=is_causal,
                                      83             **kwargs,
                                      84         )
                                      85
 attn_output_reshape_0             -&gt; 86     attn_output = attn_output.reshape(*attn_output.shape[:-2], -1).contiguous()
 contiguous_0                      -&gt;  +     ...
 self_c_proj_0                     -&gt; 87     attn_output = self.c_proj(attn_output)
 self_resid_dropout_0              -&gt; 88     attn_output = self.resid_dropout(attn_output)
                                      89
                                      90     return attn_output, attn_weights
                                      91
</pre></div></div>
</div>
<p>Let’s try accessing attention within the first layer of the model. Here’s how we access the value:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="n">attention</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">source</span><span class="o">.</span><span class="n">attention_interface_0</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">attention</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(tensor([[[[ 1.6370e-01,  2.0417e-01, -4.3643e-02,  ...,  2.2550e-04,
           -9.9765e-02,  1.4590e-02],
          [ 3.1018e-01,  1.1781e-01, -8.8173e-02,  ..., -6.1718e-01,
           -4.0972e-01,  2.4498e-01],
          [ 2.1912e-01,  8.6628e-03,  7.3504e-02,  ...,  7.9072e-02,
           -4.7960e-02,  9.4133e-02],
          ...,
          [ 7.4412e-02,  2.3964e-02,  3.1744e-02,  ...,  3.1589e-03,
            1.5856e-01, -9.6892e-02],
          [ 9.3921e-02, -2.4730e-01, -7.8721e-02,  ...,  2.7543e-02,
            2.1350e-02,  2.5469e-02],
          [ 2.9328e-02, -2.9549e-01,  1.5860e-01,  ..., -5.7903e-02,
           -8.4012e-02,  7.8738e-02]],

         [[ 1.4663e-01,  2.0370e-01, -4.2141e-02,  ..., -1.3191e-02,
           -9.2443e-02,  2.3913e-02],
          [ 4.1437e-01, -4.5388e-02, -1.6687e-01,  ...,  6.9218e-02,
            2.7292e-01,  3.8467e-03],
          [ 1.9581e-01, -5.3822e-02,  3.7868e-02,  ...,  6.1278e-02,
           -1.1840e-02,  8.9837e-02],
          ...,
          [ 4.7415e-02,  6.6649e-02,  7.6959e-02,  ..., -2.5551e-02,
            1.1607e-01, -7.5544e-02],
          [-1.2834e-01, -1.5799e-01,  5.1572e-02,  ..., -3.5387e-02,
            3.9627e-02, -6.6449e-02],
          [ 3.7163e-02, -2.6126e-01,  1.3962e-01,  ..., -5.6581e-03,
           -3.0803e-02,  8.1926e-02]]]], device=&#39;cuda:0&#39;,
       grad_fn=&lt;TransposeBackward0&gt;), None)
</pre></div></div>
</div>
<p>This also works recursively, but it must happen inside a trace.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

  <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">source</span><span class="o">.</span><span class="n">attention_interface_0</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                                                        * def sdpa_attention_forward(
                                                        0     module: torch.nn.Module,
                                                        1     query: torch.Tensor,
                                                        2     key: torch.Tensor,
                                                        3     value: torch.Tensor,
                                                        4     attention_mask: Optional[torch.Tensor],
                                                        5     dropout: float = 0.0,
                                                        6     scaling: Optional[float] = None,
                                                        7     is_causal: Optional[bool] = None,
                                                        8     **kwargs,
                                                        9 ) -&gt; tuple[torch.Tensor, None]:
 kwargs_get_0                                       -&gt; 10     if kwargs.get(&#34;output_attentions&#34;, False) or kwargs.get(&#34;head_mask&#34;) is not None:
 kwargs_get_1                                       -&gt;  +     ...
 logger_warning_once_0                              -&gt; 11         logger.warning_once(
                                                       12             &#34;`sdpa` attention does not support `output_attentions=True` or `head_mask`.&#34;
                                                       13             &#34; Please set your attention to `eager` if you want any of these features.&#34;
                                                       14         )
                                                       15     sdpa_kwargs = {}
 hasattr_0                                          -&gt; 16     if hasattr(module, &#34;num_key_value_groups&#34;):
 use_gqa_in_sdpa_0                                  -&gt; 17         if not use_gqa_in_sdpa(attention_mask, key):
 repeat_kv_0                                        -&gt; 18             key = repeat_kv(key, module.num_key_value_groups)
 repeat_kv_1                                        -&gt; 19             value = repeat_kv(value, module.num_key_value_groups)
                                                       20         else:
                                                       21             sdpa_kwargs = {&#34;enable_gqa&#34;: True}
                                                       22
                                                       23     if attention_mask is not None and attention_mask.ndim == 4:
                                                       24         attention_mask = attention_mask[:, :, :, : key.shape[-2]]
                                                       25
                                                       26     # SDPA with memory-efficient backend is bugged with non-contiguous inputs and custom attn_mask for some torch versions
                                                       27     # Reference: https://github.com/pytorch/pytorch/issues/112577.
 query_contiguous_0                                 -&gt; 28     query = query.contiguous()
 key_contiguous_0                                   -&gt; 29     key = key.contiguous()
 value_contiguous_0                                 -&gt; 30     value = value.contiguous()
                                                       31
                                                       32     # We dispatch to SDPA&#39;s Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment
                                                       33     # in SDPA to support both torch.compile&#39;s dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.
                                                       34     # Note that it is important to check first for the shape, otherwise compile will fail with `argument &#39;is_causal&#39; must be bool, not SymBool`
                                                       35     if is_causal is None:
                                                       36         # The last condition is for encoder (decoder) models which specify this by passing their own `is_causal` flag
                                                       37         # This is mainly due to those models having mixed implementations for encoder, decoder, and encoder-decoder attns
 getattr_0                                          -&gt; 38         is_causal = query.shape[2] &gt; 1 and attention_mask is None and getattr(module, &#34;is_causal&#34;, True)
                                                       39
                                                       40     # Shapes (e.g. query.shape[2]) are tensors during jit tracing, resulting in `is_causal` being a tensor.
                                                       41     # We convert it to a bool for the SDPA kernel that only accepts bools.
 torch_jit_is_tracing_0                             -&gt; 42     if torch.jit.is_tracing() and isinstance(is_causal, torch.Tensor):
 isinstance_0                                       -&gt;  +     ...
 is_causal_item_0                                   -&gt; 43         is_causal = is_causal.item()
                                                       44
 torch_nn_functional_scaled_dot_product_attention_0 -&gt; 45     attn_output = torch.nn.functional.scaled_dot_product_attention(
                                                       46         query,
                                                       47         key,
                                                       48         value,
                                                       49         attn_mask=attention_mask,
                                                       50         dropout_p=dropout,
                                                       51         scale=scaling,
                                                       52         is_causal=is_causal,
                                                       53         **sdpa_kwargs,
                                                       54     )
 attn_output_transpose_0                            -&gt; 55     attn_output = attn_output.transpose(1, 2).contiguous()
 contiguous_0                                       -&gt;  +     ...
                                                       56
                                                       57     return attn_output, None
                                                       58
</pre></div></div>
</div>
</section>
<section id="Skipping-Modules">
<h2>Skipping Modules<a class="headerlink" href="#Skipping-Modules" title="Link to this heading">#</a></h2>
<p>Another new feature of <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code> is the ability to skip modules using <code class="docutils literal notranslate"><span class="pre">.skip()</span></code>! When using <code class="docutils literal notranslate"><span class="pre">.skip()</span></code>, you must pass the replacement output value as <code class="docutils literal notranslate"><span class="pre">.skip(replacement_output)</span></code>. It is up to users to format the <code class="docutils literal notranslate"><span class="pre">replacement_output</span></code> properly.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">):</span>

  <span class="c1"># skip layer 5 MLP and pass the output of the previous layer to the next module instead</span>
  <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

  <span class="n">skipped_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>


<span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;The Eiffel Tower is in the city of&quot;</span><span class="p">):</span>
  <span class="n">normal_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">skipped_output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">normal_output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([[[ -35.8570,  -34.5914,  -37.6956,  ...,  -40.3080,  -41.1341,
           -34.5359],
         [ -70.4781,  -71.8005,  -72.8090,  ...,  -81.7647,  -79.1500,
           -72.7596],
         [ -78.2885,  -78.1395,  -81.2576,  ...,  -89.0255,  -89.1816,
           -82.1576],
         ...,
         [-116.2076, -113.9161, -115.8417,  ..., -119.3681, -116.9304,
          -114.7280],
         [ -80.4201,  -82.0173,  -90.2717,  ...,  -92.4792,  -88.7321,
           -84.1283],
         [-110.7949, -109.5150, -112.4295,  ..., -118.8905, -117.8232,
          -110.1424]]], device=&#39;cuda:0&#39;, grad_fn=&lt;UnsafeViewBackward0&gt;)
tensor([[[ -36.2874,  -35.0114,  -38.0793,  ...,  -40.5163,  -41.3759,
           -34.9193],
         [ -68.8886,  -70.1562,  -71.8408,  ...,  -80.4195,  -78.2553,
           -71.1206],
         [ -82.2950,  -81.6519,  -83.9941,  ...,  -94.4878,  -94.5194,
           -85.6998],
         ...,
         [-113.8674, -111.8628, -113.6634,  ..., -116.7652, -114.8267,
          -112.3621],
         [ -81.8531,  -83.3006,  -91.8192,  ...,  -92.9943,  -89.8382,
           -85.6898],
         [-103.9307, -102.5054, -105.1563,  ..., -109.3099, -110.4196,
          -103.1395]]], device=&#39;cuda:0&#39;, grad_fn=&lt;UnsafeViewBackward0&gt;)
</pre></div></div>
</div>
<p>Let’s say we wanted to skip the execution of layers 2 through 6. We can keep passing the output of layer 1 as the replacement until we reach layer 6.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>
    <span class="n">replacement_output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">):</span>
        <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">replacement_output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If multiple invokers are defined, module skipping needs to be specified in every invoker and passed as a respective output.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>
        <span class="c1"># skipping layer 1</span>
        <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>
        <span class="c1"># skipping layer 1</span>
        <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">skip</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
You&#39;re using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
</pre></div></div>
</div>
</section>
<section id="Cache">
<h2>Cache<a class="headerlink" href="#Cache" title="Link to this heading">#</a></h2>
<p>NNsight’s new caching functionality allows you to collect activations during tracing in one line and returns to you a dictionary of values. The functionality will save all module outputs by default, but can also specify to include the inputs to modules. More customization is also available, read through the doc string.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;cache allows you to get a bunch of values with some nice features on top</span>
<span class="sd">Args:</span>
<span class="sd">            modules: Optional list of modules to cache, defaults to all modules</span>
<span class="sd">            device: Optional device to move tensors to, defaults to cpu</span>
<span class="sd">            dtype: Optional dtype to convert tensors to, defaults to None</span>
<span class="sd">            detach: Whether to detach tensors from computation graph, defaults to True</span>
<span class="sd">            include_output: Whether to include output in the cached activations, defaults to True</span>
<span class="sd">            include_inputs: Whether to include inputs in the cached activations, defaults to False</span>

<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>

    <span class="n">cache</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cache</span><span class="p">(</span><span class="n">modules</span><span class="o">=</span><span class="p">[</span><span class="n">layer</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">])</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">cache</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cache</span><span class="p">[</span><span class="s1">&#39;model.transformer.h.11&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
dict_keys([&#39;model.transformer.h.0&#39;, &#39;model.transformer.h.1&#39;, &#39;model.transformer.h.2&#39;, &#39;model.transformer.h.3&#39;, &#39;model.transformer.h.4&#39;, &#39;model.transformer.h.5&#39;, &#39;model.transformer.h.6&#39;, &#39;model.transformer.h.7&#39;, &#39;model.transformer.h.8&#39;, &#39;model.transformer.h.9&#39;, &#39;model.transformer.h.10&#39;, &#39;model.transformer.h.11&#39;])
(tensor([[[ 5.2162e-01, -1.1755e+00, -4.6167e-01,  2.1068e-01,  2.9469e-01,
          -8.1841e-01,  5.5645e+00, -2.6175e+00, -5.8669e-01,  3.0617e-01,
           4.4443e+00,  9.5316e-02, -2.4864e-01,  6.0082e-01,  9.7770e-02,
           9.1933e-01, -9.8456e-01, -1.5554e+00,  1.8531e+00,  8.1084e-01,
           2.2836e+00, -7.9386e-01, -1.2317e+00, -1.5536e+00,  5.0423e-01,
           1.6540e+00, -3.5063e-01, -2.3019e+00,  1.3319e+00, -1.2625e+00,
           1.3790e-01, -2.7795e-01,  6.9081e-01, -2.9856e+00,  7.5079e-03,
          -4.8894e-01,  1.8372e+01, -1.9638e-01,  1.3478e-02, -1.7833e-01,
           2.7951e-01,  8.7137e-01,  1.3290e+00, -2.7877e+00, -1.0839e-02,
           3.0076e+00, -1.8287e-01,  1.0125e+00, -1.1427e+00,  1.1938e+00,
           5.8188e-01,  1.9279e+00,  2.0645e-01, -2.4402e-01,  3.3774e-01,
           2.8449e+00,  2.2243e+00, -3.0783e-01, -1.5689e+00,  1.5047e+00,
           8.6321e-01, -7.5109e-01,  1.1323e+00, -1.9002e-02,  1.5842e+01,
          -5.0414e-01,  8.8845e-02, -1.4377e+00,  4.9624e-01, -1.1333e+00,
          -7.1319e-01, -2.0177e+00,  1.6678e-01, -7.5193e-01, -1.9751e-02,
          -6.8954e-01, -2.0199e+00, -1.0126e+00,  3.3806e-01, -6.1650e-01,
          -2.2603e+00, -2.5900e-01,  2.5679e-01, -2.1663e+00, -5.7628e-01,
           1.3239e+00, -2.8475e+00,  9.8014e+00,  1.3350e+00, -1.2831e+00,
           5.4790e-01, -9.6111e-01,  5.2135e-01,  3.0719e-01, -2.4017e+00,
          -3.7401e-01,  1.3598e+00,  7.7181e-01,  6.3770e-01,  1.3030e+00,
          -1.7832e+00,  1.7611e+00,  1.6578e+00, -1.4205e+00, -8.4969e-01,
           1.0026e+00, -3.2761e-01,  4.8069e+00, -6.8352e-01, -3.8437e-01,
          -1.8492e-01,  7.3896e-01, -2.0127e-03, -1.3310e-01, -4.5113e-01,
           1.0630e+00, -2.0396e+00,  1.4283e+00, -1.3002e-01,  1.3951e+00,
          -1.4393e+00,  1.6106e+00,  1.2286e+00,  2.5244e-01, -1.1214e+00,
          -5.2458e-01, -8.9988e-01,  3.7666e-01, -2.4119e+00,  1.1727e+00,
          -6.1718e-01,  1.8588e+00,  2.6828e+00, -1.9980e-01,  8.7779e-01,
          -6.5460e-01, -2.6798e-01, -7.3539e-01,  1.5540e+00,  1.0165e+00,
          -9.3544e-01,  2.1143e+00, -2.0666e+00,  6.2405e-01,  2.7430e+00,
           5.8804e-01,  1.7574e-01,  6.9997e-01,  9.5853e-03, -9.3914e-01,
           2.6646e-01, -4.2053e-01, -4.8762e-01,  8.1835e-01, -2.0555e+00,
           1.0194e+00, -5.9165e-01, -3.0367e+00,  1.5626e+00, -9.8737e-01,
           1.8697e+00, -3.2189e-01,  1.4337e+00,  4.7976e-01, -2.5208e+00,
           7.0738e-02, -3.1074e-01, -2.4451e+00,  2.5477e-01, -1.4101e+00,
          -8.4234e-03,  1.7607e-01, -1.0526e+00,  2.6906e+00, -3.5058e-01,
           7.4041e-01,  1.7684e+00, -8.7278e-01,  1.6470e+00,  1.7573e+00,
          -1.9212e+00, -5.5846e-01, -3.2160e-01, -1.1371e+00, -5.6253e-01,
          -1.4691e+00, -2.9134e-01, -9.0656e-01,  1.4227e-01, -1.8432e-01,
          -8.0872e-01,  3.9542e-01, -1.2004e+00, -1.1700e-01, -1.2184e+00,
          -3.7953e-01,  9.2969e-01, -1.9162e+00, -1.3129e-01, -1.1224e+00,
          -1.0592e+00,  2.4055e+00, -2.0483e+00,  3.8437e-01, -4.9299e-01,
          -7.8528e-01, -1.4968e+00, -8.4001e-01, -3.2779e-02, -2.2589e-01,
           2.6156e+00,  1.4892e+00, -7.2725e-01, -4.6028e-01, -1.1144e+00,
           5.2195e-01, -2.0158e+00, -1.6432e+00, -1.3200e+00, -9.5822e-01,
           4.3253e-02,  1.1098e-01, -2.5565e-01, -7.2781e-01, -3.7242e-01,
           9.3814e-01, -1.8115e-01,  8.4659e-01,  3.3158e-01, -1.2038e+00,
           1.7593e+00,  5.3261e-01,  4.0609e+00,  4.3891e-02,  8.8552e-01,
          -1.6423e+00, -1.3854e+00, -3.6921e-01, -6.6414e-02, -5.3865e-01,
           2.1742e+00,  1.2829e+00,  2.5499e+00, -7.3002e-01, -4.1940e-01,
          -9.0079e-01, -8.7144e-01,  4.0812e-01,  2.7208e-01,  1.2028e+00,
           4.7178e-01, -1.7118e+00, -2.7384e-01,  8.6907e-01, -1.4595e+00,
           1.0502e+00,  1.7648e+00,  8.3544e-01,  1.2442e+00,  5.2319e-01,
           1.1293e+00,  6.2889e-01, -4.6979e-01,  6.3392e-01, -5.6969e-01,
          -5.4770e-01,  1.2989e+01, -4.0900e-03, -1.5296e+00,  2.3416e+00,
          -2.3869e-01,  1.8565e+00, -5.2766e-01,  5.6889e-01, -8.5407e-01,
           8.1061e-01,  1.6875e+00,  1.4550e+00, -5.3384e-01,  4.7004e-01,
           7.4083e-01, -1.8005e+00,  8.7805e-01, -8.2363e-01,  2.6488e+00,
          -1.7942e+00, -1.3637e+00, -5.0910e-01,  1.5337e+00, -1.4277e+00,
          -2.6067e-01, -5.3024e-01, -1.6535e+00,  9.2208e-02,  3.1362e-01,
          -3.9567e-02, -2.4784e-01, -1.0204e+00,  4.1693e-01, -2.0851e-01,
           6.1203e-01, -1.7849e-01,  1.8587e+00,  6.7422e-01,  2.3710e-02,
          -1.5097e+00,  2.2662e+00,  1.1053e+00,  9.1452e-01, -9.6997e-01,
          -2.8617e-01,  2.9623e+00, -1.3407e+00, -3.2086e-01,  5.1643e-01,
          -1.6070e+00, -1.5850e+00,  1.0647e+00, -1.1784e-01,  9.2111e-01,
           1.1593e+00, -1.9622e+00, -1.6188e+00, -1.8868e-01,  1.8029e+00,
           1.9497e+00,  7.2542e+00,  6.6349e-02,  1.1183e+00, -1.9206e+00,
          -2.4414e+00, -1.0822e+00,  6.4853e-01,  7.7359e-01,  2.2349e+00,
          -1.7997e+00,  7.8538e-01, -1.0740e+00, -7.9321e-01,  3.7208e-01,
          -6.7669e-02,  4.8284e-01, -2.8387e+00, -1.1935e+00, -8.0699e-02,
           1.8609e+00,  1.6182e-01, -3.8376e+00,  2.0256e+00,  2.0258e-01,
          -1.5530e+00,  1.2271e+00,  2.1142e+00, -1.2811e+00,  1.0942e+00,
          -4.2454e-01, -1.4079e+00, -7.8358e-01,  1.5096e+00, -3.8723e-01,
          -1.6061e+00, -1.1261e+00, -1.9825e+00, -2.5225e+00, -1.6321e+00,
          -2.9513e+00,  1.1196e-01,  4.9209e-01,  2.0495e+00,  1.4253e-01,
           1.6070e+00,  1.3692e+00,  5.9775e-01,  3.4555e+01, -6.4108e+00,
          -5.8437e-01,  7.2048e-02,  2.9191e+00, -6.4520e+00,  1.1640e+00,
          -5.8480e-01,  1.0187e+00,  8.1265e-01,  4.2243e-01, -2.2759e+00,
           1.0355e+00,  1.1991e+00,  5.3947e-01,  5.8532e-01, -2.0846e+00,
           4.6016e-01, -1.7242e-01,  1.6848e+00,  3.1179e-01, -1.4961e+00,
           1.2063e+00, -1.4058e+00, -1.1028e+00, -1.0559e-02,  5.5113e-01,
          -2.8866e-01, -1.5825e-01, -6.5445e-01,  1.4216e-01, -1.1572e+00,
           6.5913e-01, -5.6507e-01, -1.9988e+00, -2.8601e-01,  5.9450e-01,
          -4.0409e+00,  1.4472e+00, -1.3666e+00, -2.6870e+00, -1.5949e+00,
          -3.0164e-01,  1.1542e-01,  6.3676e-01,  1.5404e+00,  5.2768e-02,
          -3.3825e-01,  3.2540e-01,  2.6516e+00, -7.9525e-02, -6.3622e-01,
          -1.1853e-01, -1.9573e+00, -6.3031e-01, -7.0228e-02, -1.8263e+00,
           3.1315e+01, -1.1616e+00,  1.3860e+00,  7.6426e-01, -9.3801e-01,
           1.8295e+00, -1.6252e+00, -1.7850e+00, -5.2103e-01,  3.0260e-01,
          -9.6244e-02,  1.2258e-01,  7.7442e-01, -5.2875e-01,  1.9592e+00,
          -6.9340e-01, -3.6594e-02,  3.5920e+02, -1.4750e+00,  1.2106e+00,
          -9.8215e-01,  7.1432e-01,  5.5558e-01, -1.8206e+00, -5.9757e-01,
          -2.0526e+00, -8.9099e-01, -4.0860e-02,  6.7204e-04, -2.6179e+00,
           1.5422e+00,  4.9755e-01,  9.1992e-01, -3.6469e-01, -5.1798e-01,
          -1.7764e+00,  6.3068e-01, -4.8975e-01, -1.7913e+00, -7.2877e-01,
           7.4281e-01, -8.7697e-01, -3.7852e-01, -5.8061e-02, -7.4269e-01,
          -1.1344e+00,  1.1980e+00, -1.3790e-01, -2.3906e+00, -6.2684e-01,
           8.3057e+00, -2.6034e+01, -1.4518e+00,  1.3676e+00,  4.1647e-01,
           2.7969e-01,  1.9012e+00, -2.1780e-01, -2.6511e-01, -1.0906e+00,
           4.2591e-01,  1.5887e+00, -2.6241e+00,  1.3459e-02, -3.3975e-01,
           3.0270e-01,  3.7266e+01, -1.0572e+00,  9.9809e-01,  3.8319e-01,
           5.0095e-01, -1.0919e+00, -8.2203e-02, -1.9933e+00,  8.9136e-01,
          -1.4037e+00,  8.1453e-01,  2.2758e+00,  3.5162e-01,  1.4883e+00,
           4.9556e-01, -3.7500e-01,  2.0090e-01, -1.9267e+00, -6.3544e-01,
          -1.0089e+00, -1.0631e-01, -1.7096e+00, -5.4951e-01, -8.5848e-01,
          -7.8844e-01, -1.1477e+00, -7.9289e-01, -4.7290e-01,  1.5762e+00,
           2.3286e-01, -3.7085e+00, -3.4445e+00, -2.3869e+00, -3.7213e-02,
          -8.1302e-01, -1.0105e-01,  1.8670e-01, -9.5102e-02, -1.8785e-01,
          -4.2293e-01,  2.9806e-01, -1.0091e+00,  5.3771e-01, -6.6245e-01,
           1.3376e+00, -2.9570e+00,  1.3539e+00,  5.9682e-01, -1.6712e+00,
          -1.2580e+00, -1.3087e+00, -4.0089e-01,  1.9866e-01, -1.6852e+00,
           2.2126e-01,  6.2141e-01,  6.7915e-01, -5.3487e-01, -3.4278e+00,
          -4.7162e-01,  7.8166e-01,  1.3067e+00, -1.4453e+00, -1.9147e+00,
          -3.9016e-01, -1.6709e-01, -1.0692e+00,  5.2615e-01, -4.5157e-01,
          -5.2235e-01,  1.5231e-01, -2.2187e+00, -1.2282e+00, -2.3102e+00,
          -2.7544e+00,  9.7331e-01,  8.8277e-01, -7.1570e-01, -4.1908e-01,
           8.8754e-01,  6.1995e-01, -2.2913e-01, -2.3520e+00,  1.5845e+00,
           7.6593e-01, -2.8480e-01,  7.8932e-01,  5.5034e-01, -1.3632e+00,
           2.5818e+00,  8.9867e-02, -1.1566e+00,  1.0411e+00,  2.2730e+00,
           2.1031e+00,  4.2044e-01,  4.5523e-02, -1.1822e+00,  7.1408e-01,
          -4.6120e-01, -9.7785e-01,  5.8227e-01,  3.8231e-01,  1.6005e-02,
          -2.4237e-01, -2.4043e-01, -5.5243e-01, -6.8880e-01,  6.6347e-01,
           6.9083e-01, -2.8412e-01,  2.1634e+00, -2.2180e+00,  2.8574e+00,
           1.1986e+00,  2.4508e-01, -1.0806e+00,  7.1033e-02, -2.3929e+00,
          -5.3587e-01, -2.0950e+00, -8.3449e-01,  8.5021e-01, -1.2418e+00,
          -4.0465e-01,  7.0758e-01,  9.1981e-01, -7.8714e-01,  2.1276e-02,
           1.2068e+00, -1.8398e+00, -1.9259e+00,  1.0109e+00, -2.2235e+00,
           1.0607e+00, -1.4097e+00, -1.9531e-01, -8.3341e-01,  3.0622e-01,
          -1.7141e+00, -3.0956e+00,  1.0763e+00, -2.5910e+00,  2.3487e+00,
           1.0763e+00,  2.1546e+00, -2.2089e+00, -6.6214e-01, -7.5825e-02,
           8.2714e-02, -1.2740e+00, -3.9954e+00,  1.1659e-01,  3.0871e+00,
           1.6959e+00,  6.5871e-01,  1.0491e+00,  2.0759e-01,  8.3224e-01,
           3.2985e-01,  9.8359e-01,  1.8074e+00, -4.9143e-01,  2.4604e+00,
           5.5376e-01, -2.3288e-01, -1.1235e+00, -1.7670e-03,  4.3698e-02,
           2.1547e+00, -8.9628e-01, -7.0047e-01,  6.0602e-01,  5.9772e-01,
           3.8079e-01,  4.1458e-01, -6.3141e-01,  6.3436e-01, -3.9720e+00,
           9.9400e-01, -7.1190e-01, -2.4037e+00,  5.5247e-01,  2.0214e+00,
          -2.2057e+00,  1.3341e+00, -2.4518e-01,  2.5012e+00, -9.5553e-01,
          -7.1156e-01, -1.3608e+00,  1.1349e+00,  1.5929e+00,  1.6206e-01,
          -6.5363e-01,  1.8884e+00,  3.1799e-01,  1.6230e+00, -1.8998e-01,
           8.3516e-01,  2.6151e+00, -6.3245e-01,  1.0846e+00, -3.5085e-01,
           8.8083e-01, -4.7369e-01,  1.3904e-01, -4.6477e+00, -1.1650e+00,
          -9.5942e-01, -5.3974e-01, -1.1033e+00, -2.4459e+00,  4.2318e+00,
           3.6722e-01, -8.0066e-01, -2.2627e+00, -1.3228e+00, -1.7302e+00,
          -7.4916e-01, -1.9744e+00, -9.6115e-01, -4.3247e-01,  2.8402e-01,
          -1.1384e-01,  1.8387e+00,  1.4803e+00, -1.4242e+00,  8.2505e-01,
          -3.7829e-01,  1.2134e+00, -4.2631e-01,  1.1886e+00,  6.0572e-01,
           1.2001e-01, -1.4911e+00, -2.3198e+00, -1.1939e+00, -5.0289e-01,
           1.5413e+00,  2.1577e+00,  4.0063e-01, -1.8040e+00,  2.3726e+00,
          -1.2916e+00, -6.8357e-01, -5.3062e-01, -1.3877e+00, -1.4345e+00,
          -5.7733e+00, -2.7524e+00, -7.1469e-01, -1.7234e+00, -1.5938e+00,
           3.9268e-01, -1.4293e-01,  1.3666e+00, -1.2487e+00,  2.1339e-01,
           5.7732e-01, -4.4817e+00, -3.7651e-01, -9.7787e-01,  1.6542e+00,
          -1.4578e-02,  3.4764e-01,  1.7497e+00, -1.0848e+00, -3.8392e-02,
          -1.1919e+00,  2.0391e-02, -2.0075e+00]]]),)
</pre></div></div>
</div>
<p>The cache obejct is a dictionary and can be manipulated that way by accessing items in the of form <code class="docutils literal notranslate"><span class="pre">cache[&quot;module_path&quot;]</span></code>. The you can call <code class="docutils literal notranslate"><span class="pre">.inputs</span></code>, <code class="docutils literal notranslate"><span class="pre">.input</span></code> and <code class="docutils literal notranslate"><span class="pre">.output</span></code> to access the value in the CacheEntry of the module specified.</p>
<p>Alternatively, you can also attribute access the cache object, e.g.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cache</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">11</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(tensor([[[ 5.2162e-01, -1.1755e+00, -4.6167e-01,  2.1068e-01,  2.9469e-01,
           -8.1841e-01,  5.5645e+00, -2.6175e+00, -5.8669e-01,  3.0617e-01,
            4.4443e+00,  9.5316e-02, -2.4864e-01,  6.0082e-01,  9.7770e-02,
            9.1933e-01, -9.8456e-01, -1.5554e+00,  1.8531e+00,  8.1084e-01,
            2.2836e+00, -7.9386e-01, -1.2317e+00, -1.5536e+00,  5.0423e-01,
            1.6540e+00, -3.5063e-01, -2.3019e+00,  1.3319e+00, -1.2625e+00,
            1.3790e-01, -2.7795e-01,  6.9081e-01, -2.9856e+00,  7.5079e-03,
           -4.8894e-01,  1.8372e+01, -1.9638e-01,  1.3478e-02, -1.7833e-01,
            2.7951e-01,  8.7137e-01,  1.3290e+00, -2.7877e+00, -1.0839e-02,
            3.0076e+00, -1.8287e-01,  1.0125e+00, -1.1427e+00,  1.1938e+00,
            5.8188e-01,  1.9279e+00,  2.0645e-01, -2.4402e-01,  3.3774e-01,
            2.8449e+00,  2.2243e+00, -3.0783e-01, -1.5689e+00,  1.5047e+00,
            8.6321e-01, -7.5109e-01,  1.1323e+00, -1.9002e-02,  1.5842e+01,
           -5.0414e-01,  8.8845e-02, -1.4377e+00,  4.9624e-01, -1.1333e+00,
           -7.1319e-01, -2.0177e+00,  1.6678e-01, -7.5193e-01, -1.9751e-02,
           -6.8954e-01, -2.0199e+00, -1.0126e+00,  3.3806e-01, -6.1650e-01,
           -2.2603e+00, -2.5900e-01,  2.5679e-01, -2.1663e+00, -5.7628e-01,
            1.3239e+00, -2.8475e+00,  9.8014e+00,  1.3350e+00, -1.2831e+00,
            5.4790e-01, -9.6111e-01,  5.2135e-01,  3.0719e-01, -2.4017e+00,
           -3.7401e-01,  1.3598e+00,  7.7181e-01,  6.3770e-01,  1.3030e+00,
           -1.7832e+00,  1.7611e+00,  1.6578e+00, -1.4205e+00, -8.4969e-01,
            1.0026e+00, -3.2761e-01,  4.8069e+00, -6.8352e-01, -3.8437e-01,
           -1.8492e-01,  7.3896e-01, -2.0127e-03, -1.3310e-01, -4.5113e-01,
            1.0630e+00, -2.0396e+00,  1.4283e+00, -1.3002e-01,  1.3951e+00,
           -1.4393e+00,  1.6106e+00,  1.2286e+00,  2.5244e-01, -1.1214e+00,
           -5.2458e-01, -8.9988e-01,  3.7666e-01, -2.4119e+00,  1.1727e+00,
           -6.1718e-01,  1.8588e+00,  2.6828e+00, -1.9980e-01,  8.7779e-01,
           -6.5460e-01, -2.6798e-01, -7.3539e-01,  1.5540e+00,  1.0165e+00,
           -9.3544e-01,  2.1143e+00, -2.0666e+00,  6.2405e-01,  2.7430e+00,
            5.8804e-01,  1.7574e-01,  6.9997e-01,  9.5853e-03, -9.3914e-01,
            2.6646e-01, -4.2053e-01, -4.8762e-01,  8.1835e-01, -2.0555e+00,
            1.0194e+00, -5.9165e-01, -3.0367e+00,  1.5626e+00, -9.8737e-01,
            1.8697e+00, -3.2189e-01,  1.4337e+00,  4.7976e-01, -2.5208e+00,
            7.0738e-02, -3.1074e-01, -2.4451e+00,  2.5477e-01, -1.4101e+00,
           -8.4234e-03,  1.7607e-01, -1.0526e+00,  2.6906e+00, -3.5058e-01,
            7.4041e-01,  1.7684e+00, -8.7278e-01,  1.6470e+00,  1.7573e+00,
           -1.9212e+00, -5.5846e-01, -3.2160e-01, -1.1371e+00, -5.6253e-01,
           -1.4691e+00, -2.9134e-01, -9.0656e-01,  1.4227e-01, -1.8432e-01,
           -8.0872e-01,  3.9542e-01, -1.2004e+00, -1.1700e-01, -1.2184e+00,
           -3.7953e-01,  9.2969e-01, -1.9162e+00, -1.3129e-01, -1.1224e+00,
           -1.0592e+00,  2.4055e+00, -2.0483e+00,  3.8437e-01, -4.9299e-01,
           -7.8528e-01, -1.4968e+00, -8.4001e-01, -3.2779e-02, -2.2589e-01,
            2.6156e+00,  1.4892e+00, -7.2725e-01, -4.6028e-01, -1.1144e+00,
            5.2195e-01, -2.0158e+00, -1.6432e+00, -1.3200e+00, -9.5822e-01,
            4.3253e-02,  1.1098e-01, -2.5565e-01, -7.2781e-01, -3.7242e-01,
            9.3814e-01, -1.8115e-01,  8.4659e-01,  3.3158e-01, -1.2038e+00,
            1.7593e+00,  5.3261e-01,  4.0609e+00,  4.3891e-02,  8.8552e-01,
           -1.6423e+00, -1.3854e+00, -3.6921e-01, -6.6414e-02, -5.3865e-01,
            2.1742e+00,  1.2829e+00,  2.5499e+00, -7.3002e-01, -4.1940e-01,
           -9.0079e-01, -8.7144e-01,  4.0812e-01,  2.7208e-01,  1.2028e+00,
            4.7178e-01, -1.7118e+00, -2.7384e-01,  8.6907e-01, -1.4595e+00,
            1.0502e+00,  1.7648e+00,  8.3544e-01,  1.2442e+00,  5.2319e-01,
            1.1293e+00,  6.2889e-01, -4.6979e-01,  6.3392e-01, -5.6969e-01,
           -5.4770e-01,  1.2989e+01, -4.0900e-03, -1.5296e+00,  2.3416e+00,
           -2.3869e-01,  1.8565e+00, -5.2766e-01,  5.6889e-01, -8.5407e-01,
            8.1061e-01,  1.6875e+00,  1.4550e+00, -5.3384e-01,  4.7004e-01,
            7.4083e-01, -1.8005e+00,  8.7805e-01, -8.2363e-01,  2.6488e+00,
           -1.7942e+00, -1.3637e+00, -5.0910e-01,  1.5337e+00, -1.4277e+00,
           -2.6067e-01, -5.3024e-01, -1.6535e+00,  9.2208e-02,  3.1362e-01,
           -3.9567e-02, -2.4784e-01, -1.0204e+00,  4.1693e-01, -2.0851e-01,
            6.1203e-01, -1.7849e-01,  1.8587e+00,  6.7422e-01,  2.3710e-02,
           -1.5097e+00,  2.2662e+00,  1.1053e+00,  9.1452e-01, -9.6997e-01,
           -2.8617e-01,  2.9623e+00, -1.3407e+00, -3.2086e-01,  5.1643e-01,
           -1.6070e+00, -1.5850e+00,  1.0647e+00, -1.1784e-01,  9.2111e-01,
            1.1593e+00, -1.9622e+00, -1.6188e+00, -1.8868e-01,  1.8029e+00,
            1.9497e+00,  7.2542e+00,  6.6349e-02,  1.1183e+00, -1.9206e+00,
           -2.4414e+00, -1.0822e+00,  6.4853e-01,  7.7359e-01,  2.2349e+00,
           -1.7997e+00,  7.8538e-01, -1.0740e+00, -7.9321e-01,  3.7208e-01,
           -6.7669e-02,  4.8284e-01, -2.8387e+00, -1.1935e+00, -8.0699e-02,
            1.8609e+00,  1.6182e-01, -3.8376e+00,  2.0256e+00,  2.0258e-01,
           -1.5530e+00,  1.2271e+00,  2.1142e+00, -1.2811e+00,  1.0942e+00,
           -4.2454e-01, -1.4079e+00, -7.8358e-01,  1.5096e+00, -3.8723e-01,
           -1.6061e+00, -1.1261e+00, -1.9825e+00, -2.5225e+00, -1.6321e+00,
           -2.9513e+00,  1.1196e-01,  4.9209e-01,  2.0495e+00,  1.4253e-01,
            1.6070e+00,  1.3692e+00,  5.9775e-01,  3.4555e+01, -6.4108e+00,
           -5.8437e-01,  7.2048e-02,  2.9191e+00, -6.4520e+00,  1.1640e+00,
           -5.8480e-01,  1.0187e+00,  8.1265e-01,  4.2243e-01, -2.2759e+00,
            1.0355e+00,  1.1991e+00,  5.3947e-01,  5.8532e-01, -2.0846e+00,
            4.6016e-01, -1.7242e-01,  1.6848e+00,  3.1179e-01, -1.4961e+00,
            1.2063e+00, -1.4058e+00, -1.1028e+00, -1.0559e-02,  5.5113e-01,
           -2.8866e-01, -1.5825e-01, -6.5445e-01,  1.4216e-01, -1.1572e+00,
            6.5913e-01, -5.6507e-01, -1.9988e+00, -2.8601e-01,  5.9450e-01,
           -4.0409e+00,  1.4472e+00, -1.3666e+00, -2.6870e+00, -1.5949e+00,
           -3.0164e-01,  1.1542e-01,  6.3676e-01,  1.5404e+00,  5.2768e-02,
           -3.3825e-01,  3.2540e-01,  2.6516e+00, -7.9525e-02, -6.3622e-01,
           -1.1853e-01, -1.9573e+00, -6.3031e-01, -7.0228e-02, -1.8263e+00,
            3.1315e+01, -1.1616e+00,  1.3860e+00,  7.6426e-01, -9.3801e-01,
            1.8295e+00, -1.6252e+00, -1.7850e+00, -5.2103e-01,  3.0260e-01,
           -9.6244e-02,  1.2258e-01,  7.7442e-01, -5.2875e-01,  1.9592e+00,
           -6.9340e-01, -3.6594e-02,  3.5920e+02, -1.4750e+00,  1.2106e+00,
           -9.8215e-01,  7.1432e-01,  5.5558e-01, -1.8206e+00, -5.9757e-01,
           -2.0526e+00, -8.9099e-01, -4.0860e-02,  6.7204e-04, -2.6179e+00,
            1.5422e+00,  4.9755e-01,  9.1992e-01, -3.6469e-01, -5.1798e-01,
           -1.7764e+00,  6.3068e-01, -4.8975e-01, -1.7913e+00, -7.2877e-01,
            7.4281e-01, -8.7697e-01, -3.7852e-01, -5.8061e-02, -7.4269e-01,
           -1.1344e+00,  1.1980e+00, -1.3790e-01, -2.3906e+00, -6.2684e-01,
            8.3057e+00, -2.6034e+01, -1.4518e+00,  1.3676e+00,  4.1647e-01,
            2.7969e-01,  1.9012e+00, -2.1780e-01, -2.6511e-01, -1.0906e+00,
            4.2591e-01,  1.5887e+00, -2.6241e+00,  1.3459e-02, -3.3975e-01,
            3.0270e-01,  3.7266e+01, -1.0572e+00,  9.9809e-01,  3.8319e-01,
            5.0095e-01, -1.0919e+00, -8.2203e-02, -1.9933e+00,  8.9136e-01,
           -1.4037e+00,  8.1453e-01,  2.2758e+00,  3.5162e-01,  1.4883e+00,
            4.9556e-01, -3.7500e-01,  2.0090e-01, -1.9267e+00, -6.3544e-01,
           -1.0089e+00, -1.0631e-01, -1.7096e+00, -5.4951e-01, -8.5848e-01,
           -7.8844e-01, -1.1477e+00, -7.9289e-01, -4.7290e-01,  1.5762e+00,
            2.3286e-01, -3.7085e+00, -3.4445e+00, -2.3869e+00, -3.7213e-02,
           -8.1302e-01, -1.0105e-01,  1.8670e-01, -9.5102e-02, -1.8785e-01,
           -4.2293e-01,  2.9806e-01, -1.0091e+00,  5.3771e-01, -6.6245e-01,
            1.3376e+00, -2.9570e+00,  1.3539e+00,  5.9682e-01, -1.6712e+00,
           -1.2580e+00, -1.3087e+00, -4.0089e-01,  1.9866e-01, -1.6852e+00,
            2.2126e-01,  6.2141e-01,  6.7915e-01, -5.3487e-01, -3.4278e+00,
           -4.7162e-01,  7.8166e-01,  1.3067e+00, -1.4453e+00, -1.9147e+00,
           -3.9016e-01, -1.6709e-01, -1.0692e+00,  5.2615e-01, -4.5157e-01,
           -5.2235e-01,  1.5231e-01, -2.2187e+00, -1.2282e+00, -2.3102e+00,
           -2.7544e+00,  9.7331e-01,  8.8277e-01, -7.1570e-01, -4.1908e-01,
            8.8754e-01,  6.1995e-01, -2.2913e-01, -2.3520e+00,  1.5845e+00,
            7.6593e-01, -2.8480e-01,  7.8932e-01,  5.5034e-01, -1.3632e+00,
            2.5818e+00,  8.9867e-02, -1.1566e+00,  1.0411e+00,  2.2730e+00,
            2.1031e+00,  4.2044e-01,  4.5523e-02, -1.1822e+00,  7.1408e-01,
           -4.6120e-01, -9.7785e-01,  5.8227e-01,  3.8231e-01,  1.6005e-02,
           -2.4237e-01, -2.4043e-01, -5.5243e-01, -6.8880e-01,  6.6347e-01,
            6.9083e-01, -2.8412e-01,  2.1634e+00, -2.2180e+00,  2.8574e+00,
            1.1986e+00,  2.4508e-01, -1.0806e+00,  7.1033e-02, -2.3929e+00,
           -5.3587e-01, -2.0950e+00, -8.3449e-01,  8.5021e-01, -1.2418e+00,
           -4.0465e-01,  7.0758e-01,  9.1981e-01, -7.8714e-01,  2.1276e-02,
            1.2068e+00, -1.8398e+00, -1.9259e+00,  1.0109e+00, -2.2235e+00,
            1.0607e+00, -1.4097e+00, -1.9531e-01, -8.3341e-01,  3.0622e-01,
           -1.7141e+00, -3.0956e+00,  1.0763e+00, -2.5910e+00,  2.3487e+00,
            1.0763e+00,  2.1546e+00, -2.2089e+00, -6.6214e-01, -7.5825e-02,
            8.2714e-02, -1.2740e+00, -3.9954e+00,  1.1659e-01,  3.0871e+00,
            1.6959e+00,  6.5871e-01,  1.0491e+00,  2.0759e-01,  8.3224e-01,
            3.2985e-01,  9.8359e-01,  1.8074e+00, -4.9143e-01,  2.4604e+00,
            5.5376e-01, -2.3288e-01, -1.1235e+00, -1.7670e-03,  4.3698e-02,
            2.1547e+00, -8.9628e-01, -7.0047e-01,  6.0602e-01,  5.9772e-01,
            3.8079e-01,  4.1458e-01, -6.3141e-01,  6.3436e-01, -3.9720e+00,
            9.9400e-01, -7.1190e-01, -2.4037e+00,  5.5247e-01,  2.0214e+00,
           -2.2057e+00,  1.3341e+00, -2.4518e-01,  2.5012e+00, -9.5553e-01,
           -7.1156e-01, -1.3608e+00,  1.1349e+00,  1.5929e+00,  1.6206e-01,
           -6.5363e-01,  1.8884e+00,  3.1799e-01,  1.6230e+00, -1.8998e-01,
            8.3516e-01,  2.6151e+00, -6.3245e-01,  1.0846e+00, -3.5085e-01,
            8.8083e-01, -4.7369e-01,  1.3904e-01, -4.6477e+00, -1.1650e+00,
           -9.5942e-01, -5.3974e-01, -1.1033e+00, -2.4459e+00,  4.2318e+00,
            3.6722e-01, -8.0066e-01, -2.2627e+00, -1.3228e+00, -1.7302e+00,
           -7.4916e-01, -1.9744e+00, -9.6115e-01, -4.3247e-01,  2.8402e-01,
           -1.1384e-01,  1.8387e+00,  1.4803e+00, -1.4242e+00,  8.2505e-01,
           -3.7829e-01,  1.2134e+00, -4.2631e-01,  1.1886e+00,  6.0572e-01,
            1.2001e-01, -1.4911e+00, -2.3198e+00, -1.1939e+00, -5.0289e-01,
            1.5413e+00,  2.1577e+00,  4.0063e-01, -1.8040e+00,  2.3726e+00,
           -1.2916e+00, -6.8357e-01, -5.3062e-01, -1.3877e+00, -1.4345e+00,
           -5.7733e+00, -2.7524e+00, -7.1469e-01, -1.7234e+00, -1.5938e+00,
            3.9268e-01, -1.4293e-01,  1.3666e+00, -1.2487e+00,  2.1339e-01,
            5.7732e-01, -4.4817e+00, -3.7651e-01, -9.7787e-01,  1.6542e+00,
           -1.4578e-02,  3.4764e-01,  1.7497e+00, -1.0848e+00, -3.8392e-02,
           -1.1919e+00,  2.0391e-02, -2.0075e+00]]]),)
</pre></div></div>
</div>
<p>If a module’s value was cached during token generation, then accessing the values of a module will return a list of entries.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
  <span class="n">cache</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cache</span><span class="p">(</span><span class="n">modules</span><span class="o">=</span><span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cache</span><span class="p">[</span><span class="s2">&quot;model.transformer.h.0&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cache</span><span class="p">[</span><span class="s2">&quot;model.transformer.h.0&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
You have set `compile_config`, but we are unable to meet the criteria for compilation. Compilation will be skipped.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
3
(tensor([[[ 0.6784, -1.4596,  0.8340,  ..., -0.8639,  0.0798, -1.6176],
         [-1.6008,  0.3668,  0.7506,  ..., -1.1595, -0.5517,  0.3558]]]),)
</pre></div></div>
</div>
<p>When a cache is defined it can only save the values of modules from that point on in the model’s execution. So if modules are called before it, they will be missed by the cache.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
  <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>

  <span class="n">cache</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cache</span><span class="p">(</span><span class="n">modules</span><span class="o">=</span><span class="p">[</span><span class="n">layer</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">])</span>

<span class="n">cache</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-yellow-fg">NNsight Warning: A module to be cached was missed! Consider defining the Cache before the module is called.</span>
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">IndexError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipython-input-446025223.py</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span>   cache <span class="ansi-blue-fg">=</span> tracer<span class="ansi-blue-fg">.</span>cache<span class="ansi-blue-fg">(</span>modules<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span>layer <span class="ansi-green-fg">for</span> layer <span class="ansi-green-fg">in</span> model<span class="ansi-blue-fg">.</span>transformer<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>
<span class="ansi-green-fg">----&gt; 6</span><span class="ansi-red-fg"> </span>cache<span class="ansi-blue-fg">.</span>model<span class="ansi-blue-fg">.</span>transformer<span class="ansi-blue-fg">.</span>h<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>output

<span class="ansi-green-fg">/usr/local/lib/python3.12/dist-packages/nnsight/intervention/tracing/tracer.py</span> in <span class="ansi-cyan-fg">__getitem__</span><span class="ansi-blue-fg">(self, key)</span>
<span class="ansi-green-intense-fg ansi-bold">    142</span>                     <span class="ansi-green-fg">return</span> Cache<span class="ansi-blue-fg">.</span>CacheDict<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> path<span class="ansi-blue-fg">,</span> rename<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>_rename<span class="ansi-blue-fg">,</span> alias<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>_alias<span class="ansi-blue-fg">,</span> alias_paths<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>_alias_paths<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    143</span>                 <span class="ansi-green-fg">elif</span> any<span class="ansi-blue-fg">(</span>key<span class="ansi-blue-fg">.</span>startswith<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_path <span class="ansi-blue-fg">+</span> <span class="ansi-blue-fg">&#34;.&#34;</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">and</span> len<span class="ansi-blue-fg">(</span>key<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">&gt;=</span> len<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_path<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> <span class="ansi-cyan-fg">1</span> <span class="ansi-green-fg">and</span> key<span class="ansi-blue-fg">[</span>len<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_path<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>isdigit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">for</span> key <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 144</span><span class="ansi-red-fg">                     </span><span class="ansi-green-fg">raise</span> IndexError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">f&#34;Index {key} is out of bounds for modulelist or module does not allow indexing.&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    145</span>
<span class="ansi-green-intense-fg ansi-bold">    146</span>             <span class="ansi-green-fg">return</span> dict<span class="ansi-blue-fg">.</span>__getitem__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> key<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">IndexError</span>: Index 0 is out of bounds for modulelist or module does not allow indexing.
</pre></div></div>
</div>
<p>Multiple caches can be defined in the same tracing context. Additionally, if multiple invokers are defined, the user can choose to cache from one or multiple invokes or from all the invokes at once (basically cache the entire batch)</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span> <span class="k">as</span> <span class="n">tracer</span><span class="p">:</span>
    <span class="n">cache</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

        <span class="n">cache_1</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tracer</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

        <span class="n">cache_2</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
<section id="Renaming">
<h2>Renaming<a class="headerlink" href="#Renaming" title="Link to this heading">#</a></h2>
<p>Although not technically a new feature, renaming modules is possible within <code class="docutils literal notranslate"><span class="pre">NNsight</span></code>! Within the LanguageModel class, you can create a rename attribute that maps a name within the model to a new name. This can help streamline work with multiple models.</p>
<p>Let’s try renaming the <code class="docutils literal notranslate"><span class="pre">gpt2</span></code> layers from <code class="docutils literal notranslate"><span class="pre">h</span></code> to <code class="docutils literal notranslate"><span class="pre">layers</span></code>.</p>
<!-- < not technically new but we should highlight>
< can be attr paths like rename={"transformer.h.0.mlp": "l0mlp"} --><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">rename</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;h&#39;</span><span class="p">:</span> <span class="s1">&#39;layers&#39;</span><span class="p">})</span>

<span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

    <span class="n">l1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Renaming alsow works with dot seperated attribute paths.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">other_model</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">rename</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;transformer.h.0.mlp&#39;</span><span class="p">:</span> <span class="s1">&#39;my_mlp&#39;</span><span class="p">})</span>

<span class="k">with</span> <span class="n">other_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

    <span class="n">l1</span> <span class="o">=</span> <span class="n">other_model</span><span class="o">.</span><span class="n">my_mlp</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="Saving-Edits">
<h2>Saving Edits<a class="headerlink" href="#Saving-Edits" title="Link to this heading">#</a></h2>
<p>In the previous version of nnsight you could integrate your interventions into the model itself using .edit():</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model</span><span class="o">.</span><span class="n">edit</span><span class="p">()</span> <span class="k">as</span> <span class="n">new_model</span><span class="p">:</span>

    <span class="n">new_model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">with</span> <span class="n">new_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">new_model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor(0., device=&#39;cuda:0&#39;, grad_fn=&lt;SumBackward0&gt;)
</pre></div></div>
</div>
<p>Now, you can save those edits on disk using <code class="docutils literal notranslate"><span class="pre">export_edits</span></code></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_model</span><span class="o">.</span><span class="n">export_edits</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>And load them on initialization:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_model</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">import_edits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">with</span> <span class="n">new_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">new_model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor(0., device=&#39;cuda:0&#39;, grad_fn=&lt;SumBackward0&gt;)
</pre></div></div>
</div>
<p>You can even have multiple variants of the same model using the variant keyword:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">new_model</span><span class="o">.</span><span class="n">export_edits</span><span class="p">(</span><span class="n">variant</span><span class="o">=</span><span class="s1">&#39;ablated&#39;</span><span class="p">)</span>

<span class="n">new_model</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">import_edits</span><span class="o">=</span><span class="s1">&#39;ablated&#39;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">new_model</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s2">&quot;Hello World&quot;</span><span class="p">):</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">new_model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor(0., device=&#39;cuda:0&#39;, grad_fn=&lt;SumBackward0&gt;)
</pre></div></div>
</div>
</section>
</section>
<section id="0.5-and-NDIF">
<h1>0.5 and NDIF<a class="headerlink" href="#0.5-and-NDIF" title="Link to this heading">#</a></h1>
<p>NDIF has officially been upgraded to <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code>, so we would love you to test <code class="docutils literal notranslate"><span class="pre">NNsight</span> <span class="pre">0.5</span></code> with our remote models! Learn about accessing NDIF remote models <a class="reference external" href="https://nnsight.net/notebooks/features/remote_execution/">here</a>.</p>
<p>As this is a new release, we expect there will be some bugs that arise. We request that you <strong>report any bugs</strong> or feedback on our forum: <a class="reference external" href="https://discuss.ndif.us">https://discuss.ndif.us</a>.</p>
<p>Thank you for working with us to build and improve NNsight.</p>
<img alt="u2369712967_httpss.mj.runD-sr3xXceZU_NN_logo._Ai._Stylized_di_c161e831-8cb0-4710-9274-bbd6532822ff_2_optimized.png" src="data:image/png;base64,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" />
<script type="application/vnd.jupyter.widget-state+json">
{"02c688c465134409b37562cebae830bb": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_1a57cc32c20342eeaaed2d61e0a95219", "IPY_MODEL_2edbe49fb27c4903a45951c021cc49cd", "IPY_MODEL_16c45f11f27e453ab7c57f8c1ba7c30b"], "layout": "IPY_MODEL_f20058b8554c444b8b0adb80cb1938b5"}}, "038fd76276714b22a08b2d8867820b6d": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "07a4358a6c5b470e8fb1d1da02f1035a": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "0e387e1c95974a04b5f6195de9994143": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "16c45f11f27e453ab7c57f8c1ba7c30b": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_b9e4b00288994c5496145ef292986b45", "placeholder": "\u200b", "style": "IPY_MODEL_3b299f259fde4945a4bc02ac34995768", "value": "\u2007548M/548M\u2007[00:12&lt;00:00,\u200777.3MB/s]"}}, "19f7d7f7c5b349dda4dd68c2d08c5c26": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "20px"}}, "1a57cc32c20342eeaaed2d61e0a95219": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_31a607c045a84bfda28610ec33cd3933", "placeholder": "\u200b", "style": "IPY_MODEL_2206040a2f894e0eb35df25bbe46bbf0", "value": "model.safetensors:\u2007100%"}}, "1b1f5341573943ddacf23693894be89b": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "1beafd4e0bf845b09b2d5182023ec0d4": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "1f025eaf88174cc49ad4ff57bba24b7b": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_efe0d4eadf2f4e518d516cf6f183c11b", "placeholder": "\u200b", "style": "IPY_MODEL_470369ae7cb447d08266b42b96016e3f", "value": "config.json:\u2007100%"}}, "2015dba36094474ebb59380d491f9fc8": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "207c3f884bf44abdb7136f568e85b2a9": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "2206040a2f894e0eb35df25bbe46bbf0": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "2b95db51686948f08ad143beaa271ed8": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_e475ed4872cc4b878a747dca18f542fd", "IPY_MODEL_8858b9a6ad0448c0ad7f7ead6209c49e", "IPY_MODEL_a111724dddb342e79984164547b5afd3"], "layout": "IPY_MODEL_1b1f5341573943ddacf23693894be89b"}}, "2edbe49fb27c4903a45951c021cc49cd": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_328e34e7a3e6499689564baa96806bb0", "max": 548105171, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_432ab2683efa4610b2a2d436227a8b10", "value": 548105171}}, "303856351482433dbac9cc6334450f1c": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3123c39aafaa42eaa7e4f4a5d67f9c4c": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "3150b92b9d4c43e2b95055926cbbbe9e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_2015dba36094474ebb59380d491f9fc8", "max": 124, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_b2ee6cba43ad4a7a837c5808ec4a03ef", "value": 124}}, "31a607c045a84bfda28610ec33cd3933": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "323e253fd8f545e1b78ebadf5f6bb9a4": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "328e34e7a3e6499689564baa96806bb0": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "36990444f0c64717a32fc8891fe4acdb": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "3aa2c0b5982d411787af38e89113e152": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "3b299f259fde4945a4bc02ac34995768": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "3e2800c652ad4984a7e4edc4370f1b09": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "3f9c3d735252411ba777537edd738b96": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_cf285553d6ba4f1bb96e09b3546f8641", "max": 1, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_6903fcf311ea4607849059abe2a43ea3", "value": 1}}, "428c768d7e364b9bad3d45ec087912c8": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_60e4b2fcad9a4383ad4de2dcc4321a99", "placeholder": "\u200b", "style": "IPY_MODEL_8e74ad00af7943febd8251bf8278359a", "value": "\u2007124/124\u2007[00:00&lt;00:00,\u20073.74kB/s]"}}, "432ab2683efa4610b2a2d436227a8b10": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "470369ae7cb447d08266b42b96016e3f": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "4ffde8564945494898a107cbf1b8627b": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "517d535fc5ef4f52bc8bd443f919679e": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "5685e11d1b2342fc916a3f2acdeee4b9": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_3123c39aafaa42eaa7e4f4a5d67f9c4c", "max": 26, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_f0ffef87dee24bc3b8e3c08bc2ea068d", "value": 26}}, "57e15fb40a17484baee9c7248f0c0551": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_de3536c02e0e4e5b84668ddbc266438a", "placeholder": "\u200b", "style": "IPY_MODEL_f97684ca7b1746beb8d2c1d182a1819d", "value": "\u20071.04M/?\u2007[00:00&lt;00:00,\u200710.5MB/s]"}}, "594c18475953477f83fe4aed57e4bd91": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_cfa2115345d04cdf9c91411db02b7df4", "placeholder": "\u200b", "style": "IPY_MODEL_c3208e21697440d1b99fd923a99f6aab", "value": "\u2007665/665\u2007[00:00&lt;00:00,\u200714.8kB/s]"}}, "608f68fc2e2f4d269906e22069f9a384": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "20px"}}, "60e4b2fcad9a4383ad4de2dcc4321a99": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6903fcf311ea4607849059abe2a43ea3": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "6b96cec6a55d423692e106d3ff4f96ac": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_1f025eaf88174cc49ad4ff57bba24b7b", "IPY_MODEL_89bbab0da2304e75815fd5d3e2f088cb", "IPY_MODEL_594c18475953477f83fe4aed57e4bd91"], "layout": "IPY_MODEL_ba5ae11f7e204b429abf352b2d83c22d"}}, "808e5a53556d4ef9a46fabbf62f89081": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_ffcda521fce0428098d5157beadedac8", "IPY_MODEL_3f9c3d735252411ba777537edd738b96", "IPY_MODEL_d34ff36bf6ef4b1dba3d4a8feaf16971"], "layout": "IPY_MODEL_f12374b206e84737b128647c6715a75b"}}, "8858b9a6ad0448c0ad7f7ead6209c49e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_608f68fc2e2f4d269906e22069f9a384", "max": 1, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_207c3f884bf44abdb7136f568e85b2a9", "value": 1}}, "89bbab0da2304e75815fd5d3e2f088cb": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_323e253fd8f545e1b78ebadf5f6bb9a4", "max": 665, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_a7c28e3184ff41cdb75bb325c030f12e", "value": 665}}, "8b19d034ba7247cab1446d0150273c33": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "8e74ad00af7943febd8251bf8278359a": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "94edb0cbe1c04746ad8d060451c164b1": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "98e24571920b4e538c3e45c1aeea9189": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "99a4501374e2412d95eb98ee36f84070": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "9b7e2f91cb4b4b4192b260a68c526975": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "a111724dddb342e79984164547b5afd3": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_d8d64799fdbe4e28be25643da7270317", "placeholder": "\u200b", "style": "IPY_MODEL_36990444f0c64717a32fc8891fe4acdb", "value": "\u2007456k/?\u2007[00:00&lt;00:00,\u200712.4MB/s]"}}, "a62afae87a624d5d9f2e45f2972e2956": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_db8d417341c4405995922000817f0d85", "IPY_MODEL_3150b92b9d4c43e2b95055926cbbbe9e", "IPY_MODEL_428c768d7e364b9bad3d45ec087912c8"], "layout": "IPY_MODEL_98e24571920b4e538c3e45c1aeea9189"}}, "a7c28e3184ff41cdb75bb325c030f12e": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "b2ee6cba43ad4a7a837c5808ec4a03ef": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "b797914fef1e4774953e8592c9f26baa": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_fa17a92caed845e6b97d4932df9e0e98", "IPY_MODEL_5685e11d1b2342fc916a3f2acdeee4b9", "IPY_MODEL_cada7f2593834b57bd0de7510073ebe5"], "layout": "IPY_MODEL_e00e576abb674d4baec0cb4b504b131b"}}, "b9e4b00288994c5496145ef292986b45": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ba5ae11f7e204b429abf352b2d83c22d": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "c08a3788b23d418ea8e665dafab534bd": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_303856351482433dbac9cc6334450f1c", "placeholder": "\u200b", "style": "IPY_MODEL_e3ae73b8e70a41d8bf0897e2fc759471", "value": "vocab.json:\u2007"}}, "c3208e21697440d1b99fd923a99f6aab": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "cada7f2593834b57bd0de7510073ebe5": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_038fd76276714b22a08b2d8867820b6d", "placeholder": "\u200b", "style": "IPY_MODEL_07a4358a6c5b470e8fb1d1da02f1035a", "value": "\u200726.0/26.0\u2007[00:00&lt;00:00,\u2007784B/s]"}}, "cf285553d6ba4f1bb96e09b3546f8641": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": "20px"}}, "cfa2115345d04cdf9c91411db02b7df4": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "d038f77870cc4ff28a30ce7431571c5c": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "FloatProgressModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_19f7d7f7c5b349dda4dd68c2d08c5c26", "max": 1, "min": 0, "orientation": "horizontal", "style": "IPY_MODEL_8b19d034ba7247cab1446d0150273c33", "value": 1}}, "d34ff36bf6ef4b1dba3d4a8feaf16971": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_4ffde8564945494898a107cbf1b8627b", "placeholder": "\u200b", "style": "IPY_MODEL_3aa2c0b5982d411787af38e89113e152", "value": "\u20071.36M/?\u2007[00:00&lt;00:00,\u20079.26MB/s]"}}, "d8d64799fdbe4e28be25643da7270317": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "db8d417341c4405995922000817f0d85": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_99a4501374e2412d95eb98ee36f84070", "placeholder": "\u200b", "style": "IPY_MODEL_3e2800c652ad4984a7e4edc4370f1b09", "value": "generation_config.json:\u2007100%"}}, "de3536c02e0e4e5b84668ddbc266438a": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e00e576abb674d4baec0cb4b504b131b": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "e2bca1ef8c444edfa573242257e54aee": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HBoxModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_c08a3788b23d418ea8e665dafab534bd", "IPY_MODEL_d038f77870cc4ff28a30ce7431571c5c", "IPY_MODEL_57e15fb40a17484baee9c7248f0c0551"], "layout": "IPY_MODEL_94edb0cbe1c04746ad8d060451c164b1"}}, "e3ae73b8e70a41d8bf0897e2fc759471": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "e475ed4872cc4b878a747dca18f542fd": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_9b7e2f91cb4b4b4192b260a68c526975", "placeholder": "\u200b", "style": "IPY_MODEL_0e387e1c95974a04b5f6195de9994143", "value": "merges.txt:\u2007"}}, "efe0d4eadf2f4e518d516cf6f183c11b": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f0ffef87dee24bc3b8e3c08bc2ea068d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "ProgressStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "f12374b206e84737b128647c6715a75b": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f20058b8554c444b8b0adb80cb1938b5": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f64fbc1ec10347be8eee1992d3705f86": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "f95813109f1740ae8551ae0f36f1a601": {"model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "model_name": "LayoutModel", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "f97684ca7b1746beb8d2c1d182a1819d": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "DescriptionStyleModel", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "fa17a92caed845e6b97d4932df9e0e98": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_f95813109f1740ae8551ae0f36f1a601", "placeholder": "\u200b", "style": "IPY_MODEL_f64fbc1ec10347be8eee1992d3705f86", "value": "tokenizer_config.json:\u2007100%"}}, "ffcda521fce0428098d5157beadedac8": {"model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "model_name": "HTMLModel", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_517d535fc5ef4f52bc8bd443f919679e", "placeholder": "\u200b", "style": "IPY_MODEL_1beafd4e0bf845b09b2d5182023ec0d4", "value": "tokenizer.json:\u2007"}}}
</script></section>


                </article>
              
              
              
              
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">NNsight 0.5: Official Walkthrough</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Core-Behavior">Core Behavior</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#No-More-Proxies!">No More Proxies!</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Stack-Traces">Stack Traces</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Vestigial-NNsight-0.4-Artifacts">Vestigial NNsight 0.4 Artifacts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Memory-Management">Memory Management</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Breaking-Changes">Breaking Changes</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Enforcing-Order-with-Modules">Enforcing Order with Modules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#New-Cross-Invoker-Behaviour">New Cross Invoker Behaviour</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Syntax-Update:-.backward()">Syntax Update: <code class="docutils literal notranslate"><span class="pre">.backward()</span></code></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#New-Features">New Features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Accessing-Intermediate-Values">Accessing Intermediate Values</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Skipping-Modules">Skipping Modules</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Cache">Cache</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Renaming">Renaming</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Saving-Edits">Saving Edits</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#0.5-and-NDIF">0.5 and NDIF</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2025 NDIF.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>