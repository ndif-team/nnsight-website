{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSAONKhVOPrx"
   },
   "source": [
    "## Chat Templates\n",
    "\n",
    "ðŸ“— You can find an interactive Colab version of this tutorial [here](https://colab.research.google.com/drive/1dM0tjcP1uZHEDxmHeXndW3HqMPSFA3hL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0AAKnSeL54H"
   },
   "source": [
    "In this tutorial we will be using a [Text Generation Pipeline](https://huggingface.co/docs/transformers/en/conversations#textgenerationpipeline) to demonstrate how to use chat templates with NNsight. We will use Llama 70B-Instruct model remotely to show how different chat formats can be used. With chat templates, rather than writing formatting code by hand each time, you can simply use a template to format chat inputs to any model.\n",
    "\n",
    "\n",
    "This tutorial was adapted from HuggingFace's [Templates](https://huggingface.co/docs/transformers/en/chat_templating) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EknT3tjKbwT5"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QacbbN1iMXTE"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "try:\n",
    "    import google.colab\n",
    "    is_colab = True\n",
    "except ImportError:\n",
    "    is_colab = False\n",
    "\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4Yo4mijcPTA"
   },
   "outputs": [],
   "source": [
    "if is_colab:\n",
    "    !pip install --no-deps nnsight\n",
    "    !pip install msgspec python-socketio[client]\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qO3MZWnwLzU9"
   },
   "outputs": [],
   "source": [
    "import nnsight\n",
    "from nnsight import CONFIG\n",
    "nnsight.CONFIG.APP.REMOTE_LOGGING = False\n",
    "from nnsight import LanguageModel, util\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# include your HuggingFace Token and NNsight API key on Colab secrets\n",
    "!huggingface-cli login --token YOUR_HUGGINGFACE_TOKEN\n",
    "CONFIG.set_default_api_key('YOUR_NDIF_API_KEY')\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uK5wlHprPkhr",
    "outputId": "0caba1d2-7c28-48bb-b81b-a8bb89dffcfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: huggingface-cli <command> [<args>] login [-h] [--token TOKEN]\n",
      "                                                [--add-to-git-credential]\n",
      "huggingface-cli <command> [<args>] login: error: argument --token: expected one argument\n"
     ]
    }
   ],
   "source": [
    "# load in LLama-70B Instruct model\n",
    "!huggingface-cli login --token\n",
    "model = LanguageModel(\"meta-llama/Llama-3.3-70B-Instruct\", device_map=\"auto\", dtype=\"bfloat16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHjrBEVU3xjW"
   },
   "source": [
    "## Applying a Chat Template\n",
    "\n",
    "In order to apply a chat template, there is a specific format that each conversation piece should take. They should be formatted as a list of dictionaries with `role` and `content` key value pairs.\n",
    "\n",
    "\n",
    "![CHAT TEMPLATE EXAMPLE](https://drive.google.com/uc?export-view&id=19Hhn4Q95CvcYfIeEJuaqbkv3fk7gXxZG)\n",
    "\n",
    "The `role` key is used to specify the speaker and the `content` key is used to describe how the model should respond when prompted by the given speaker. In order to apply the template we need to load the tokenizer from the LLama 70B Instruct model so that the model can convert tokens into text. The `user` role is the human asking the question and the `assistant` role provides context to the model about what has already been \"said\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJgxmiepw7fY"
   },
   "source": [
    "Now we will pass a messager to our model and see how it responds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJpfjqsr32WN",
    "outputId": "f457de9e-eb8e-418e-f7c2-0a38a1d0e39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a friendly chatbot who always responds like a teacher<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How many helicopters can a human eat in one sitting?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load in tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.3-70B-Instruct\")\n",
    "\n",
    "# define chat conversation\n",
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a friendly chatbot who always responds like a teacher\"},\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    " ]\n",
    "\n",
    "# convert the conversation into a format the model will understand\n",
    "prompt = tokenizer.apply_chat_template(chat, tokenize=True, add_generation_prompt=True)\n",
    "\n",
    "print(tokenizer.decode(prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lttqzH4Wip-"
   },
   "source": [
    "To generate a response, we will use `.generate()` and `nnsight`'s remote execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319,
     "referenced_widgets": [
      "d62fdf0b17a64494b26308986d27c0a7",
      "1241b74ae46b4ee0bec31f5f97b9656b",
      "352e4b550788448ba73c18c7987360da",
      "a5ac9916569f4a24af53152e34e6352f",
      "4d0e46b09d454082afcfe2545bbabcac",
      "2e5e18293fb547bf8c169ccfce726f3f",
      "72afae0577b0434191508f910ce3d3f1",
      "93cbff1f436d4e38a4657767c329d1b7",
      "07ea4913f93d4345b387237441787cee",
      "6d4c695e8f344ea4a7946dcc21fbc8af",
      "59e62ab39f564dfe9ff3a0c8bf8226e1"
     ]
    },
    "id": "EcMHnDGtzDi2",
    "outputId": "39acd8d7-709e-4a5b-ff78-a894f1b57a5b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62fdf0b17a64494b26308986d27c0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading result:   0%|          | 0.00/3.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a friendly chatbot who always responds like a teacheruser\n",
      "\n",
      "How many helicopters can a human eat in one sitting?assistant\n",
      "\n",
      "I think there may be a bit of a misconception here, my inquisitive student! Helicopters are not edible objects, and it's not possible for a human to eat one, let alone multiple helicopters in one sitting.\n",
      "\n",
      "You see, helicopters are complex machines made of metal, plastic, and other materials, and they are not meant to be consumed as food. In fact, it would be quite harmful to try to eat a helicopter, as it could cause serious injury or even be fatal.\n",
      "\n",
      "So, the answer to your question is zero - a human cannot eat any helicopters in one sitting, or ever, for that matter! But\n"
     ]
    }
   ],
   "source": [
    "with model.generate(prompt, max_new_tokens=128, remote=True) as gen:\n",
    "    # save final generated tokens\n",
    "    saved = model.generator.output.save()\n",
    "\n",
    "# print each decoded output on a new line\n",
    "for seq in saved:\n",
    "    print(model.tokenizer.decode(seq, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuzNLcg9sgDZ"
   },
   "source": [
    "As you can see, the prompt we give the chat model has a huge influence on how the model responds. Let's try some other prompts to see the difference in what the model generates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426,
     "referenced_widgets": [
      "9c1cec9a04fb47ffbc8c7eb955c195fc",
      "698bac5adcf64cc9a8ed86a6578939cf",
      "c4e58beb68944e129f1d6f45aa26ee8b",
      "713049cf46ed4312b664f786c3992cba",
      "f9c1173e38894753b0064ac7ca29a473",
      "391e6b25098d4bcea0035b1d1e1b1ff0",
      "8a3787f5acd64421a222cf4f8ea57a33",
      "888bc733235841ad955cefdae17978f4",
      "8a03ac83547041f896c221dc0c2f9f6a",
      "4b042040ca284abc95c28c73544071b9",
      "5933f91c3e1d447a85453a4c60ebe135"
     ]
    },
    "id": "PWeZVSgwstFY",
    "outputId": "1c5728ea-34f7-40e4-acf4-28a676bc0ce8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1cec9a04fb47ffbc8c7eb955c195fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading result:   0%|          | 0.00/3.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a serious chatbot who always responds like a news reporteruser\n",
      "\n",
      "How many helicopters can a human eat in one sitting?assistant\n",
      "\n",
      "(Breaking News Theme Music Plays)\n",
      "\n",
      "I'm reporting live from the desk, and we have a rather unusual question on our hands. The inquiry at hand is: \"How many helicopters can a human eat in one sitting?\"\n",
      "\n",
      "(Pause for dramatic effect)\n",
      "\n",
      "After conducting a thorough investigation, our team has come to the conclusion that this question is, in fact, based on a false premise. Humans cannot eat helicopters, as they are complex machines made of metal, plastic, and other materials that are not consumable by humans.\n",
      "\n",
      "(Live footage of a helicopter in flight appears on screen)\n",
      "\n",
      "Helicopters are aircraft designed for transportation, rescue,\n"
     ]
    }
   ],
   "source": [
    "# change the system prompt s\n",
    "chat = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a serious chatbot who always responds like a news reporter\"},\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    " ]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(chat, tokenize=True, add_generation_prompt=True)\n",
    "\n",
    "with model.generate(prompt, max_new_tokens=128, remote=True) as gen:\n",
    "    saved = model.generator.output.save()\n",
    "\n",
    "for seq in saved:\n",
    "    print(model.tokenizer.decode(seq, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jb_WAyrSlvra"
   },
   "source": [
    "## Chat Template Parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DTfy88lfRDh"
   },
   "source": [
    "### Indicating the Start of a Response\n",
    "\n",
    "\n",
    "If you'd like to indicate the start of a response, you can use the `add_generation_prompt`. This prompt ensures the model will generate a system response rather than continue the user's message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVQMw4qwmu67",
    "outputId": "9604b75b-31c0-4382-d984-9deb163280ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a friendly chatbot who always responds like a teacher<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How many helicopters can a human eat in one sitting?<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=False)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pfe5xvTMr1qJ"
   },
   "source": [
    "*Note: Not all models require generation prompts*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oX5G8Cvyl4ty"
   },
   "source": [
    "### Continuing the Final Messages\n",
    "\n",
    "In a similar way, the `continue_final_message` parameter determines whether the message should be continued or whether a new message should start. This parameter is useful if you want to 'prefill' a model response to improve the accuracy of a particular instruction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkHQTDu7r_Lm",
    "outputId": "68fb4d3c-70fb-43cf-ebf5-65510f1e40b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nnsight.intervention.contexts.interleaving.InterleavingTracer object at 0x790b98b1b910>\n"
     ]
    }
   ],
   "source": [
    "final_chat = [\n",
    "    {\"role\": \"user\", \"content\": \"Can you format the answer in JSON?\"},\n",
    "    {\"role\": \"assistant\", \"content\": '{\"name\": \"'},\n",
    "]\n",
    "\n",
    "formatted_chat = tokenizer.apply_chat_template(chat, tokenize=True, return_dict=True, continue_final_message=True)\n",
    "print(model.generate(formatted_chat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0DarzkgtPt9"
   },
   "source": [
    "*Note: You shouldnâ€™t use `add_generation_prompt` and `continue_final_message` at the same time. The `add_generation_prompt` adds tokens that start a new message, while the latter removes end of sequence tokens. Using them together returns an error.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NyMYG_cImAXW"
   },
   "source": [
    "## Multiple Templates\n",
    "\n",
    "Each model may have several different templates available for use. In the case that there are multiple templates, the chat template can serve as a dictionary where each dictionary key corresponds to a specific template name. However, there will always be a default template which the `apply_chat_template` command will always look for.\n",
    "\n",
    "\n",
    "In order to access other templates, you can simply add the `chat_template` parameter and the name of whichever template you wish to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "La93F3dd3_iU"
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Chat templates can be added as a preprocessing step before model training as a way to ensure a chat template matches the tokens a model is trained on. You can set `add_generation_prompt= False` because extra tokens meant to start a reply aren't needed while training.\n",
    "\n",
    "<br>\n",
    "It is important to note that some tokenizers add special `<bos>` and `<eos>` tokens. However, adding additional special tokens is often incorrect or duplicated, hurting model performance. When you format text with `apply_chat_template(tokenize = False)`, make sure you set `add_special_tokens = False` as well to avoid duplicating them."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EknT3tjKbwT5",
    "tHjrBEVU3xjW",
    "jb_WAyrSlvra"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07ea4913f93d4345b387237441787cee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1241b74ae46b4ee0bec31f5f97b9656b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e5e18293fb547bf8c169ccfce726f3f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_72afae0577b0434191508f910ce3d3f1",
      "value": "Downloadingâ€‡result:â€‡100%"
     }
    },
    "2e5e18293fb547bf8c169ccfce726f3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "352e4b550788448ba73c18c7987360da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93cbff1f436d4e38a4657767c329d1b7",
      "max": 3113,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07ea4913f93d4345b387237441787cee",
      "value": 3113
     }
    },
    "391e6b25098d4bcea0035b1d1e1b1ff0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b042040ca284abc95c28c73544071b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d0e46b09d454082afcfe2545bbabcac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5933f91c3e1d447a85453a4c60ebe135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59e62ab39f564dfe9ff3a0c8bf8226e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "698bac5adcf64cc9a8ed86a6578939cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_391e6b25098d4bcea0035b1d1e1b1ff0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8a3787f5acd64421a222cf4f8ea57a33",
      "value": "Downloadingâ€‡result:â€‡100%"
     }
    },
    "6d4c695e8f344ea4a7946dcc21fbc8af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "713049cf46ed4312b664f786c3992cba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b042040ca284abc95c28c73544071b9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5933f91c3e1d447a85453a4c60ebe135",
      "value": "â€‡3.11k/3.11kâ€‡[00:00&lt;00:00,â€‡272kB/s]"
     }
    },
    "72afae0577b0434191508f910ce3d3f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "888bc733235841ad955cefdae17978f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a03ac83547041f896c221dc0c2f9f6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a3787f5acd64421a222cf4f8ea57a33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93cbff1f436d4e38a4657767c329d1b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c1cec9a04fb47ffbc8c7eb955c195fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_698bac5adcf64cc9a8ed86a6578939cf",
       "IPY_MODEL_c4e58beb68944e129f1d6f45aa26ee8b",
       "IPY_MODEL_713049cf46ed4312b664f786c3992cba"
      ],
      "layout": "IPY_MODEL_f9c1173e38894753b0064ac7ca29a473"
     }
    },
    "a5ac9916569f4a24af53152e34e6352f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d4c695e8f344ea4a7946dcc21fbc8af",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_59e62ab39f564dfe9ff3a0c8bf8226e1",
      "value": "â€‡3.11k/3.11kâ€‡[00:00&lt;00:00,â€‡201kB/s]"
     }
    },
    "c4e58beb68944e129f1d6f45aa26ee8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_888bc733235841ad955cefdae17978f4",
      "max": 3113,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a03ac83547041f896c221dc0c2f9f6a",
      "value": 3113
     }
    },
    "d62fdf0b17a64494b26308986d27c0a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1241b74ae46b4ee0bec31f5f97b9656b",
       "IPY_MODEL_352e4b550788448ba73c18c7987360da",
       "IPY_MODEL_a5ac9916569f4a24af53152e34e6352f"
      ],
      "layout": "IPY_MODEL_4d0e46b09d454082afcfe2545bbabcac"
     }
    },
    "f9c1173e38894753b0064ac7ca29a473": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
